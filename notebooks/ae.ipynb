{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e769f9c-d0e2-41be-ae9b-cc8f85c7e33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tugash/Documents/gt-explorer\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1f111c-8f04-4d11-96c3-7627097c2c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.nn import functional as F\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf0706e-dc5f-42de-86b2-47559c6bc57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjaimcamp\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">glad-glitter-14</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jaimcamp/gt-explorer\" target=\"_blank\">https://wandb.ai/jaimcamp/gt-explorer</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jaimcamp/gt-explorer/runs/19utkvo3\" target=\"_blank\">https://wandb.ai/jaimcamp/gt-explorer/runs/19utkvo3</a><br/>\n",
       "                Run data is saved locally in <code>/home/tugash/Documents/gt-explorer/wandb/run-20210511_225510-19utkvo3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import wandb\n",
    "\n",
    "# 1. Start a new run\n",
    "wandb.init(project='gt-explorer', entity='jaimcamp')\n",
    "\n",
    "# 2. Save model inputs and hyperparameters\n",
    "config = wandb.config\n",
    "config.learning_rate = 0.0001\n",
    "config.epochs = 1500\n",
    "config.H = 200\n",
    "config.H2 = 50\n",
    "config.H3 = 12\n",
    "config.final = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51d6a88-38a1-4bb5-8a83-897b965b92ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "145a1a99-6b1b-4e51-ad37-79fe820b3784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e84bef1-9f29-470f-9314-85a1a5710bc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-b04004a6dd44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdata_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_X' is not defined"
     ]
    }
   ],
   "source": [
    "del data_X, data_y, data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8e7a37-4a34-409f-9511-a6e8aa806f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "# data_X = torch.load(\"data/processed/mini_dataset.pt\", device)\n",
    "data_y = torch.load(\"data/processed/data_y.pt\", device)\n",
    "data_set = TensorDataset(torch.load(\"data/processed/selected_data.pt\", device).float())\n",
    "#                          torch.load(\"data/processed/mini_data_y.pt\", device).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da4001a3-df39-4ab2-b8f4-e2a40e0c3808",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = DataLoader(data_set, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba5cf13-12f6-48c8-b1c3-f8ff566df8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda')\n",
    "# data_X = torch.load(\"data/processed/mini_dataset.pt\", device)\n",
    "# data_y = torch.load(\"data/processed/mini_data_y.pt\", device)\n",
    "# data_set = TensorDataset(data_X.float(), data_y.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17283eeb-9da8-4829-a75a-fdeaa8d40baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR\n",
    "from pl_bolts.models.self_supervised.simclr.transforms import SimCLRTrainDataTransform, SimCLREvalDataTransform\n",
    "import pytorch_lightning as pl\n",
    "from pl_bolts.models.autoencoders import AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fe7bd59-824f-4e43-8819-a9b8b862a1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,D_in,H=50,H2=12, H3=5,latent_dim=3):\n",
    "        \n",
    "        #Encoder\n",
    "        super(Autoencoder,self).__init__()\n",
    "        self.linear1=nn.Linear(D_in,H)\n",
    "        self.lin_bn1 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear2=nn.Linear(H,H2)\n",
    "        self.lin_bn2 = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear3=nn.Linear(H2,H3)\n",
    "        self.lin_bn3 = nn.BatchNorm1d(num_features=H3)\n",
    "        self.linear4=nn.Linear(H3,H3)\n",
    "        self.lin_bn4 = nn.BatchNorm1d(num_features=H3)\n",
    "        \n",
    "#         # Latent vectors mu and sigma\n",
    "        self.fc1 = nn.Linear(H3, latent_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=latent_dim)\n",
    "        self.fc21 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(latent_dim, latent_dim)\n",
    "\n",
    "#         # Sampling vector\n",
    "        self.fc3 = nn.Linear(latent_dim, latent_dim)\n",
    "        self.fc_bn3 = nn.BatchNorm1d(latent_dim)\n",
    "        self.fc4 = nn.Linear(latent_dim, H3)\n",
    "        self.fc_bn4 = nn.BatchNorm1d(H3)\n",
    "        \n",
    "#         # Decoder\n",
    "        self.linear4a=nn.Linear(H3,H3)\n",
    "        self.lin_bn4a = nn.BatchNorm1d(num_features=H3)\n",
    "        self.linear4b=nn.Linear(H3,H2)\n",
    "        self.lin_bn4b = nn.BatchNorm1d(num_features=H2)\n",
    "        self.linear5=nn.Linear(H2,H)\n",
    "        self.lin_bn5 = nn.BatchNorm1d(num_features=H)\n",
    "        self.linear6=nn.Linear(H,D_in)\n",
    "        self.lin_bn6 = nn.BatchNorm1d(num_features=D_in)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def encode(self, x):\n",
    "        lin1 = self.relu(self.lin_bn1(self.linear1(x)))\n",
    "        lin2 = self.relu(self.lin_bn2(self.linear2(lin1)))\n",
    "        lin3 = self.relu(self.lin_bn3(self.linear3(lin2)))\n",
    "        lin4 = self.relu(self.lin_bn4(self.linear4(lin3)))\n",
    "        \n",
    "        fc1 = F.relu(self.bn1(self.fc1(lin4)))\n",
    "\n",
    "        r1 = self.fc21(fc1)\n",
    "        r2 = self.fc22(fc1)\n",
    "        \n",
    "        return r1, r2\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        if self.training:\n",
    "            std = logvar.mul(0.5).exp_()\n",
    "            eps = Variable(std.data.new(std.size()).normal_())\n",
    "            return eps.mul(std).add_(mu)\n",
    "        else:\n",
    "            return mu\n",
    "        \n",
    "    def decode(self, z):\n",
    "        fc3 = self.relu(self.fc_bn3(self.fc3(z)))\n",
    "        fc4 = self.relu(self.fc_bn4(self.fc4(fc3)))\n",
    "\n",
    "        lin4a = self.relu(self.lin_bn4a(self.linear4a(fc4)))\n",
    "        lin4b = self.relu(self.lin_bn4b(self.linear4b(lin4a)))\n",
    "        lin5 = self.relu(self.lin_bn5(self.linear5(lin4b)))\n",
    "        return self.lin_bn6(self.linear6(lin5))\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        # self.decode(z) ist sp√§ter recon_batch, mu ist mu und logvar ist logvar\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e399259-7fa0-454b-890d-a480f294059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(customLoss, self).__init__()\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"sum\")\n",
    "    \n",
    "    # x_recon ist der im forward im Model erstellte recon_batch, x ist der originale x Batch, mu ist mu und logvar ist logvar \n",
    "    def forward(self, x_recon, x, mu, logvar):\n",
    "        loss_MSE = self.mse_loss(x_recon, x)\n",
    "        loss_KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "        return loss_MSE + loss_KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c552a78-bea3-475c-b737-f7cff6d655db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a module and applies the specified weight initialization\n",
    "def weights_init_uniform_rule(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # for every Linear layer in a model..\n",
    "    if classname.find('Linear') != -1:\n",
    "        # get the number of the inputs\n",
    "        n = m.in_features\n",
    "        y = 1.0/np.sqrt(n)\n",
    "        m.weight.data.uniform_(-y, y)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd57c47f-d90c-4bee-b30e-f971a6b8ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "D_in = data_set.tensors[0].shape[1]\n",
    "H = config.H\n",
    "H2 = config.H2\n",
    "H3 = config.H3\n",
    "final = config.final\n",
    "model = Autoencoder(D_in, H, H2, H3, final).to(device)\n",
    "model.apply(weights_init_uniform_rule)\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aafee8e-b946-4123-b3a7-109c2ee8d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "loss_mse = customLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c21b7161-fbca-4714-9bf7-816b18cda472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x7f3c57f90ee0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "epochs = config.epochs\n",
    "log_interval = 5\n",
    "val_losses = []\n",
    "train_losses = []\n",
    "wandb.watch(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "771e0bea-457a-4dd6-92d3-cf3af80aba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, data in enumerate(train_batches):\n",
    "#         breakpoint()\n",
    "        data = data[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data)\n",
    "        loss = loss_mse(recon_batch, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            wandb.log({\"loss\": loss})\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "               epoch, batch_idx * len(data), len(train_batches.dataset),\n",
    "                      100. * batch_idx / len(train_batches),\n",
    "                      loss.item() / len(data)))\n",
    "    if epoch % 200 == 0:        \n",
    "        print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "            epoch, train_loss / len(train_batches.dataset)))\n",
    "        train_losses.append(train_loss / len(train_batches.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b262e5e-17c3-4d9e-bb03-841893d3455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/11093 (0%)]\tLoss: 1239123456.000000\n",
      "Train Epoch: 1 [5120/11093 (45%)]\tLoss: 1209822592.000000\n",
      "Train Epoch: 1 [8530/11093 (91%)]\tLoss: 1365015615.624853\n",
      "Train Epoch: 2 [0/11093 (0%)]\tLoss: 1464208384.000000\n",
      "Train Epoch: 2 [5120/11093 (45%)]\tLoss: 1284364032.000000\n",
      "Train Epoch: 2 [8530/11093 (91%)]\tLoss: 1312842352.243845\n",
      "Train Epoch: 3 [0/11093 (0%)]\tLoss: 1479628928.000000\n",
      "Train Epoch: 3 [5120/11093 (45%)]\tLoss: 1227810816.000000\n",
      "Train Epoch: 3 [8530/11093 (91%)]\tLoss: 1317840451.826495\n",
      "Train Epoch: 4 [0/11093 (0%)]\tLoss: 1181414400.000000\n",
      "Train Epoch: 4 [5120/11093 (45%)]\tLoss: 1448801792.000000\n",
      "Train Epoch: 4 [8530/11093 (91%)]\tLoss: 1293029121.500586\n",
      "Train Epoch: 5 [0/11093 (0%)]\tLoss: 1054684928.000000\n",
      "Train Epoch: 5 [5120/11093 (45%)]\tLoss: 1206439936.000000\n",
      "Train Epoch: 5 [8530/11093 (91%)]\tLoss: 1206783130.860492\n",
      "Train Epoch: 6 [0/11093 (0%)]\tLoss: 1137474816.000000\n",
      "Train Epoch: 6 [5120/11093 (45%)]\tLoss: 1206588160.000000\n",
      "Train Epoch: 6 [8530/11093 (91%)]\tLoss: 1595829719.784291\n",
      "Train Epoch: 7 [0/11093 (0%)]\tLoss: 1215657216.000000\n",
      "Train Epoch: 7 [5120/11093 (45%)]\tLoss: 1220700672.000000\n",
      "Train Epoch: 7 [8530/11093 (91%)]\tLoss: 1274344600.459554\n",
      "Train Epoch: 8 [0/11093 (0%)]\tLoss: 1721334016.000000\n",
      "Train Epoch: 8 [5120/11093 (45%)]\tLoss: 1395931392.000000\n",
      "Train Epoch: 8 [8530/11093 (91%)]\tLoss: 1058487378.832356\n",
      "Train Epoch: 9 [0/11093 (0%)]\tLoss: 1263277056.000000\n",
      "Train Epoch: 9 [5120/11093 (45%)]\tLoss: 1271223040.000000\n",
      "Train Epoch: 9 [8530/11093 (91%)]\tLoss: 1167247559.277843\n",
      "Train Epoch: 10 [0/11093 (0%)]\tLoss: 1482955776.000000\n",
      "Train Epoch: 10 [5120/11093 (45%)]\tLoss: 1464694784.000000\n",
      "Train Epoch: 10 [8530/11093 (91%)]\tLoss: 1200353995.479484\n",
      "Train Epoch: 11 [0/11093 (0%)]\tLoss: 1196907264.000000\n",
      "Train Epoch: 11 [5120/11093 (45%)]\tLoss: 1340011008.000000\n",
      "Train Epoch: 11 [8530/11093 (91%)]\tLoss: 1278727445.308324\n",
      "Train Epoch: 12 [0/11093 (0%)]\tLoss: 1168841984.000000\n",
      "Train Epoch: 12 [5120/11093 (45%)]\tLoss: 1327762176.000000\n",
      "Train Epoch: 12 [8530/11093 (91%)]\tLoss: 1179031208.665885\n",
      "Train Epoch: 13 [0/11093 (0%)]\tLoss: 1145769728.000000\n",
      "Train Epoch: 13 [5120/11093 (45%)]\tLoss: 1329063936.000000\n",
      "Train Epoch: 13 [8530/11093 (91%)]\tLoss: 1128185106.907386\n",
      "Train Epoch: 14 [0/11093 (0%)]\tLoss: 1241162496.000000\n",
      "Train Epoch: 14 [5120/11093 (45%)]\tLoss: 1247357568.000000\n",
      "Train Epoch: 14 [8530/11093 (91%)]\tLoss: 1269279505.106682\n",
      "Train Epoch: 15 [0/11093 (0%)]\tLoss: 1306916096.000000\n",
      "Train Epoch: 15 [5120/11093 (45%)]\tLoss: 1312645376.000000\n",
      "Train Epoch: 15 [8530/11093 (91%)]\tLoss: 1535003399.502931\n",
      "Train Epoch: 16 [0/11093 (0%)]\tLoss: 1325398528.000000\n",
      "Train Epoch: 16 [5120/11093 (45%)]\tLoss: 1152455296.000000\n",
      "Train Epoch: 16 [8530/11093 (91%)]\tLoss: 1730086784.750293\n",
      "Train Epoch: 17 [0/11093 (0%)]\tLoss: 1151248512.000000\n",
      "Train Epoch: 17 [5120/11093 (45%)]\tLoss: 1383972992.000000\n",
      "Train Epoch: 17 [8530/11093 (91%)]\tLoss: 1263170597.214537\n",
      "Train Epoch: 18 [0/11093 (0%)]\tLoss: 1151844608.000000\n",
      "Train Epoch: 18 [5120/11093 (45%)]\tLoss: 1234855680.000000\n",
      "Train Epoch: 18 [8530/11093 (91%)]\tLoss: 1266584231.465416\n",
      "Train Epoch: 19 [0/11093 (0%)]\tLoss: 1216858368.000000\n",
      "Train Epoch: 19 [5120/11093 (45%)]\tLoss: 1317624320.000000\n",
      "Train Epoch: 19 [8530/11093 (91%)]\tLoss: 1559041666.250879\n",
      "Train Epoch: 20 [0/11093 (0%)]\tLoss: 1212079104.000000\n",
      "Train Epoch: 20 [5120/11093 (45%)]\tLoss: 1134588416.000000\n",
      "Train Epoch: 20 [8530/11093 (91%)]\tLoss: 1172136483.413834\n",
      "Train Epoch: 21 [0/11093 (0%)]\tLoss: 1191073152.000000\n",
      "Train Epoch: 21 [5120/11093 (45%)]\tLoss: 1326480640.000000\n",
      "Train Epoch: 21 [8530/11093 (91%)]\tLoss: 1508224145.256741\n",
      "Train Epoch: 22 [0/11093 (0%)]\tLoss: 1269146496.000000\n",
      "Train Epoch: 22 [5120/11093 (45%)]\tLoss: 1473805824.000000\n",
      "Train Epoch: 22 [8530/11093 (91%)]\tLoss: 1288880454.527550\n",
      "Train Epoch: 23 [0/11093 (0%)]\tLoss: 1190179072.000000\n",
      "Train Epoch: 23 [5120/11093 (45%)]\tLoss: 1183617280.000000\n",
      "Train Epoch: 23 [8530/11093 (91%)]\tLoss: 1267970091.216882\n",
      "Train Epoch: 24 [0/11093 (0%)]\tLoss: 1245053696.000000\n",
      "Train Epoch: 24 [5120/11093 (45%)]\tLoss: 1103077376.000000\n",
      "Train Epoch: 24 [8530/11093 (91%)]\tLoss: 1543307801.810082\n",
      "Train Epoch: 25 [0/11093 (0%)]\tLoss: 1271463168.000000\n",
      "Train Epoch: 25 [5120/11093 (45%)]\tLoss: 1419411200.000000\n",
      "Train Epoch: 25 [8530/11093 (91%)]\tLoss: 1506993021.148886\n",
      "Train Epoch: 26 [0/11093 (0%)]\tLoss: 1423638784.000000\n",
      "Train Epoch: 26 [5120/11093 (45%)]\tLoss: 1186316928.000000\n",
      "Train Epoch: 26 [8530/11093 (91%)]\tLoss: 1371609320.890973\n",
      "Train Epoch: 27 [0/11093 (0%)]\tLoss: 1223541120.000000\n",
      "Train Epoch: 27 [5120/11093 (45%)]\tLoss: 1208364288.000000\n",
      "Train Epoch: 27 [8530/11093 (91%)]\tLoss: 1222835686.189918\n",
      "Train Epoch: 28 [0/11093 (0%)]\tLoss: 1219231488.000000\n",
      "Train Epoch: 28 [5120/11093 (45%)]\tLoss: 1258242816.000000\n",
      "Train Epoch: 28 [8530/11093 (91%)]\tLoss: 1353167659.516999\n",
      "Train Epoch: 29 [0/11093 (0%)]\tLoss: 1164198272.000000\n",
      "Train Epoch: 29 [5120/11093 (45%)]\tLoss: 1307875072.000000\n",
      "Train Epoch: 29 [8530/11093 (91%)]\tLoss: 1240820669.974209\n",
      "Train Epoch: 30 [0/11093 (0%)]\tLoss: 1329313536.000000\n",
      "Train Epoch: 30 [5120/11093 (45%)]\tLoss: 1278546176.000000\n",
      "Train Epoch: 30 [8530/11093 (91%)]\tLoss: 1269349420.417351\n",
      "Train Epoch: 31 [0/11093 (0%)]\tLoss: 1183063168.000000\n",
      "Train Epoch: 31 [5120/11093 (45%)]\tLoss: 1547486848.000000\n",
      "Train Epoch: 31 [8530/11093 (91%)]\tLoss: 1280705587.620164\n",
      "Train Epoch: 32 [0/11093 (0%)]\tLoss: 1154970368.000000\n",
      "Train Epoch: 32 [5120/11093 (45%)]\tLoss: 1449482368.000000\n",
      "Train Epoch: 32 [8530/11093 (91%)]\tLoss: 1185772427.554513\n",
      "Train Epoch: 33 [0/11093 (0%)]\tLoss: 1142868736.000000\n",
      "Train Epoch: 33 [5120/11093 (45%)]\tLoss: 1213544448.000000\n",
      "Train Epoch: 33 [8530/11093 (91%)]\tLoss: 1304042242.701055\n",
      "Train Epoch: 34 [0/11093 (0%)]\tLoss: 1270602368.000000\n",
      "Train Epoch: 34 [5120/11093 (45%)]\tLoss: 1212621824.000000\n",
      "Train Epoch: 34 [8530/11093 (91%)]\tLoss: 1562678030.705745\n",
      "Train Epoch: 35 [0/11093 (0%)]\tLoss: 1289437568.000000\n",
      "Train Epoch: 35 [5120/11093 (45%)]\tLoss: 1339599616.000000\n",
      "Train Epoch: 35 [8530/11093 (91%)]\tLoss: 1279487985.594373\n",
      "Train Epoch: 36 [0/11093 (0%)]\tLoss: 1341818880.000000\n",
      "Train Epoch: 36 [5120/11093 (45%)]\tLoss: 1221374464.000000\n",
      "Train Epoch: 36 [8530/11093 (91%)]\tLoss: 1307558598.677608\n",
      "Train Epoch: 37 [0/11093 (0%)]\tLoss: 1219230208.000000\n",
      "Train Epoch: 37 [5120/11093 (45%)]\tLoss: 1210582400.000000\n",
      "Train Epoch: 37 [8530/11093 (91%)]\tLoss: 1203525154.213365\n",
      "Train Epoch: 38 [0/11093 (0%)]\tLoss: 1486988928.000000\n",
      "Train Epoch: 38 [5120/11093 (45%)]\tLoss: 1378442368.000000\n",
      "Train Epoch: 38 [8530/11093 (91%)]\tLoss: 1162863869.298945\n",
      "Train Epoch: 39 [0/11093 (0%)]\tLoss: 1258183424.000000\n",
      "Train Epoch: 39 [5120/11093 (45%)]\tLoss: 1331207936.000000\n",
      "Train Epoch: 39 [8530/11093 (91%)]\tLoss: 1507110110.086753\n",
      "Train Epoch: 40 [0/11093 (0%)]\tLoss: 1348600576.000000\n",
      "Train Epoch: 40 [5120/11093 (45%)]\tLoss: 1241541120.000000\n",
      "Train Epoch: 40 [8530/11093 (91%)]\tLoss: 1803612491.329426\n",
      "Train Epoch: 41 [0/11093 (0%)]\tLoss: 1312323584.000000\n",
      "Train Epoch: 41 [5120/11093 (45%)]\tLoss: 1469692288.000000\n",
      "Train Epoch: 41 [8530/11093 (91%)]\tLoss: 1208839409.294255\n",
      "Train Epoch: 42 [0/11093 (0%)]\tLoss: 1230361984.000000\n",
      "Train Epoch: 42 [5120/11093 (45%)]\tLoss: 1479873792.000000\n",
      "Train Epoch: 42 [8530/11093 (91%)]\tLoss: 1529276797.749121\n",
      "Train Epoch: 43 [0/11093 (0%)]\tLoss: 1449055104.000000\n",
      "Train Epoch: 43 [5120/11093 (45%)]\tLoss: 1149964032.000000\n",
      "Train Epoch: 43 [8530/11093 (91%)]\tLoss: 1149054519.821805\n",
      "Train Epoch: 44 [0/11093 (0%)]\tLoss: 1236175488.000000\n",
      "Train Epoch: 44 [5120/11093 (45%)]\tLoss: 1111387392.000000\n",
      "Train Epoch: 44 [8530/11093 (91%)]\tLoss: 1136019847.352872\n",
      "Train Epoch: 45 [0/11093 (0%)]\tLoss: 1377615104.000000\n",
      "Train Epoch: 45 [5120/11093 (45%)]\tLoss: 1289834496.000000\n",
      "Train Epoch: 45 [8530/11093 (91%)]\tLoss: 1189879759.981243\n",
      "Train Epoch: 46 [0/11093 (0%)]\tLoss: 1216256256.000000\n",
      "Train Epoch: 46 [5120/11093 (45%)]\tLoss: 1485321088.000000\n",
      "Train Epoch: 46 [8530/11093 (91%)]\tLoss: 1291267102.011723\n",
      "Train Epoch: 47 [0/11093 (0%)]\tLoss: 1177165184.000000\n",
      "Train Epoch: 47 [5120/11093 (45%)]\tLoss: 1444678144.000000\n",
      "Train Epoch: 47 [8530/11093 (91%)]\tLoss: 1313745719.521688\n",
      "Train Epoch: 48 [0/11093 (0%)]\tLoss: 1594257536.000000\n",
      "Train Epoch: 48 [5120/11093 (45%)]\tLoss: 1229078272.000000\n",
      "Train Epoch: 48 [8530/11093 (91%)]\tLoss: 1363852562.907386\n",
      "Train Epoch: 49 [0/11093 (0%)]\tLoss: 1294173440.000000\n",
      "Train Epoch: 49 [5120/11093 (45%)]\tLoss: 1099985408.000000\n",
      "Train Epoch: 49 [8530/11093 (91%)]\tLoss: 1175978444.980070\n",
      "Train Epoch: 50 [0/11093 (0%)]\tLoss: 1214050176.000000\n",
      "Train Epoch: 50 [5120/11093 (45%)]\tLoss: 1298884736.000000\n",
      "Train Epoch: 50 [8530/11093 (91%)]\tLoss: 1182751471.493552\n",
      "Train Epoch: 51 [0/11093 (0%)]\tLoss: 1364285952.000000\n",
      "Train Epoch: 51 [5120/11093 (45%)]\tLoss: 1311720704.000000\n",
      "Train Epoch: 51 [8530/11093 (91%)]\tLoss: 1318787458.550997\n",
      "Train Epoch: 52 [0/11093 (0%)]\tLoss: 1236625664.000000\n",
      "Train Epoch: 52 [5120/11093 (45%)]\tLoss: 1629341440.000000\n",
      "Train Epoch: 52 [8530/11093 (91%)]\tLoss: 1082644501.608441\n",
      "Train Epoch: 53 [0/11093 (0%)]\tLoss: 1169747456.000000\n",
      "Train Epoch: 53 [5120/11093 (45%)]\tLoss: 1272402432.000000\n",
      "Train Epoch: 53 [8530/11093 (91%)]\tLoss: 1166596885.908558\n",
      "Train Epoch: 54 [0/11093 (0%)]\tLoss: 1213404160.000000\n",
      "Train Epoch: 54 [5120/11093 (45%)]\tLoss: 1247798528.000000\n",
      "Train Epoch: 54 [8530/11093 (91%)]\tLoss: 1344438233.584994\n",
      "Train Epoch: 55 [0/11093 (0%)]\tLoss: 1158815744.000000\n",
      "Train Epoch: 55 [5120/11093 (45%)]\tLoss: 1419268224.000000\n",
      "Train Epoch: 55 [8530/11093 (91%)]\tLoss: 1087193529.772568\n",
      "Train Epoch: 56 [0/11093 (0%)]\tLoss: 1396473728.000000\n",
      "Train Epoch: 56 [5120/11093 (45%)]\tLoss: 1324374016.000000\n",
      "Train Epoch: 56 [8530/11093 (91%)]\tLoss: 1252417929.753810\n",
      "Train Epoch: 57 [0/11093 (0%)]\tLoss: 1119211008.000000\n",
      "Train Epoch: 57 [5120/11093 (45%)]\tLoss: 1103173504.000000\n",
      "Train Epoch: 57 [8530/11093 (91%)]\tLoss: 1159278058.991794\n",
      "Train Epoch: 58 [0/11093 (0%)]\tLoss: 1133521024.000000\n",
      "Train Epoch: 58 [5120/11093 (45%)]\tLoss: 1492248320.000000\n",
      "Train Epoch: 58 [8530/11093 (91%)]\tLoss: 1166991945.828839\n",
      "Train Epoch: 59 [0/11093 (0%)]\tLoss: 1373807104.000000\n",
      "Train Epoch: 59 [5120/11093 (45%)]\tLoss: 1072767488.000000\n",
      "Train Epoch: 59 [8530/11093 (91%)]\tLoss: 1077488209.031653\n",
      "Train Epoch: 60 [0/11093 (0%)]\tLoss: 1243634560.000000\n",
      "Train Epoch: 60 [5120/11093 (45%)]\tLoss: 1127742208.000000\n",
      "Train Epoch: 60 [8530/11093 (91%)]\tLoss: 1096689949.711606\n",
      "Train Epoch: 61 [0/11093 (0%)]\tLoss: 1287174144.000000\n",
      "Train Epoch: 61 [5120/11093 (45%)]\tLoss: 1404617984.000000\n",
      "Train Epoch: 61 [8530/11093 (91%)]\tLoss: 1314177657.847597\n",
      "Train Epoch: 62 [0/11093 (0%)]\tLoss: 1187394304.000000\n",
      "Train Epoch: 62 [5120/11093 (45%)]\tLoss: 1288458752.000000\n",
      "Train Epoch: 62 [8530/11093 (91%)]\tLoss: 1577095489.725674\n",
      "Train Epoch: 63 [0/11093 (0%)]\tLoss: 1316858624.000000\n",
      "Train Epoch: 63 [5120/11093 (45%)]\tLoss: 1548602496.000000\n",
      "Train Epoch: 63 [8530/11093 (91%)]\tLoss: 1215116113.932005\n",
      "Train Epoch: 64 [0/11093 (0%)]\tLoss: 1186356480.000000\n",
      "Train Epoch: 64 [5120/11093 (45%)]\tLoss: 1361602048.000000\n",
      "Train Epoch: 64 [8530/11093 (91%)]\tLoss: 1145696971.479484\n",
      "Train Epoch: 65 [0/11093 (0%)]\tLoss: 1280554880.000000\n",
      "Train Epoch: 65 [5120/11093 (45%)]\tLoss: 1379867520.000000\n",
      "Train Epoch: 65 [8530/11093 (91%)]\tLoss: 1195373105.819461\n",
      "Train Epoch: 66 [0/11093 (0%)]\tLoss: 1204614016.000000\n",
      "Train Epoch: 66 [5120/11093 (45%)]\tLoss: 1309517312.000000\n",
      "Train Epoch: 66 [8530/11093 (91%)]\tLoss: 1198287114.504103\n",
      "Train Epoch: 67 [0/11093 (0%)]\tLoss: 1178708480.000000\n",
      "Train Epoch: 67 [5120/11093 (45%)]\tLoss: 1344423424.000000\n",
      "Train Epoch: 67 [8530/11093 (91%)]\tLoss: 1308076432.956624\n",
      "Train Epoch: 68 [0/11093 (0%)]\tLoss: 1373137920.000000\n",
      "Train Epoch: 68 [5120/11093 (45%)]\tLoss: 1633312256.000000\n",
      "Train Epoch: 68 [8530/11093 (91%)]\tLoss: 1144643094.208675\n",
      "Train Epoch: 69 [0/11093 (0%)]\tLoss: 1146294272.000000\n",
      "Train Epoch: 69 [5120/11093 (45%)]\tLoss: 1162086144.000000\n",
      "Train Epoch: 69 [8530/11093 (91%)]\tLoss: 1621399055.005862\n",
      "Train Epoch: 70 [0/11093 (0%)]\tLoss: 1306781952.000000\n",
      "Train Epoch: 70 [5120/11093 (45%)]\tLoss: 1168721408.000000\n",
      "Train Epoch: 70 [8530/11093 (91%)]\tLoss: 1437674372.351700\n",
      "Train Epoch: 71 [0/11093 (0%)]\tLoss: 1316942592.000000\n",
      "Train Epoch: 71 [5120/11093 (45%)]\tLoss: 1509028608.000000\n",
      "Train Epoch: 71 [8530/11093 (91%)]\tLoss: 1123519220.295428\n",
      "Train Epoch: 72 [0/11093 (0%)]\tLoss: 1180381952.000000\n",
      "Train Epoch: 72 [5120/11093 (45%)]\tLoss: 1362422528.000000\n",
      "Train Epoch: 72 [8530/11093 (91%)]\tLoss: 1129509348.989449\n",
      "Train Epoch: 73 [0/11093 (0%)]\tLoss: 1415951872.000000\n",
      "Train Epoch: 73 [5120/11093 (45%)]\tLoss: 1246806144.000000\n",
      "Train Epoch: 73 [8530/11093 (91%)]\tLoss: 1236543927.371629\n",
      "Train Epoch: 74 [0/11093 (0%)]\tLoss: 1263342336.000000\n",
      "Train Epoch: 74 [5120/11093 (45%)]\tLoss: 1163129344.000000\n",
      "Train Epoch: 74 [8530/11093 (91%)]\tLoss: 1544860382.686987\n",
      "Train Epoch: 75 [0/11093 (0%)]\tLoss: 1331521024.000000\n",
      "Train Epoch: 75 [5120/11093 (45%)]\tLoss: 1245464960.000000\n",
      "Train Epoch: 75 [8530/11093 (91%)]\tLoss: 1423016589.055100\n",
      "Train Epoch: 76 [0/11093 (0%)]\tLoss: 1254497536.000000\n",
      "Train Epoch: 76 [5120/11093 (45%)]\tLoss: 1331351424.000000\n",
      "Train Epoch: 76 [8530/11093 (91%)]\tLoss: 1333008386.400938\n",
      "Train Epoch: 77 [0/11093 (0%)]\tLoss: 1527743360.000000\n",
      "Train Epoch: 77 [5120/11093 (45%)]\tLoss: 1555648512.000000\n",
      "Train Epoch: 77 [8530/11093 (91%)]\tLoss: 1458520198.452521\n",
      "Train Epoch: 78 [0/11093 (0%)]\tLoss: 1326562304.000000\n",
      "Train Epoch: 78 [5120/11093 (45%)]\tLoss: 1152195584.000000\n",
      "Train Epoch: 78 [8530/11093 (91%)]\tLoss: 1488958866.157093\n",
      "Train Epoch: 79 [0/11093 (0%)]\tLoss: 1369608448.000000\n",
      "Train Epoch: 79 [5120/11093 (45%)]\tLoss: 1285735168.000000\n",
      "Train Epoch: 79 [8530/11093 (91%)]\tLoss: 1345202999.521688\n",
      "Train Epoch: 80 [0/11093 (0%)]\tLoss: 1176162304.000000\n",
      "Train Epoch: 80 [5120/11093 (45%)]\tLoss: 1159814272.000000\n",
      "Train Epoch: 80 [8530/11093 (91%)]\tLoss: 1527853598.611958\n",
      "Train Epoch: 81 [0/11093 (0%)]\tLoss: 1338372480.000000\n",
      "Train Epoch: 81 [5120/11093 (45%)]\tLoss: 1287219968.000000\n",
      "Train Epoch: 81 [8530/11093 (91%)]\tLoss: 1446122754.100821\n",
      "Train Epoch: 82 [0/11093 (0%)]\tLoss: 1196515456.000000\n",
      "Train Epoch: 82 [5120/11093 (45%)]\tLoss: 1377699072.000000\n",
      "Train Epoch: 82 [8530/11093 (91%)]\tLoss: 1231476911.268464\n",
      "Train Epoch: 83 [0/11093 (0%)]\tLoss: 1219116544.000000\n",
      "Train Epoch: 83 [5120/11093 (45%)]\tLoss: 1260310400.000000\n",
      "Train Epoch: 83 [8530/11093 (91%)]\tLoss: 1136806970.822978\n",
      "Train Epoch: 84 [0/11093 (0%)]\tLoss: 1387269760.000000\n",
      "Train Epoch: 84 [5120/11093 (45%)]\tLoss: 1200838272.000000\n",
      "Train Epoch: 84 [8530/11093 (91%)]\tLoss: 1757971622.865182\n",
      "Train Epoch: 85 [0/11093 (0%)]\tLoss: 1555493632.000000\n",
      "Train Epoch: 85 [5120/11093 (45%)]\tLoss: 1298906112.000000\n",
      "Train Epoch: 85 [8530/11093 (91%)]\tLoss: 1283311507.957796\n",
      "Train Epoch: 86 [0/11093 (0%)]\tLoss: 1309816064.000000\n",
      "Train Epoch: 86 [5120/11093 (45%)]\tLoss: 1163273216.000000\n",
      "Train Epoch: 86 [8530/11093 (91%)]\tLoss: 1247103521.012896\n",
      "Train Epoch: 87 [0/11093 (0%)]\tLoss: 1180481024.000000\n",
      "Train Epoch: 87 [5120/11093 (45%)]\tLoss: 1102629888.000000\n",
      "Train Epoch: 87 [8530/11093 (91%)]\tLoss: 1609412343.896835\n",
      "Train Epoch: 88 [0/11093 (0%)]\tLoss: 1363298304.000000\n",
      "Train Epoch: 88 [5120/11093 (45%)]\tLoss: 1368887808.000000\n",
      "Train Epoch: 88 [8530/11093 (91%)]\tLoss: 1414565595.085580\n",
      "Train Epoch: 89 [0/11093 (0%)]\tLoss: 1452340736.000000\n",
      "Train Epoch: 89 [5120/11093 (45%)]\tLoss: 1325193728.000000\n",
      "Train Epoch: 89 [8530/11093 (91%)]\tLoss: 1114678851.826495\n",
      "Train Epoch: 90 [0/11093 (0%)]\tLoss: 1074448896.000000\n",
      "Train Epoch: 90 [5120/11093 (45%)]\tLoss: 1384373632.000000\n",
      "Train Epoch: 90 [8530/11093 (91%)]\tLoss: 1253136981.833529\n",
      "Train Epoch: 91 [0/11093 (0%)]\tLoss: 1347925248.000000\n",
      "Train Epoch: 91 [5120/11093 (45%)]\tLoss: 1338826752.000000\n",
      "Train Epoch: 91 [8530/11093 (91%)]\tLoss: 1174850887.728019\n",
      "Train Epoch: 92 [0/11093 (0%)]\tLoss: 1268796032.000000\n",
      "Train Epoch: 92 [5120/11093 (45%)]\tLoss: 1482772992.000000\n",
      "Train Epoch: 92 [8530/11093 (91%)]\tLoss: 1150786345.116061\n",
      "Train Epoch: 93 [0/11093 (0%)]\tLoss: 1448969984.000000\n",
      "Train Epoch: 93 [5120/11093 (45%)]\tLoss: 1343565056.000000\n",
      "Train Epoch: 93 [8530/11093 (91%)]\tLoss: 1300483783.878077\n",
      "Train Epoch: 94 [0/11093 (0%)]\tLoss: 1317271680.000000\n",
      "Train Epoch: 94 [5120/11093 (45%)]\tLoss: 1425769600.000000\n",
      "Train Epoch: 94 [8530/11093 (91%)]\tLoss: 1269201138.494725\n",
      "Train Epoch: 95 [0/11093 (0%)]\tLoss: 1298583808.000000\n",
      "Train Epoch: 95 [5120/11093 (45%)]\tLoss: 1166450304.000000\n",
      "Train Epoch: 95 [8530/11093 (91%)]\tLoss: 1114251062.321219\n",
      "Train Epoch: 96 [0/11093 (0%)]\tLoss: 1251712512.000000\n",
      "Train Epoch: 96 [5120/11093 (45%)]\tLoss: 1520253696.000000\n",
      "Train Epoch: 96 [8530/11093 (91%)]\tLoss: 1178703451.835873\n",
      "Train Epoch: 97 [0/11093 (0%)]\tLoss: 1190666624.000000\n",
      "Train Epoch: 97 [5120/11093 (45%)]\tLoss: 1212964608.000000\n",
      "Train Epoch: 97 [8530/11093 (91%)]\tLoss: 1259931828.070340\n",
      "Train Epoch: 98 [0/11093 (0%)]\tLoss: 1341303808.000000\n",
      "Train Epoch: 98 [5120/11093 (45%)]\tLoss: 1402278656.000000\n",
      "Train Epoch: 98 [8530/11093 (91%)]\tLoss: 1248485462.433763\n",
      "Train Epoch: 99 [0/11093 (0%)]\tLoss: 1377041664.000000\n",
      "Train Epoch: 99 [5120/11093 (45%)]\tLoss: 1513739520.000000\n",
      "Train Epoch: 99 [8530/11093 (91%)]\tLoss: 1204564664.271981\n",
      "Train Epoch: 100 [0/11093 (0%)]\tLoss: 1247270912.000000\n",
      "Train Epoch: 100 [5120/11093 (45%)]\tLoss: 1286921472.000000\n",
      "Train Epoch: 100 [8530/11093 (91%)]\tLoss: 1088612733.749121\n",
      "Train Epoch: 101 [0/11093 (0%)]\tLoss: 1320317952.000000\n",
      "Train Epoch: 101 [5120/11093 (45%)]\tLoss: 1278965504.000000\n",
      "Train Epoch: 101 [8530/11093 (91%)]\tLoss: 1287460482.250879\n",
      "Train Epoch: 102 [0/11093 (0%)]\tLoss: 1220923136.000000\n",
      "Train Epoch: 102 [5120/11093 (45%)]\tLoss: 1182358016.000000\n",
      "Train Epoch: 102 [8530/11093 (91%)]\tLoss: 1106417013.345838\n",
      "Train Epoch: 103 [0/11093 (0%)]\tLoss: 1391808896.000000\n",
      "Train Epoch: 103 [5120/11093 (45%)]\tLoss: 1342814720.000000\n",
      "Train Epoch: 103 [8530/11093 (91%)]\tLoss: 1226207755.404455\n",
      "Train Epoch: 104 [0/11093 (0%)]\tLoss: 1199418112.000000\n",
      "Train Epoch: 104 [5120/11093 (45%)]\tLoss: 1158689152.000000\n",
      "Train Epoch: 104 [8530/11093 (91%)]\tLoss: 1307621138.307151\n",
      "Train Epoch: 105 [0/11093 (0%)]\tLoss: 1076842112.000000\n",
      "Train Epoch: 105 [5120/11093 (45%)]\tLoss: 1414948864.000000\n",
      "Train Epoch: 105 [8530/11093 (91%)]\tLoss: 1237395741.711606\n",
      "Train Epoch: 106 [0/11093 (0%)]\tLoss: 1208482304.000000\n",
      "Train Epoch: 106 [5120/11093 (45%)]\tLoss: 1337723136.000000\n",
      "Train Epoch: 106 [8530/11093 (91%)]\tLoss: 1602034204.211020\n",
      "Train Epoch: 107 [0/11093 (0%)]\tLoss: 1276875264.000000\n",
      "Train Epoch: 107 [5120/11093 (45%)]\tLoss: 1460322816.000000\n",
      "Train Epoch: 107 [8530/11093 (91%)]\tLoss: 1277460441.584994\n",
      "Train Epoch: 108 [0/11093 (0%)]\tLoss: 1176444416.000000\n",
      "Train Epoch: 108 [5120/11093 (45%)]\tLoss: 1421154432.000000\n",
      "Train Epoch: 108 [8530/11093 (91%)]\tLoss: 1119094733.580305\n",
      "Train Epoch: 109 [0/11093 (0%)]\tLoss: 1169024768.000000\n",
      "Train Epoch: 109 [5120/11093 (45%)]\tLoss: 1220110080.000000\n",
      "Train Epoch: 109 [8530/11093 (91%)]\tLoss: 1122797786.485346\n",
      "Train Epoch: 110 [0/11093 (0%)]\tLoss: 1359921920.000000\n",
      "Train Epoch: 110 [5120/11093 (45%)]\tLoss: 1218170624.000000\n",
      "Train Epoch: 110 [8530/11093 (91%)]\tLoss: 1372843210.879250\n",
      "Train Epoch: 111 [0/11093 (0%)]\tLoss: 1420376832.000000\n",
      "Train Epoch: 111 [5120/11093 (45%)]\tLoss: 1184152960.000000\n",
      "Train Epoch: 111 [8530/11093 (91%)]\tLoss: 1219929821.486518\n",
      "Train Epoch: 112 [0/11093 (0%)]\tLoss: 1220517760.000000\n",
      "Train Epoch: 112 [5120/11093 (45%)]\tLoss: 1218913920.000000\n",
      "Train Epoch: 112 [8530/11093 (91%)]\tLoss: 1277581833.003517\n",
      "Train Epoch: 113 [0/11093 (0%)]\tLoss: 1373780736.000000\n",
      "Train Epoch: 113 [5120/11093 (45%)]\tLoss: 1218534144.000000\n",
      "Train Epoch: 113 [8530/11093 (91%)]\tLoss: 1138409644.867526\n",
      "Train Epoch: 114 [0/11093 (0%)]\tLoss: 1243487232.000000\n",
      "Train Epoch: 114 [5120/11093 (45%)]\tLoss: 1170284288.000000\n",
      "Train Epoch: 114 [8530/11093 (91%)]\tLoss: 1392467439.793669\n",
      "Train Epoch: 115 [0/11093 (0%)]\tLoss: 1452948736.000000\n",
      "Train Epoch: 115 [5120/11093 (45%)]\tLoss: 1448717312.000000\n",
      "Train Epoch: 115 [8530/11093 (91%)]\tLoss: 1151312784.356389\n",
      "Train Epoch: 116 [0/11093 (0%)]\tLoss: 1297209344.000000\n",
      "Train Epoch: 116 [5120/11093 (45%)]\tLoss: 1294252928.000000\n",
      "Train Epoch: 116 [8530/11093 (91%)]\tLoss: 1314134633.041032\n",
      "Train Epoch: 117 [0/11093 (0%)]\tLoss: 1302033664.000000\n",
      "Train Epoch: 117 [5120/11093 (45%)]\tLoss: 1175699968.000000\n",
      "Train Epoch: 117 [8530/11093 (91%)]\tLoss: 1472474218.841735\n",
      "Train Epoch: 118 [0/11093 (0%)]\tLoss: 1319129088.000000\n",
      "Train Epoch: 118 [5120/11093 (45%)]\tLoss: 1231479808.000000\n",
      "Train Epoch: 118 [8530/11093 (91%)]\tLoss: 1101449031.127784\n",
      "Train Epoch: 119 [0/11093 (0%)]\tLoss: 1099981312.000000\n",
      "Train Epoch: 119 [5120/11093 (45%)]\tLoss: 1166542720.000000\n",
      "Train Epoch: 119 [8530/11093 (91%)]\tLoss: 1279367977.116061\n",
      "Train Epoch: 120 [0/11093 (0%)]\tLoss: 1114020096.000000\n",
      "Train Epoch: 120 [5120/11093 (45%)]\tLoss: 1344897408.000000\n",
      "Train Epoch: 120 [8530/11093 (91%)]\tLoss: 1197573517.355217\n",
      "Train Epoch: 121 [0/11093 (0%)]\tLoss: 1324030464.000000\n",
      "Train Epoch: 121 [5120/11093 (45%)]\tLoss: 1411812864.000000\n",
      "Train Epoch: 121 [8530/11093 (91%)]\tLoss: 1190342507.141852\n",
      "Train Epoch: 122 [0/11093 (0%)]\tLoss: 1357703936.000000\n",
      "Train Epoch: 122 [5120/11093 (45%)]\tLoss: 1268342144.000000\n",
      "Train Epoch: 122 [8530/11093 (91%)]\tLoss: 1295091085.355217\n",
      "Train Epoch: 123 [0/11093 (0%)]\tLoss: 1239850240.000000\n",
      "Train Epoch: 123 [5120/11093 (45%)]\tLoss: 1107058816.000000\n",
      "Train Epoch: 123 [8530/11093 (91%)]\tLoss: 1392347431.315357\n",
      "Train Epoch: 124 [0/11093 (0%)]\tLoss: 1302929408.000000\n",
      "Train Epoch: 124 [5120/11093 (45%)]\tLoss: 1196137856.000000\n",
      "Train Epoch: 124 [8530/11093 (91%)]\tLoss: 1238763623.240328\n",
      "Train Epoch: 125 [0/11093 (0%)]\tLoss: 1071448320.000000\n",
      "Train Epoch: 125 [5120/11093 (45%)]\tLoss: 1242838400.000000\n",
      "Train Epoch: 125 [8530/11093 (91%)]\tLoss: 1207632717.130129\n",
      "Train Epoch: 126 [0/11093 (0%)]\tLoss: 1330607360.000000\n",
      "Train Epoch: 126 [5120/11093 (45%)]\tLoss: 1385254144.000000\n",
      "Train Epoch: 126 [8530/11093 (91%)]\tLoss: 1110711350.021102\n",
      "Train Epoch: 127 [0/11093 (0%)]\tLoss: 1157136128.000000\n",
      "Train Epoch: 127 [5120/11093 (45%)]\tLoss: 1399638016.000000\n",
      "Train Epoch: 127 [8530/11093 (91%)]\tLoss: 1336236629.833529\n",
      "Train Epoch: 128 [0/11093 (0%)]\tLoss: 1170280960.000000\n",
      "Train Epoch: 128 [5120/11093 (45%)]\tLoss: 1174750976.000000\n",
      "Train Epoch: 128 [8530/11093 (91%)]\tLoss: 1268723255.821805\n",
      "Train Epoch: 129 [0/11093 (0%)]\tLoss: 1173969920.000000\n",
      "Train Epoch: 129 [5120/11093 (45%)]\tLoss: 1273537280.000000\n",
      "Train Epoch: 129 [8530/11093 (91%)]\tLoss: 1166712130.926143\n",
      "Train Epoch: 130 [0/11093 (0%)]\tLoss: 1194467584.000000\n",
      "Train Epoch: 130 [5120/11093 (45%)]\tLoss: 1519275392.000000\n",
      "Train Epoch: 130 [8530/11093 (91%)]\tLoss: 1264004202.841735\n",
      "Train Epoch: 131 [0/11093 (0%)]\tLoss: 1405265664.000000\n",
      "Train Epoch: 131 [5120/11093 (45%)]\tLoss: 1233762304.000000\n",
      "Train Epoch: 131 [8530/11093 (91%)]\tLoss: 1107667191.296600\n",
      "Train Epoch: 132 [0/11093 (0%)]\tLoss: 1466769152.000000\n",
      "Train Epoch: 132 [5120/11093 (45%)]\tLoss: 1084015232.000000\n",
      "Train Epoch: 132 [8530/11093 (91%)]\tLoss: 1312617086.649472\n",
      "Train Epoch: 133 [0/11093 (0%)]\tLoss: 1638150784.000000\n",
      "Train Epoch: 133 [5120/11093 (45%)]\tLoss: 1190621824.000000\n",
      "Train Epoch: 133 [8530/11093 (91%)]\tLoss: 1191466607.043376\n",
      "Train Epoch: 134 [0/11093 (0%)]\tLoss: 1284201984.000000\n",
      "Train Epoch: 134 [5120/11093 (45%)]\tLoss: 1128805888.000000\n",
      "Train Epoch: 134 [8530/11093 (91%)]\tLoss: 1296149956.576788\n",
      "Train Epoch: 135 [0/11093 (0%)]\tLoss: 1369360128.000000\n",
      "Train Epoch: 135 [5120/11093 (45%)]\tLoss: 1294627072.000000\n",
      "Train Epoch: 135 [8530/11093 (91%)]\tLoss: 1137718097.932005\n",
      "Train Epoch: 136 [0/11093 (0%)]\tLoss: 1346209408.000000\n",
      "Train Epoch: 136 [5120/11093 (45%)]\tLoss: 1237087232.000000\n",
      "Train Epoch: 136 [8530/11093 (91%)]\tLoss: 1238276059.985932\n",
      "Train Epoch: 137 [0/11093 (0%)]\tLoss: 1182175744.000000\n",
      "Train Epoch: 137 [5120/11093 (45%)]\tLoss: 1365766784.000000\n",
      "Train Epoch: 137 [8530/11093 (91%)]\tLoss: 1240216786.082063\n",
      "Train Epoch: 138 [0/11093 (0%)]\tLoss: 1167734912.000000\n",
      "Train Epoch: 138 [5120/11093 (45%)]\tLoss: 1276601088.000000\n",
      "Train Epoch: 138 [8530/11093 (91%)]\tLoss: 1338857147.873388\n",
      "Train Epoch: 139 [0/11093 (0%)]\tLoss: 1408014848.000000\n",
      "Train Epoch: 139 [5120/11093 (45%)]\tLoss: 1282286080.000000\n",
      "Train Epoch: 139 [8530/11093 (91%)]\tLoss: 1463001232.056272\n",
      "Train Epoch: 140 [0/11093 (0%)]\tLoss: 1080712448.000000\n",
      "Train Epoch: 140 [5120/11093 (45%)]\tLoss: 1174340096.000000\n",
      "Train Epoch: 140 [8530/11093 (91%)]\tLoss: 1080259774.874560\n",
      "Train Epoch: 141 [0/11093 (0%)]\tLoss: 1186746624.000000\n",
      "Train Epoch: 141 [5120/11093 (45%)]\tLoss: 1316824960.000000\n",
      "Train Epoch: 141 [8530/11093 (91%)]\tLoss: 1545468261.739742\n",
      "Train Epoch: 142 [0/11093 (0%)]\tLoss: 1165296640.000000\n",
      "Train Epoch: 142 [5120/11093 (45%)]\tLoss: 1460754816.000000\n",
      "Train Epoch: 142 [8530/11093 (91%)]\tLoss: 1248785329.969519\n",
      "Train Epoch: 143 [0/11093 (0%)]\tLoss: 1190791424.000000\n",
      "Train Epoch: 143 [5120/11093 (45%)]\tLoss: 1326903424.000000\n",
      "Train Epoch: 143 [8530/11093 (91%)]\tLoss: 1265675178.766706\n",
      "Train Epoch: 144 [0/11093 (0%)]\tLoss: 1217347712.000000\n",
      "Train Epoch: 144 [5120/11093 (45%)]\tLoss: 1476596352.000000\n",
      "Train Epoch: 144 [8530/11093 (91%)]\tLoss: 1421890414.743259\n",
      "Train Epoch: 145 [0/11093 (0%)]\tLoss: 1329458432.000000\n",
      "Train Epoch: 145 [5120/11093 (45%)]\tLoss: 1052920704.000000\n",
      "Train Epoch: 145 [8530/11093 (91%)]\tLoss: 1562996260.614302\n",
      "Train Epoch: 146 [0/11093 (0%)]\tLoss: 1433710336.000000\n",
      "Train Epoch: 146 [5120/11093 (45%)]\tLoss: 1373361664.000000\n",
      "Train Epoch: 146 [8530/11093 (91%)]\tLoss: 1225914187.929660\n",
      "Train Epoch: 147 [0/11093 (0%)]\tLoss: 1211024896.000000\n",
      "Train Epoch: 147 [5120/11093 (45%)]\tLoss: 1434419968.000000\n",
      "Train Epoch: 147 [8530/11093 (91%)]\tLoss: 1296016886.996483\n",
      "Train Epoch: 148 [0/11093 (0%)]\tLoss: 1191072000.000000\n",
      "Train Epoch: 148 [5120/11093 (45%)]\tLoss: 1260473728.000000\n",
      "Train Epoch: 148 [8530/11093 (91%)]\tLoss: 1217335656.140680\n",
      "Train Epoch: 149 [0/11093 (0%)]\tLoss: 1482520192.000000\n",
      "Train Epoch: 149 [5120/11093 (45%)]\tLoss: 1302702208.000000\n",
      "Train Epoch: 149 [8530/11093 (91%)]\tLoss: 1320078202.747948\n",
      "Train Epoch: 150 [0/11093 (0%)]\tLoss: 1385543936.000000\n",
      "Train Epoch: 150 [5120/11093 (45%)]\tLoss: 1360127488.000000\n",
      "Train Epoch: 150 [8530/11093 (91%)]\tLoss: 1247733219.788980\n",
      "Train Epoch: 151 [0/11093 (0%)]\tLoss: 1111576064.000000\n",
      "Train Epoch: 151 [5120/11093 (45%)]\tLoss: 1576131968.000000\n",
      "Train Epoch: 151 [8530/11093 (91%)]\tLoss: 1232950510.893318\n",
      "Train Epoch: 152 [0/11093 (0%)]\tLoss: 1261207296.000000\n",
      "Train Epoch: 152 [5120/11093 (45%)]\tLoss: 1367373056.000000\n",
      "Train Epoch: 152 [8530/11093 (91%)]\tLoss: 1339750680.909730\n",
      "Train Epoch: 153 [0/11093 (0%)]\tLoss: 1554180096.000000\n",
      "Train Epoch: 153 [5120/11093 (45%)]\tLoss: 1154977024.000000\n",
      "Train Epoch: 153 [8530/11093 (91%)]\tLoss: 1064380240.731536\n",
      "Train Epoch: 154 [0/11093 (0%)]\tLoss: 1302668416.000000\n",
      "Train Epoch: 154 [5120/11093 (45%)]\tLoss: 1215414400.000000\n",
      "Train Epoch: 154 [8530/11093 (91%)]\tLoss: 1310699409.556858\n",
      "Train Epoch: 155 [0/11093 (0%)]\tLoss: 1101599360.000000\n",
      "Train Epoch: 155 [5120/11093 (45%)]\tLoss: 1165449984.000000\n",
      "Train Epoch: 155 [8530/11093 (91%)]\tLoss: 1213467726.030481\n",
      "Train Epoch: 156 [0/11093 (0%)]\tLoss: 1075504256.000000\n",
      "Train Epoch: 156 [5120/11093 (45%)]\tLoss: 1461109760.000000\n",
      "Train Epoch: 156 [8530/11093 (91%)]\tLoss: 1105537309.711606\n",
      "Train Epoch: 157 [0/11093 (0%)]\tLoss: 1448462848.000000\n",
      "Train Epoch: 157 [5120/11093 (45%)]\tLoss: 1024256960.000000\n",
      "Train Epoch: 157 [8530/11093 (91%)]\tLoss: 1029211149.205158\n",
      "Train Epoch: 158 [0/11093 (0%)]\tLoss: 1238056448.000000\n",
      "Train Epoch: 158 [5120/11093 (45%)]\tLoss: 1284492800.000000\n",
      "Train Epoch: 158 [8530/11093 (91%)]\tLoss: 1233209274.372802\n",
      "Train Epoch: 159 [0/11093 (0%)]\tLoss: 1299124352.000000\n",
      "Train Epoch: 159 [5120/11093 (45%)]\tLoss: 1386954240.000000\n",
      "Train Epoch: 159 [8530/11093 (91%)]\tLoss: 1536396173.955451\n",
      "Train Epoch: 160 [0/11093 (0%)]\tLoss: 1197864448.000000\n",
      "Train Epoch: 160 [5120/11093 (45%)]\tLoss: 1450908160.000000\n",
      "Train Epoch: 160 [8530/11093 (91%)]\tLoss: 1289145825.388042\n",
      "Train Epoch: 161 [0/11093 (0%)]\tLoss: 1436029184.000000\n",
      "Train Epoch: 161 [5120/11093 (45%)]\tLoss: 1191543552.000000\n",
      "Train Epoch: 161 [8530/11093 (91%)]\tLoss: 1350835868.661196\n",
      "Train Epoch: 162 [0/11093 (0%)]\tLoss: 1376259328.000000\n",
      "Train Epoch: 162 [5120/11093 (45%)]\tLoss: 1220885888.000000\n",
      "Train Epoch: 162 [8530/11093 (91%)]\tLoss: 1221696911.756155\n",
      "Train Epoch: 163 [0/11093 (0%)]\tLoss: 1297186048.000000\n",
      "Train Epoch: 163 [5120/11093 (45%)]\tLoss: 1274449152.000000\n",
      "Train Epoch: 163 [8530/11093 (91%)]\tLoss: 1256319050.429074\n",
      "Train Epoch: 164 [0/11093 (0%)]\tLoss: 1164121344.000000\n",
      "Train Epoch: 164 [5120/11093 (45%)]\tLoss: 1159833472.000000\n",
      "Train Epoch: 164 [8530/11093 (91%)]\tLoss: 1203309185.050410\n",
      "Train Epoch: 165 [0/11093 (0%)]\tLoss: 1206328960.000000\n",
      "Train Epoch: 165 [5120/11093 (45%)]\tLoss: 1495882752.000000\n",
      "Train Epoch: 165 [8530/11093 (91%)]\tLoss: 1553465036.679953\n",
      "Train Epoch: 166 [0/11093 (0%)]\tLoss: 1312163328.000000\n",
      "Train Epoch: 166 [5120/11093 (45%)]\tLoss: 1218673920.000000\n",
      "Train Epoch: 166 [8530/11093 (91%)]\tLoss: 1155887012.764361\n",
      "Train Epoch: 167 [0/11093 (0%)]\tLoss: 1172150528.000000\n",
      "Train Epoch: 167 [5120/11093 (45%)]\tLoss: 1200696960.000000\n",
      "Train Epoch: 167 [8530/11093 (91%)]\tLoss: 1193612469.270809\n",
      "Train Epoch: 168 [0/11093 (0%)]\tLoss: 1584676608.000000\n",
      "Train Epoch: 168 [5120/11093 (45%)]\tLoss: 1120544512.000000\n",
      "Train Epoch: 168 [8530/11093 (91%)]\tLoss: 1127704381.524033\n",
      "Train Epoch: 169 [0/11093 (0%)]\tLoss: 1238198528.000000\n",
      "Train Epoch: 169 [5120/11093 (45%)]\tLoss: 1206177024.000000\n",
      "Train Epoch: 169 [8530/11093 (91%)]\tLoss: 1023716113.106682\n",
      "Train Epoch: 170 [0/11093 (0%)]\tLoss: 1378538752.000000\n",
      "Train Epoch: 170 [5120/11093 (45%)]\tLoss: 1375290368.000000\n",
      "Train Epoch: 170 [8530/11093 (91%)]\tLoss: 1254929886.987104\n",
      "Train Epoch: 171 [0/11093 (0%)]\tLoss: 1333219072.000000\n",
      "Train Epoch: 171 [5120/11093 (45%)]\tLoss: 1430905344.000000\n",
      "Train Epoch: 171 [8530/11093 (91%)]\tLoss: 1381237965.280188\n",
      "Train Epoch: 172 [0/11093 (0%)]\tLoss: 1345778944.000000\n",
      "Train Epoch: 172 [5120/11093 (45%)]\tLoss: 1076070912.000000\n",
      "Train Epoch: 172 [8530/11093 (91%)]\tLoss: 1227485592.159437\n",
      "Train Epoch: 173 [0/11093 (0%)]\tLoss: 1149852160.000000\n",
      "Train Epoch: 173 [5120/11093 (45%)]\tLoss: 1404733952.000000\n",
      "Train Epoch: 173 [8530/11093 (91%)]\tLoss: 1442434913.538101\n",
      "Train Epoch: 174 [0/11093 (0%)]\tLoss: 1286942464.000000\n",
      "Train Epoch: 174 [5120/11093 (45%)]\tLoss: 1313458944.000000\n",
      "Train Epoch: 174 [8530/11093 (91%)]\tLoss: 1098265656.422040\n",
      "Train Epoch: 175 [0/11093 (0%)]\tLoss: 1218786304.000000\n",
      "Train Epoch: 175 [5120/11093 (45%)]\tLoss: 1327493632.000000\n",
      "Train Epoch: 175 [8530/11093 (91%)]\tLoss: 1230429410.888628\n",
      "Train Epoch: 176 [0/11093 (0%)]\tLoss: 1224820224.000000\n",
      "Train Epoch: 176 [5120/11093 (45%)]\tLoss: 1285080704.000000\n",
      "Train Epoch: 176 [8530/11093 (91%)]\tLoss: 1093411997.261430\n",
      "Train Epoch: 177 [0/11093 (0%)]\tLoss: 1113981952.000000\n",
      "Train Epoch: 177 [5120/11093 (45%)]\tLoss: 1561254656.000000\n",
      "Train Epoch: 177 [8530/11093 (91%)]\tLoss: 1244331494.189918\n",
      "Train Epoch: 178 [0/11093 (0%)]\tLoss: 1297818624.000000\n",
      "Train Epoch: 178 [5120/11093 (45%)]\tLoss: 1439999488.000000\n",
      "Train Epoch: 178 [8530/11093 (91%)]\tLoss: 1544675068.698710\n",
      "Train Epoch: 179 [0/11093 (0%)]\tLoss: 1205041152.000000\n",
      "Train Epoch: 179 [5120/11093 (45%)]\tLoss: 1530902784.000000\n",
      "Train Epoch: 179 [8530/11093 (91%)]\tLoss: 1144882727.015240\n",
      "Train Epoch: 180 [0/11093 (0%)]\tLoss: 1181185280.000000\n",
      "Train Epoch: 180 [5120/11093 (45%)]\tLoss: 1153339264.000000\n",
      "Train Epoch: 180 [8530/11093 (91%)]\tLoss: 1642765788.586166\n",
      "Train Epoch: 181 [0/11093 (0%)]\tLoss: 1233457280.000000\n",
      "Train Epoch: 181 [5120/11093 (45%)]\tLoss: 1116018688.000000\n",
      "Train Epoch: 181 [8530/11093 (91%)]\tLoss: 1270179722.354044\n",
      "Train Epoch: 182 [0/11093 (0%)]\tLoss: 1328868864.000000\n",
      "Train Epoch: 182 [5120/11093 (45%)]\tLoss: 1257674240.000000\n",
      "Train Epoch: 182 [8530/11093 (91%)]\tLoss: 1269497932.830012\n",
      "Train Epoch: 183 [0/11093 (0%)]\tLoss: 1248580096.000000\n",
      "Train Epoch: 183 [5120/11093 (45%)]\tLoss: 1374605824.000000\n",
      "Train Epoch: 183 [8530/11093 (91%)]\tLoss: 1320311151.343493\n",
      "Train Epoch: 184 [0/11093 (0%)]\tLoss: 1251631104.000000\n",
      "Train Epoch: 184 [5120/11093 (45%)]\tLoss: 1420246656.000000\n",
      "Train Epoch: 184 [8530/11093 (91%)]\tLoss: 1146945766.490035\n",
      "Train Epoch: 185 [0/11093 (0%)]\tLoss: 1312451584.000000\n",
      "Train Epoch: 185 [5120/11093 (45%)]\tLoss: 1227117184.000000\n",
      "Train Epoch: 185 [8530/11093 (91%)]\tLoss: 1153800232.815944\n",
      "Train Epoch: 186 [0/11093 (0%)]\tLoss: 1078998016.000000\n",
      "Train Epoch: 186 [5120/11093 (45%)]\tLoss: 1630047488.000000\n",
      "Train Epoch: 186 [8530/11093 (91%)]\tLoss: 1199028831.437280\n",
      "Train Epoch: 187 [0/11093 (0%)]\tLoss: 1176935808.000000\n",
      "Train Epoch: 187 [5120/11093 (45%)]\tLoss: 1454332672.000000\n",
      "Train Epoch: 187 [8530/11093 (91%)]\tLoss: 1236010573.430246\n",
      "Train Epoch: 188 [0/11093 (0%)]\tLoss: 1281260160.000000\n",
      "Train Epoch: 188 [5120/11093 (45%)]\tLoss: 1403433856.000000\n",
      "Train Epoch: 188 [8530/11093 (91%)]\tLoss: 1161336565.495897\n",
      "Train Epoch: 189 [0/11093 (0%)]\tLoss: 1665763712.000000\n",
      "Train Epoch: 189 [5120/11093 (45%)]\tLoss: 1161632000.000000\n",
      "Train Epoch: 189 [8530/11093 (91%)]\tLoss: 1186894914.025791\n",
      "Train Epoch: 190 [0/11093 (0%)]\tLoss: 1174942336.000000\n",
      "Train Epoch: 190 [5120/11093 (45%)]\tLoss: 1177172736.000000\n",
      "Train Epoch: 190 [8530/11093 (91%)]\tLoss: 1464305959.315357\n",
      "Train Epoch: 191 [0/11093 (0%)]\tLoss: 1309622400.000000\n",
      "Train Epoch: 191 [5120/11093 (45%)]\tLoss: 1274439168.000000\n",
      "Train Epoch: 191 [8530/11093 (91%)]\tLoss: 1188723007.324736\n",
      "Train Epoch: 192 [0/11093 (0%)]\tLoss: 1226717440.000000\n",
      "Train Epoch: 192 [5120/11093 (45%)]\tLoss: 1210182272.000000\n",
      "Train Epoch: 192 [8530/11093 (91%)]\tLoss: 1213658033.969519\n",
      "Train Epoch: 193 [0/11093 (0%)]\tLoss: 1250058240.000000\n",
      "Train Epoch: 193 [5120/11093 (45%)]\tLoss: 1359270272.000000\n",
      "Train Epoch: 193 [8530/11093 (91%)]\tLoss: 1426169385.416178\n",
      "Train Epoch: 194 [0/11093 (0%)]\tLoss: 1075240320.000000\n",
      "Train Epoch: 194 [5120/11093 (45%)]\tLoss: 1142968704.000000\n",
      "Train Epoch: 194 [8530/11093 (91%)]\tLoss: 1448570865.594373\n",
      "Train Epoch: 195 [0/11093 (0%)]\tLoss: 1125893376.000000\n",
      "Train Epoch: 195 [5120/11093 (45%)]\tLoss: 1135382144.000000\n",
      "Train Epoch: 195 [8530/11093 (91%)]\tLoss: 1150515596.154748\n",
      "Train Epoch: 196 [0/11093 (0%)]\tLoss: 1141386496.000000\n",
      "Train Epoch: 196 [5120/11093 (45%)]\tLoss: 1629005824.000000\n",
      "Train Epoch: 196 [8530/11093 (91%)]\tLoss: 1313441011.695194\n",
      "Train Epoch: 197 [0/11093 (0%)]\tLoss: 1427801344.000000\n",
      "Train Epoch: 197 [5120/11093 (45%)]\tLoss: 1441789440.000000\n",
      "Train Epoch: 197 [8530/11093 (91%)]\tLoss: 1179098819.076202\n",
      "Train Epoch: 198 [0/11093 (0%)]\tLoss: 1217007872.000000\n",
      "Train Epoch: 198 [5120/11093 (45%)]\tLoss: 1143855616.000000\n",
      "Train Epoch: 198 [8530/11093 (91%)]\tLoss: 1490101328.431418\n",
      "Train Epoch: 199 [0/11093 (0%)]\tLoss: 1594766592.000000\n",
      "Train Epoch: 199 [5120/11093 (45%)]\tLoss: 1359877760.000000\n",
      "Train Epoch: 199 [8530/11093 (91%)]\tLoss: 1093048744.966002\n",
      "Train Epoch: 200 [0/11093 (0%)]\tLoss: 1277867648.000000\n",
      "Train Epoch: 200 [5120/11093 (45%)]\tLoss: 1196878592.000000\n",
      "Train Epoch: 200 [8530/11093 (91%)]\tLoss: 1226065312.562720\n",
      "====> Epoch: 200 Average loss: 1293043937.0529\n",
      "Train Epoch: 201 [0/11093 (0%)]\tLoss: 1296393600.000000\n",
      "Train Epoch: 201 [5120/11093 (45%)]\tLoss: 1298774528.000000\n",
      "Train Epoch: 201 [8530/11093 (91%)]\tLoss: 1370112518.602579\n",
      "Train Epoch: 202 [0/11093 (0%)]\tLoss: 1242543232.000000\n",
      "Train Epoch: 202 [5120/11093 (45%)]\tLoss: 1519146752.000000\n",
      "Train Epoch: 202 [8530/11093 (91%)]\tLoss: 1422963422.686987\n",
      "Train Epoch: 203 [0/11093 (0%)]\tLoss: 1181218304.000000\n",
      "Train Epoch: 203 [5120/11093 (45%)]\tLoss: 1287543424.000000\n",
      "Train Epoch: 203 [8530/11093 (91%)]\tLoss: 1318794219.592028\n",
      "Train Epoch: 204 [0/11093 (0%)]\tLoss: 1299670784.000000\n",
      "Train Epoch: 204 [5120/11093 (45%)]\tLoss: 1136481024.000000\n",
      "Train Epoch: 204 [8530/11093 (91%)]\tLoss: 1575219608.159437\n",
      "Train Epoch: 205 [0/11093 (0%)]\tLoss: 1131179776.000000\n",
      "Train Epoch: 205 [5120/11093 (45%)]\tLoss: 1051444608.000000\n",
      "Train Epoch: 205 [8530/11093 (91%)]\tLoss: 1278904077.505275\n",
      "Train Epoch: 206 [0/11093 (0%)]\tLoss: 1455475456.000000\n",
      "Train Epoch: 206 [5120/11093 (45%)]\tLoss: 1182837248.000000\n",
      "Train Epoch: 206 [8530/11093 (91%)]\tLoss: 1230377627.460727\n",
      "Train Epoch: 207 [0/11093 (0%)]\tLoss: 1229452288.000000\n",
      "Train Epoch: 207 [5120/11093 (45%)]\tLoss: 1224965376.000000\n",
      "Train Epoch: 207 [8530/11093 (91%)]\tLoss: 1240555299.113716\n",
      "Train Epoch: 208 [0/11093 (0%)]\tLoss: 1254734336.000000\n",
      "Train Epoch: 208 [5120/11093 (45%)]\tLoss: 1480084224.000000\n",
      "Train Epoch: 208 [8530/11093 (91%)]\tLoss: 1523550964.295428\n",
      "Train Epoch: 209 [0/11093 (0%)]\tLoss: 1122469376.000000\n",
      "Train Epoch: 209 [5120/11093 (45%)]\tLoss: 1194776704.000000\n",
      "Train Epoch: 209 [8530/11093 (91%)]\tLoss: 1226701311.399765\n",
      "Train Epoch: 210 [0/11093 (0%)]\tLoss: 1408244096.000000\n",
      "Train Epoch: 210 [5120/11093 (45%)]\tLoss: 1466894336.000000\n",
      "Train Epoch: 210 [8530/11093 (91%)]\tLoss: 1246591295.324736\n",
      "Train Epoch: 211 [0/11093 (0%)]\tLoss: 1166792960.000000\n",
      "Train Epoch: 211 [5120/11093 (45%)]\tLoss: 1485172736.000000\n",
      "Train Epoch: 211 [8530/11093 (91%)]\tLoss: 1283168911.456038\n",
      "Train Epoch: 212 [0/11093 (0%)]\tLoss: 1243526016.000000\n",
      "Train Epoch: 212 [5120/11093 (45%)]\tLoss: 1282945152.000000\n",
      "Train Epoch: 212 [8530/11093 (91%)]\tLoss: 1232236452.764361\n",
      "Train Epoch: 213 [0/11093 (0%)]\tLoss: 1223917056.000000\n",
      "Train Epoch: 213 [5120/11093 (45%)]\tLoss: 1356428544.000000\n",
      "Train Epoch: 213 [8530/11093 (91%)]\tLoss: 1387113309.936694\n",
      "Train Epoch: 214 [0/11093 (0%)]\tLoss: 1152477056.000000\n",
      "Train Epoch: 214 [5120/11093 (45%)]\tLoss: 1311357952.000000\n",
      "Train Epoch: 214 [8530/11093 (91%)]\tLoss: 1278363040.562720\n",
      "Train Epoch: 215 [0/11093 (0%)]\tLoss: 1268450048.000000\n",
      "Train Epoch: 215 [5120/11093 (45%)]\tLoss: 1221776000.000000\n",
      "Train Epoch: 215 [8530/11093 (91%)]\tLoss: 1121623439.756155\n",
      "Train Epoch: 216 [0/11093 (0%)]\tLoss: 1293137920.000000\n",
      "Train Epoch: 216 [5120/11093 (45%)]\tLoss: 1132511488.000000\n",
      "Train Epoch: 216 [8530/11093 (91%)]\tLoss: 1475729199.118406\n",
      "Train Epoch: 217 [0/11093 (0%)]\tLoss: 1538233088.000000\n",
      "Train Epoch: 217 [5120/11093 (45%)]\tLoss: 1216157312.000000\n",
      "Train Epoch: 217 [8530/11093 (91%)]\tLoss: 1182181239.146542\n",
      "Train Epoch: 218 [0/11093 (0%)]\tLoss: 1334691968.000000\n",
      "Train Epoch: 218 [5120/11093 (45%)]\tLoss: 1309357312.000000\n",
      "Train Epoch: 218 [8530/11093 (91%)]\tLoss: 1239228137.491208\n",
      "Train Epoch: 219 [0/11093 (0%)]\tLoss: 1288931328.000000\n",
      "Train Epoch: 219 [5120/11093 (45%)]\tLoss: 1224623232.000000\n",
      "Train Epoch: 219 [8530/11093 (91%)]\tLoss: 1268509745.219226\n",
      "Train Epoch: 220 [0/11093 (0%)]\tLoss: 1088820992.000000\n",
      "Train Epoch: 220 [5120/11093 (45%)]\tLoss: 1102797824.000000\n",
      "Train Epoch: 220 [8530/11093 (91%)]\tLoss: 1587693114.222743\n",
      "Train Epoch: 221 [0/11093 (0%)]\tLoss: 1208669952.000000\n",
      "Train Epoch: 221 [5120/11093 (45%)]\tLoss: 1111874304.000000\n",
      "Train Epoch: 221 [8530/11093 (91%)]\tLoss: 1183812109.805393\n",
      "Train Epoch: 222 [0/11093 (0%)]\tLoss: 1269465984.000000\n",
      "Train Epoch: 222 [5120/11093 (45%)]\tLoss: 1177552128.000000\n",
      "Train Epoch: 222 [8530/11093 (91%)]\tLoss: 1446625529.697538\n",
      "Train Epoch: 223 [0/11093 (0%)]\tLoss: 1249791360.000000\n",
      "Train Epoch: 223 [5120/11093 (45%)]\tLoss: 1512119808.000000\n",
      "Train Epoch: 223 [8530/11093 (91%)]\tLoss: 1284624532.858148\n",
      "Train Epoch: 224 [0/11093 (0%)]\tLoss: 1160650880.000000\n",
      "Train Epoch: 224 [5120/11093 (45%)]\tLoss: 1282966528.000000\n",
      "Train Epoch: 224 [8530/11093 (91%)]\tLoss: 1241740325.214537\n",
      "Train Epoch: 225 [0/11093 (0%)]\tLoss: 1336430080.000000\n",
      "Train Epoch: 225 [5120/11093 (45%)]\tLoss: 1584425728.000000\n",
      "Train Epoch: 225 [8530/11093 (91%)]\tLoss: 1524935748.426729\n",
      "Train Epoch: 226 [0/11093 (0%)]\tLoss: 1128762880.000000\n",
      "Train Epoch: 226 [5120/11093 (45%)]\tLoss: 1424200320.000000\n",
      "Train Epoch: 226 [8530/11093 (91%)]\tLoss: 1235630802.682298\n",
      "Train Epoch: 227 [0/11093 (0%)]\tLoss: 1340515456.000000\n",
      "Train Epoch: 227 [5120/11093 (45%)]\tLoss: 1218070784.000000\n",
      "Train Epoch: 227 [8530/11093 (91%)]\tLoss: 1041906386.682298\n",
      "Train Epoch: 228 [0/11093 (0%)]\tLoss: 1252689920.000000\n",
      "Train Epoch: 228 [5120/11093 (45%)]\tLoss: 1273038720.000000\n",
      "Train Epoch: 228 [8530/11093 (91%)]\tLoss: 1587956641.162954\n",
      "Train Epoch: 229 [0/11093 (0%)]\tLoss: 1462514432.000000\n",
      "Train Epoch: 229 [5120/11093 (45%)]\tLoss: 1565221760.000000\n",
      "Train Epoch: 229 [8530/11093 (91%)]\tLoss: 1442527877.852286\n",
      "Train Epoch: 230 [0/11093 (0%)]\tLoss: 1276615680.000000\n",
      "Train Epoch: 230 [5120/11093 (45%)]\tLoss: 1254663168.000000\n",
      "Train Epoch: 230 [8530/11093 (91%)]\tLoss: 1500736753.294255\n",
      "Train Epoch: 231 [0/11093 (0%)]\tLoss: 1408947968.000000\n",
      "Train Epoch: 231 [5120/11093 (45%)]\tLoss: 1266823936.000000\n",
      "Train Epoch: 231 [8530/11093 (91%)]\tLoss: 1480331624.140680\n",
      "Train Epoch: 232 [0/11093 (0%)]\tLoss: 1219593472.000000\n",
      "Train Epoch: 232 [5120/11093 (45%)]\tLoss: 1283717504.000000\n",
      "Train Epoch: 232 [8530/11093 (91%)]\tLoss: 1319577885.711606\n",
      "Train Epoch: 233 [0/11093 (0%)]\tLoss: 1480207872.000000\n",
      "Train Epoch: 233 [5120/11093 (45%)]\tLoss: 1249104640.000000\n",
      "Train Epoch: 233 [8530/11093 (91%)]\tLoss: 1239514021.964830\n",
      "Train Epoch: 234 [0/11093 (0%)]\tLoss: 1299211008.000000\n",
      "Train Epoch: 234 [5120/11093 (45%)]\tLoss: 1117459840.000000\n",
      "Train Epoch: 234 [8530/11093 (91%)]\tLoss: 1715704667.535756\n",
      "Train Epoch: 235 [0/11093 (0%)]\tLoss: 1348897280.000000\n",
      "Train Epoch: 235 [5120/11093 (45%)]\tLoss: 1221509632.000000\n",
      "Train Epoch: 235 [8530/11093 (91%)]\tLoss: 1361386319.531067\n",
      "Train Epoch: 236 [0/11093 (0%)]\tLoss: 1261909760.000000\n",
      "Train Epoch: 236 [5120/11093 (45%)]\tLoss: 1326796032.000000\n",
      "Train Epoch: 236 [8530/11093 (91%)]\tLoss: 1338302127.868699\n",
      "Train Epoch: 237 [0/11093 (0%)]\tLoss: 1295190784.000000\n",
      "Train Epoch: 237 [5120/11093 (45%)]\tLoss: 1411630208.000000\n",
      "Train Epoch: 237 [8530/11093 (91%)]\tLoss: 1454740008.215709\n",
      "Train Epoch: 238 [0/11093 (0%)]\tLoss: 1200902656.000000\n",
      "Train Epoch: 238 [5120/11093 (45%)]\tLoss: 1265599744.000000\n",
      "Train Epoch: 238 [8530/11093 (91%)]\tLoss: 1579093991.990621\n",
      "Train Epoch: 239 [0/11093 (0%)]\tLoss: 1150207488.000000\n",
      "Train Epoch: 239 [5120/11093 (45%)]\tLoss: 1156223104.000000\n",
      "Train Epoch: 239 [8530/11093 (91%)]\tLoss: 1454394580.483001\n",
      "Train Epoch: 240 [0/11093 (0%)]\tLoss: 1377790976.000000\n",
      "Train Epoch: 240 [5120/11093 (45%)]\tLoss: 1173763840.000000\n",
      "Train Epoch: 240 [8530/11093 (91%)]\tLoss: 1604208800.862837\n",
      "Train Epoch: 241 [0/11093 (0%)]\tLoss: 1239809408.000000\n",
      "Train Epoch: 241 [5120/11093 (45%)]\tLoss: 1331498624.000000\n",
      "Train Epoch: 241 [8530/11093 (91%)]\tLoss: 1263659543.409144\n",
      "Train Epoch: 242 [0/11093 (0%)]\tLoss: 1331790336.000000\n",
      "Train Epoch: 242 [5120/11093 (45%)]\tLoss: 1256992896.000000\n",
      "Train Epoch: 242 [8530/11093 (91%)]\tLoss: 1122364465.219226\n",
      "Train Epoch: 243 [0/11093 (0%)]\tLoss: 1566435328.000000\n",
      "Train Epoch: 243 [5120/11093 (45%)]\tLoss: 1185801472.000000\n",
      "Train Epoch: 243 [8530/11093 (91%)]\tLoss: 1383247992.046893\n",
      "Train Epoch: 244 [0/11093 (0%)]\tLoss: 1294119936.000000\n",
      "Train Epoch: 244 [5120/11093 (45%)]\tLoss: 1353290496.000000\n",
      "Train Epoch: 244 [8530/11093 (91%)]\tLoss: 1455216046.968347\n",
      "Train Epoch: 245 [0/11093 (0%)]\tLoss: 1263226624.000000\n",
      "Train Epoch: 245 [5120/11093 (45%)]\tLoss: 1440335616.000000\n",
      "Train Epoch: 245 [8530/11093 (91%)]\tLoss: 1291945664.675264\n",
      "Train Epoch: 246 [0/11093 (0%)]\tLoss: 1306563584.000000\n",
      "Train Epoch: 246 [5120/11093 (45%)]\tLoss: 1214742016.000000\n",
      "Train Epoch: 246 [8530/11093 (91%)]\tLoss: 1602296655.531067\n",
      "Train Epoch: 247 [0/11093 (0%)]\tLoss: 1435493120.000000\n",
      "Train Epoch: 247 [5120/11093 (45%)]\tLoss: 1277408512.000000\n",
      "Train Epoch: 247 [8530/11093 (91%)]\tLoss: 1561054612.558030\n",
      "Train Epoch: 248 [0/11093 (0%)]\tLoss: 1138172160.000000\n",
      "Train Epoch: 248 [5120/11093 (45%)]\tLoss: 1161969408.000000\n",
      "Train Epoch: 248 [8530/11093 (91%)]\tLoss: 1519139999.662368\n",
      "Train Epoch: 249 [0/11093 (0%)]\tLoss: 1278666240.000000\n",
      "Train Epoch: 249 [5120/11093 (45%)]\tLoss: 1294445952.000000\n",
      "Train Epoch: 249 [8530/11093 (91%)]\tLoss: 1329602972.961313\n",
      "Train Epoch: 250 [0/11093 (0%)]\tLoss: 1216267520.000000\n",
      "Train Epoch: 250 [5120/11093 (45%)]\tLoss: 1312286720.000000\n",
      "Train Epoch: 250 [8530/11093 (91%)]\tLoss: 1160918687.062134\n",
      "Train Epoch: 251 [0/11093 (0%)]\tLoss: 1255578368.000000\n",
      "Train Epoch: 251 [5120/11093 (45%)]\tLoss: 1566115840.000000\n",
      "Train Epoch: 251 [8530/11093 (91%)]\tLoss: 1242828084.520516\n",
      "Train Epoch: 252 [0/11093 (0%)]\tLoss: 1250844928.000000\n",
      "Train Epoch: 252 [5120/11093 (45%)]\tLoss: 1140826624.000000\n",
      "Train Epoch: 252 [8530/11093 (91%)]\tLoss: 1285833529.922626\n",
      "Train Epoch: 253 [0/11093 (0%)]\tLoss: 1125830528.000000\n",
      "Train Epoch: 253 [5120/11093 (45%)]\tLoss: 1152221312.000000\n",
      "Train Epoch: 253 [8530/11093 (91%)]\tLoss: 1163919206.339977\n",
      "Train Epoch: 254 [0/11093 (0%)]\tLoss: 1434380160.000000\n",
      "Train Epoch: 254 [5120/11093 (45%)]\tLoss: 1438430464.000000\n",
      "Train Epoch: 254 [8530/11093 (91%)]\tLoss: 1071354177.725674\n",
      "Train Epoch: 255 [0/11093 (0%)]\tLoss: 1334600448.000000\n",
      "Train Epoch: 255 [5120/11093 (45%)]\tLoss: 1451332608.000000\n",
      "Train Epoch: 255 [8530/11093 (91%)]\tLoss: 1358698191.080891\n",
      "Train Epoch: 256 [0/11093 (0%)]\tLoss: 1184278016.000000\n",
      "Train Epoch: 256 [5120/11093 (45%)]\tLoss: 1134118400.000000\n",
      "Train Epoch: 256 [8530/11093 (91%)]\tLoss: 1243902629.064478\n",
      "Train Epoch: 257 [0/11093 (0%)]\tLoss: 1169296896.000000\n",
      "Train Epoch: 257 [5120/11093 (45%)]\tLoss: 1227203584.000000\n",
      "Train Epoch: 257 [8530/11093 (91%)]\tLoss: 1616583349.871043\n",
      "Train Epoch: 258 [0/11093 (0%)]\tLoss: 1585518336.000000\n",
      "Train Epoch: 258 [5120/11093 (45%)]\tLoss: 1058317568.000000\n",
      "Train Epoch: 258 [8530/11093 (91%)]\tLoss: 1571054192.243845\n",
      "Train Epoch: 259 [0/11093 (0%)]\tLoss: 1304990976.000000\n",
      "Train Epoch: 259 [5120/11093 (45%)]\tLoss: 1636008448.000000\n",
      "Train Epoch: 259 [8530/11093 (91%)]\tLoss: 1235310805.683470\n",
      "Train Epoch: 260 [0/11093 (0%)]\tLoss: 1108630528.000000\n",
      "Train Epoch: 260 [5120/11093 (45%)]\tLoss: 1227069568.000000\n",
      "Train Epoch: 260 [8530/11093 (91%)]\tLoss: 1350539765.796014\n",
      "Train Epoch: 261 [0/11093 (0%)]\tLoss: 1312114432.000000\n",
      "Train Epoch: 261 [5120/11093 (45%)]\tLoss: 1370247552.000000\n",
      "Train Epoch: 261 [8530/11093 (91%)]\tLoss: 1196788007.315357\n",
      "Train Epoch: 262 [0/11093 (0%)]\tLoss: 1161458560.000000\n",
      "Train Epoch: 262 [5120/11093 (45%)]\tLoss: 1211955456.000000\n",
      "Train Epoch: 262 [8530/11093 (91%)]\tLoss: 1179124941.280188\n",
      "Train Epoch: 263 [0/11093 (0%)]\tLoss: 1330875520.000000\n",
      "Train Epoch: 263 [5120/11093 (45%)]\tLoss: 1357345280.000000\n",
      "Train Epoch: 263 [8530/11093 (91%)]\tLoss: 1443422332.848769\n",
      "Train Epoch: 264 [0/11093 (0%)]\tLoss: 1191525376.000000\n",
      "Train Epoch: 264 [5120/11093 (45%)]\tLoss: 1225431040.000000\n",
      "Train Epoch: 264 [8530/11093 (91%)]\tLoss: 1295566355.807737\n",
      "Train Epoch: 265 [0/11093 (0%)]\tLoss: 1413622656.000000\n",
      "Train Epoch: 265 [5120/11093 (45%)]\tLoss: 1250837248.000000\n",
      "Train Epoch: 265 [8530/11093 (91%)]\tLoss: 1231585395.245018\n",
      "Train Epoch: 266 [0/11093 (0%)]\tLoss: 1275962240.000000\n",
      "Train Epoch: 266 [5120/11093 (45%)]\tLoss: 1372604800.000000\n",
      "Train Epoch: 266 [8530/11093 (91%)]\tLoss: 1217689765.664713\n",
      "Train Epoch: 267 [0/11093 (0%)]\tLoss: 1455354496.000000\n",
      "Train Epoch: 267 [5120/11093 (45%)]\tLoss: 1257097088.000000\n",
      "Train Epoch: 267 [8530/11093 (91%)]\tLoss: 1256699282.157093\n",
      "Train Epoch: 268 [0/11093 (0%)]\tLoss: 1287802496.000000\n",
      "Train Epoch: 268 [5120/11093 (45%)]\tLoss: 1339662080.000000\n",
      "Train Epoch: 268 [8530/11093 (91%)]\tLoss: 1231071940.276670\n",
      "Train Epoch: 269 [0/11093 (0%)]\tLoss: 1425173120.000000\n",
      "Train Epoch: 269 [5120/11093 (45%)]\tLoss: 1474655104.000000\n",
      "Train Epoch: 269 [8530/11093 (91%)]\tLoss: 1258082068.708089\n",
      "Train Epoch: 270 [0/11093 (0%)]\tLoss: 1289002880.000000\n",
      "Train Epoch: 270 [5120/11093 (45%)]\tLoss: 1212873728.000000\n",
      "Train Epoch: 270 [8530/11093 (91%)]\tLoss: 1149345321.416178\n",
      "Train Epoch: 271 [0/11093 (0%)]\tLoss: 1138450560.000000\n",
      "Train Epoch: 271 [5120/11093 (45%)]\tLoss: 1412492416.000000\n",
      "Train Epoch: 271 [8530/11093 (91%)]\tLoss: 1194579759.118406\n",
      "Train Epoch: 272 [0/11093 (0%)]\tLoss: 1605070464.000000\n",
      "Train Epoch: 272 [5120/11093 (45%)]\tLoss: 1239586176.000000\n",
      "Train Epoch: 272 [8530/11093 (91%)]\tLoss: 1214189543.990621\n",
      "Train Epoch: 273 [0/11093 (0%)]\tLoss: 1615644672.000000\n",
      "Train Epoch: 273 [5120/11093 (45%)]\tLoss: 1526322304.000000\n",
      "Train Epoch: 273 [8530/11093 (91%)]\tLoss: 1295420993.425557\n",
      "Train Epoch: 274 [0/11093 (0%)]\tLoss: 1220494592.000000\n",
      "Train Epoch: 274 [5120/11093 (45%)]\tLoss: 1285063040.000000\n",
      "Train Epoch: 274 [8530/11093 (91%)]\tLoss: 1766445665.838218\n",
      "Train Epoch: 275 [0/11093 (0%)]\tLoss: 1152285440.000000\n",
      "Train Epoch: 275 [5120/11093 (45%)]\tLoss: 1105888896.000000\n",
      "Train Epoch: 275 [8530/11093 (91%)]\tLoss: 1513585958.114889\n",
      "Train Epoch: 276 [0/11093 (0%)]\tLoss: 1396410112.000000\n",
      "Train Epoch: 276 [5120/11093 (45%)]\tLoss: 1286003584.000000\n",
      "Train Epoch: 276 [8530/11093 (91%)]\tLoss: 1206197225.191090\n",
      "Train Epoch: 277 [0/11093 (0%)]\tLoss: 1405377536.000000\n",
      "Train Epoch: 277 [5120/11093 (45%)]\tLoss: 1251543424.000000\n",
      "Train Epoch: 277 [8530/11093 (91%)]\tLoss: 1335476012.717468\n",
      "Train Epoch: 278 [0/11093 (0%)]\tLoss: 1325338368.000000\n",
      "Train Epoch: 278 [5120/11093 (45%)]\tLoss: 1341053568.000000\n",
      "Train Epoch: 278 [8530/11093 (91%)]\tLoss: 1191871731.695194\n",
      "Train Epoch: 279 [0/11093 (0%)]\tLoss: 1151363840.000000\n",
      "Train Epoch: 279 [5120/11093 (45%)]\tLoss: 1375490048.000000\n",
      "Train Epoch: 279 [8530/11093 (91%)]\tLoss: 1163265075.620164\n",
      "Train Epoch: 280 [0/11093 (0%)]\tLoss: 1237054208.000000\n",
      "Train Epoch: 280 [5120/11093 (45%)]\tLoss: 1382907264.000000\n",
      "Train Epoch: 280 [8530/11093 (91%)]\tLoss: 1121267332.651817\n",
      "Train Epoch: 281 [0/11093 (0%)]\tLoss: 1288629504.000000\n",
      "Train Epoch: 281 [5120/11093 (45%)]\tLoss: 1349930496.000000\n",
      "Train Epoch: 281 [8530/11093 (91%)]\tLoss: 1163927811.301290\n",
      "Train Epoch: 282 [0/11093 (0%)]\tLoss: 1412845312.000000\n",
      "Train Epoch: 282 [5120/11093 (45%)]\tLoss: 1550999040.000000\n",
      "Train Epoch: 282 [8530/11093 (91%)]\tLoss: 1113182971.498241\n",
      "Train Epoch: 283 [0/11093 (0%)]\tLoss: 1116020096.000000\n",
      "Train Epoch: 283 [5120/11093 (45%)]\tLoss: 1172775808.000000\n",
      "Train Epoch: 283 [8530/11093 (91%)]\tLoss: 1404357345.087925\n",
      "Train Epoch: 284 [0/11093 (0%)]\tLoss: 1433288960.000000\n",
      "Train Epoch: 284 [5120/11093 (45%)]\tLoss: 1266168320.000000\n",
      "Train Epoch: 284 [8530/11093 (91%)]\tLoss: 1138722496.675264\n",
      "Train Epoch: 285 [0/11093 (0%)]\tLoss: 1136284800.000000\n",
      "Train Epoch: 285 [5120/11093 (45%)]\tLoss: 1568046080.000000\n",
      "Train Epoch: 285 [8530/11093 (91%)]\tLoss: 1156491127.146542\n",
      "Train Epoch: 286 [0/11093 (0%)]\tLoss: 1417534848.000000\n",
      "Train Epoch: 286 [5120/11093 (45%)]\tLoss: 1522150784.000000\n",
      "Train Epoch: 286 [8530/11093 (91%)]\tLoss: 1114617387.817116\n",
      "Train Epoch: 287 [0/11093 (0%)]\tLoss: 1128188672.000000\n",
      "Train Epoch: 287 [5120/11093 (45%)]\tLoss: 1179918336.000000\n",
      "Train Epoch: 287 [8530/11093 (91%)]\tLoss: 1367800088.909730\n",
      "Train Epoch: 288 [0/11093 (0%)]\tLoss: 1427810048.000000\n",
      "Train Epoch: 288 [5120/11093 (45%)]\tLoss: 1394644224.000000\n",
      "Train Epoch: 288 [8530/11093 (91%)]\tLoss: 1100809805.430246\n",
      "Train Epoch: 289 [0/11093 (0%)]\tLoss: 1280300288.000000\n",
      "Train Epoch: 289 [5120/11093 (45%)]\tLoss: 1596627712.000000\n",
      "Train Epoch: 289 [8530/11093 (91%)]\tLoss: 1116518930.607269\n",
      "Train Epoch: 290 [0/11093 (0%)]\tLoss: 1224118528.000000\n",
      "Train Epoch: 290 [5120/11093 (45%)]\tLoss: 1411341056.000000\n",
      "Train Epoch: 290 [8530/11093 (91%)]\tLoss: 1198305861.026964\n",
      "Train Epoch: 291 [0/11093 (0%)]\tLoss: 1308556544.000000\n",
      "Train Epoch: 291 [5120/11093 (45%)]\tLoss: 1332100352.000000\n",
      "Train Epoch: 291 [8530/11093 (91%)]\tLoss: 1198224421.214537\n",
      "Train Epoch: 292 [0/11093 (0%)]\tLoss: 1202094080.000000\n",
      "Train Epoch: 292 [5120/11093 (45%)]\tLoss: 1284556672.000000\n",
      "Train Epoch: 292 [8530/11093 (91%)]\tLoss: 1127664660.407972\n",
      "Train Epoch: 293 [0/11093 (0%)]\tLoss: 1224623232.000000\n",
      "Train Epoch: 293 [5120/11093 (45%)]\tLoss: 1382273024.000000\n",
      "Train Epoch: 293 [8530/11093 (91%)]\tLoss: 1495378474.616647\n",
      "Train Epoch: 294 [0/11093 (0%)]\tLoss: 1327808640.000000\n",
      "Train Epoch: 294 [5120/11093 (45%)]\tLoss: 1544751872.000000\n",
      "Train Epoch: 294 [8530/11093 (91%)]\tLoss: 1212313816.084408\n",
      "Train Epoch: 295 [0/11093 (0%)]\tLoss: 1339502592.000000\n",
      "Train Epoch: 295 [5120/11093 (45%)]\tLoss: 1393127680.000000\n",
      "Train Epoch: 295 [8530/11093 (91%)]\tLoss: 1329143836.811255\n",
      "Train Epoch: 296 [0/11093 (0%)]\tLoss: 1208699264.000000\n",
      "Train Epoch: 296 [5120/11093 (45%)]\tLoss: 1286272512.000000\n",
      "Train Epoch: 296 [8530/11093 (91%)]\tLoss: 1392999103.474795\n",
      "Train Epoch: 297 [0/11093 (0%)]\tLoss: 1283335808.000000\n",
      "Train Epoch: 297 [5120/11093 (45%)]\tLoss: 1231884416.000000\n",
      "Train Epoch: 297 [8530/11093 (91%)]\tLoss: 1464285061.552169\n",
      "Train Epoch: 298 [0/11093 (0%)]\tLoss: 1278150400.000000\n",
      "Train Epoch: 298 [5120/11093 (45%)]\tLoss: 1301661184.000000\n",
      "Train Epoch: 298 [8530/11093 (91%)]\tLoss: 1188478841.547479\n",
      "Train Epoch: 299 [0/11093 (0%)]\tLoss: 1217909248.000000\n",
      "Train Epoch: 299 [5120/11093 (45%)]\tLoss: 1209593728.000000\n",
      "Train Epoch: 299 [8530/11093 (91%)]\tLoss: 1289828536.872216\n",
      "Train Epoch: 300 [0/11093 (0%)]\tLoss: 1112345600.000000\n",
      "Train Epoch: 300 [5120/11093 (45%)]\tLoss: 1441357312.000000\n",
      "Train Epoch: 300 [8530/11093 (91%)]\tLoss: 1465374050.138335\n",
      "Train Epoch: 301 [0/11093 (0%)]\tLoss: 1434244608.000000\n",
      "Train Epoch: 301 [5120/11093 (45%)]\tLoss: 1168054400.000000\n",
      "Train Epoch: 301 [8530/11093 (91%)]\tLoss: 1476773011.657679\n",
      "Train Epoch: 302 [0/11093 (0%)]\tLoss: 1496688128.000000\n",
      "Train Epoch: 302 [5120/11093 (45%)]\tLoss: 1193252480.000000\n",
      "Train Epoch: 302 [8530/11093 (91%)]\tLoss: 1250402601.716295\n",
      "Train Epoch: 303 [0/11093 (0%)]\tLoss: 1150614528.000000\n",
      "Train Epoch: 303 [5120/11093 (45%)]\tLoss: 1141273600.000000\n",
      "Train Epoch: 303 [8530/11093 (91%)]\tLoss: 1395935546.522861\n",
      "Train Epoch: 304 [0/11093 (0%)]\tLoss: 1393606784.000000\n",
      "Train Epoch: 304 [5120/11093 (45%)]\tLoss: 1187061760.000000\n",
      "Train Epoch: 304 [8530/11093 (91%)]\tLoss: 1260488615.165299\n",
      "Train Epoch: 305 [0/11093 (0%)]\tLoss: 1570573312.000000\n",
      "Train Epoch: 305 [5120/11093 (45%)]\tLoss: 1257616256.000000\n",
      "Train Epoch: 305 [8530/11093 (91%)]\tLoss: 1205776043.066823\n",
      "Train Epoch: 306 [0/11093 (0%)]\tLoss: 1188629248.000000\n",
      "Train Epoch: 306 [5120/11093 (45%)]\tLoss: 1408000768.000000\n",
      "Train Epoch: 306 [8530/11093 (91%)]\tLoss: 1376916123.460727\n",
      "Train Epoch: 307 [0/11093 (0%)]\tLoss: 1074732288.000000\n",
      "Train Epoch: 307 [5120/11093 (45%)]\tLoss: 1452529280.000000\n",
      "Train Epoch: 307 [8530/11093 (91%)]\tLoss: 1283251887.868699\n",
      "Train Epoch: 308 [0/11093 (0%)]\tLoss: 1336457216.000000\n",
      "Train Epoch: 308 [5120/11093 (45%)]\tLoss: 1256231168.000000\n",
      "Train Epoch: 308 [8530/11093 (91%)]\tLoss: 1300424778.429074\n",
      "Train Epoch: 309 [0/11093 (0%)]\tLoss: 1198148608.000000\n",
      "Train Epoch: 309 [5120/11093 (45%)]\tLoss: 1484993792.000000\n",
      "Train Epoch: 309 [8530/11093 (91%)]\tLoss: 1454240613.139508\n",
      "Train Epoch: 310 [0/11093 (0%)]\tLoss: 1475554560.000000\n",
      "Train Epoch: 310 [5120/11093 (45%)]\tLoss: 1355094912.000000\n",
      "Train Epoch: 310 [8530/11093 (91%)]\tLoss: 1057730910.536929\n",
      "Train Epoch: 311 [0/11093 (0%)]\tLoss: 1270804736.000000\n",
      "Train Epoch: 311 [5120/11093 (45%)]\tLoss: 1325370240.000000\n",
      "Train Epoch: 311 [8530/11093 (91%)]\tLoss: 1310187414.358734\n",
      "Train Epoch: 312 [0/11093 (0%)]\tLoss: 1521980800.000000\n",
      "Train Epoch: 312 [5120/11093 (45%)]\tLoss: 1170950656.000000\n",
      "Train Epoch: 312 [8530/11093 (91%)]\tLoss: 1361789984.412661\n",
      "Train Epoch: 313 [0/11093 (0%)]\tLoss: 1415681536.000000\n",
      "Train Epoch: 313 [5120/11093 (45%)]\tLoss: 1167010816.000000\n",
      "Train Epoch: 313 [8530/11093 (91%)]\tLoss: 1164516021.871043\n",
      "Train Epoch: 314 [0/11093 (0%)]\tLoss: 1119025152.000000\n",
      "Train Epoch: 314 [5120/11093 (45%)]\tLoss: 1209283968.000000\n",
      "Train Epoch: 314 [8530/11093 (91%)]\tLoss: 1534084512.562720\n",
      "Train Epoch: 315 [0/11093 (0%)]\tLoss: 1219061248.000000\n",
      "Train Epoch: 315 [5120/11093 (45%)]\tLoss: 1431528832.000000\n",
      "Train Epoch: 315 [8530/11093 (91%)]\tLoss: 1117597316.651817\n",
      "Train Epoch: 316 [0/11093 (0%)]\tLoss: 1243983232.000000\n",
      "Train Epoch: 316 [5120/11093 (45%)]\tLoss: 1483011328.000000\n",
      "Train Epoch: 316 [8530/11093 (91%)]\tLoss: 1177642275.713951\n",
      "Train Epoch: 317 [0/11093 (0%)]\tLoss: 1133132544.000000\n",
      "Train Epoch: 317 [5120/11093 (45%)]\tLoss: 1206670720.000000\n",
      "Train Epoch: 317 [8530/11093 (91%)]\tLoss: 1203249411.301290\n",
      "Train Epoch: 318 [0/11093 (0%)]\tLoss: 1323042304.000000\n",
      "Train Epoch: 318 [5120/11093 (45%)]\tLoss: 1233438720.000000\n",
      "Train Epoch: 318 [8530/11093 (91%)]\tLoss: 1377328239.643611\n",
      "Train Epoch: 319 [0/11093 (0%)]\tLoss: 1279226496.000000\n",
      "Train Epoch: 319 [5120/11093 (45%)]\tLoss: 1332300800.000000\n",
      "Train Epoch: 319 [8530/11093 (91%)]\tLoss: 1282626107.423212\n",
      "Train Epoch: 320 [0/11093 (0%)]\tLoss: 1285185024.000000\n",
      "Train Epoch: 320 [5120/11093 (45%)]\tLoss: 1197496192.000000\n",
      "Train Epoch: 320 [8530/11093 (91%)]\tLoss: 1088167580.661196\n",
      "Train Epoch: 321 [0/11093 (0%)]\tLoss: 1305974400.000000\n",
      "Train Epoch: 321 [5120/11093 (45%)]\tLoss: 1176687360.000000\n",
      "Train Epoch: 321 [8530/11093 (91%)]\tLoss: 1141267874.963658\n",
      "Train Epoch: 322 [0/11093 (0%)]\tLoss: 1311773952.000000\n",
      "Train Epoch: 322 [5120/11093 (45%)]\tLoss: 1318390528.000000\n",
      "Train Epoch: 322 [8530/11093 (91%)]\tLoss: 1160180196.989449\n",
      "Train Epoch: 323 [0/11093 (0%)]\tLoss: 1129846912.000000\n",
      "Train Epoch: 323 [5120/11093 (45%)]\tLoss: 1205089664.000000\n",
      "Train Epoch: 323 [8530/11093 (91%)]\tLoss: 1396010378.954279\n",
      "Train Epoch: 324 [0/11093 (0%)]\tLoss: 1345528576.000000\n",
      "Train Epoch: 324 [5120/11093 (45%)]\tLoss: 1510686976.000000\n",
      "Train Epoch: 324 [8530/11093 (91%)]\tLoss: 1346113281.500586\n",
      "Train Epoch: 325 [0/11093 (0%)]\tLoss: 1127353728.000000\n",
      "Train Epoch: 325 [5120/11093 (45%)]\tLoss: 1121794048.000000\n",
      "Train Epoch: 325 [8530/11093 (91%)]\tLoss: 1875598217.153576\n",
      "Train Epoch: 326 [0/11093 (0%)]\tLoss: 1127294464.000000\n",
      "Train Epoch: 326 [5120/11093 (45%)]\tLoss: 1127961600.000000\n",
      "Train Epoch: 326 [8530/11093 (91%)]\tLoss: 1292787414.283705\n",
      "Train Epoch: 327 [0/11093 (0%)]\tLoss: 1194285184.000000\n",
      "Train Epoch: 327 [5120/11093 (45%)]\tLoss: 1202519168.000000\n",
      "Train Epoch: 327 [8530/11093 (91%)]\tLoss: 1397469380.876905\n",
      "Train Epoch: 328 [0/11093 (0%)]\tLoss: 1189304832.000000\n",
      "Train Epoch: 328 [5120/11093 (45%)]\tLoss: 1209827840.000000\n",
      "Train Epoch: 328 [8530/11093 (91%)]\tLoss: 1318631954.607269\n",
      "Train Epoch: 329 [0/11093 (0%)]\tLoss: 1372242432.000000\n",
      "Train Epoch: 329 [5120/11093 (45%)]\tLoss: 1225061120.000000\n",
      "Train Epoch: 329 [8530/11093 (91%)]\tLoss: 1166698916.164127\n",
      "Train Epoch: 330 [0/11093 (0%)]\tLoss: 1437563648.000000\n",
      "Train Epoch: 330 [5120/11093 (45%)]\tLoss: 1296166400.000000\n",
      "Train Epoch: 330 [8530/11093 (91%)]\tLoss: 1089284842.691676\n",
      "Train Epoch: 331 [0/11093 (0%)]\tLoss: 1352668672.000000\n",
      "Train Epoch: 331 [5120/11093 (45%)]\tLoss: 1309158016.000000\n",
      "Train Epoch: 331 [8530/11093 (91%)]\tLoss: 1411657425.481829\n",
      "Train Epoch: 332 [0/11093 (0%)]\tLoss: 1228544896.000000\n",
      "Train Epoch: 332 [5120/11093 (45%)]\tLoss: 1304278528.000000\n",
      "Train Epoch: 332 [8530/11093 (91%)]\tLoss: 1197382902.096131\n",
      "Train Epoch: 333 [0/11093 (0%)]\tLoss: 1467942912.000000\n",
      "Train Epoch: 333 [5120/11093 (45%)]\tLoss: 1210921216.000000\n",
      "Train Epoch: 333 [8530/11093 (91%)]\tLoss: 1182636764.286049\n",
      "Train Epoch: 334 [0/11093 (0%)]\tLoss: 1228488704.000000\n",
      "Train Epoch: 334 [5120/11093 (45%)]\tLoss: 1471095552.000000\n",
      "Train Epoch: 334 [8530/11093 (91%)]\tLoss: 1389860751.155920\n",
      "Train Epoch: 335 [0/11093 (0%)]\tLoss: 1604187136.000000\n",
      "Train Epoch: 335 [5120/11093 (45%)]\tLoss: 1166047360.000000\n",
      "Train Epoch: 335 [8530/11093 (91%)]\tLoss: 1397385482.504103\n",
      "Train Epoch: 336 [0/11093 (0%)]\tLoss: 1395249152.000000\n",
      "Train Epoch: 336 [5120/11093 (45%)]\tLoss: 1238891776.000000\n",
      "Train Epoch: 336 [8530/11093 (91%)]\tLoss: 1143727510.958968\n",
      "Train Epoch: 337 [0/11093 (0%)]\tLoss: 1239069440.000000\n",
      "Train Epoch: 337 [5120/11093 (45%)]\tLoss: 1272531456.000000\n",
      "Train Epoch: 337 [8530/11093 (91%)]\tLoss: 1196940822.208675\n",
      "Train Epoch: 338 [0/11093 (0%)]\tLoss: 1051547776.000000\n",
      "Train Epoch: 338 [5120/11093 (45%)]\tLoss: 1301124736.000000\n",
      "Train Epoch: 338 [8530/11093 (91%)]\tLoss: 1495698394.785463\n",
      "Train Epoch: 339 [0/11093 (0%)]\tLoss: 1281238528.000000\n",
      "Train Epoch: 339 [5120/11093 (45%)]\tLoss: 1471873920.000000\n",
      "Train Epoch: 339 [8530/11093 (91%)]\tLoss: 1200025086.199297\n",
      "Train Epoch: 340 [0/11093 (0%)]\tLoss: 1241125888.000000\n",
      "Train Epoch: 340 [5120/11093 (45%)]\tLoss: 1341704704.000000\n",
      "Train Epoch: 340 [8530/11093 (91%)]\tLoss: 1217152032.412661\n",
      "Train Epoch: 341 [0/11093 (0%)]\tLoss: 1491154944.000000\n",
      "Train Epoch: 341 [5120/11093 (45%)]\tLoss: 1195788800.000000\n",
      "Train Epoch: 341 [8530/11093 (91%)]\tLoss: 1345146298.973036\n",
      "Train Epoch: 342 [0/11093 (0%)]\tLoss: 1274468864.000000\n",
      "Train Epoch: 342 [5120/11093 (45%)]\tLoss: 1243165440.000000\n",
      "Train Epoch: 342 [8530/11093 (91%)]\tLoss: 1373853371.873388\n",
      "Train Epoch: 343 [0/11093 (0%)]\tLoss: 1244564224.000000\n",
      "Train Epoch: 343 [5120/11093 (45%)]\tLoss: 1241235712.000000\n",
      "Train Epoch: 343 [8530/11093 (91%)]\tLoss: 1105964791.896835\n",
      "Train Epoch: 344 [0/11093 (0%)]\tLoss: 977655744.000000\n",
      "Train Epoch: 344 [5120/11093 (45%)]\tLoss: 1464541440.000000\n",
      "Train Epoch: 344 [8530/11093 (91%)]\tLoss: 1359358314.541618\n",
      "Train Epoch: 345 [0/11093 (0%)]\tLoss: 1281272960.000000\n",
      "Train Epoch: 345 [5120/11093 (45%)]\tLoss: 1118703360.000000\n",
      "Train Epoch: 345 [8530/11093 (91%)]\tLoss: 1115376007.352872\n",
      "Train Epoch: 346 [0/11093 (0%)]\tLoss: 1316059264.000000\n",
      "Train Epoch: 346 [5120/11093 (45%)]\tLoss: 1131846400.000000\n",
      "Train Epoch: 346 [8530/11093 (91%)]\tLoss: 1203189868.042204\n",
      "Train Epoch: 347 [0/11093 (0%)]\tLoss: 1213386240.000000\n",
      "Train Epoch: 347 [5120/11093 (45%)]\tLoss: 1303615744.000000\n",
      "Train Epoch: 347 [8530/11093 (91%)]\tLoss: 1332809857.650645\n",
      "Train Epoch: 348 [0/11093 (0%)]\tLoss: 1603879424.000000\n",
      "Train Epoch: 348 [5120/11093 (45%)]\tLoss: 1282037248.000000\n",
      "Train Epoch: 348 [8530/11093 (91%)]\tLoss: 1161167539.470105\n",
      "Train Epoch: 349 [0/11093 (0%)]\tLoss: 1129347840.000000\n",
      "Train Epoch: 349 [5120/11093 (45%)]\tLoss: 1201639680.000000\n",
      "Train Epoch: 349 [8530/11093 (91%)]\tLoss: 1788010774.508792\n",
      "Train Epoch: 350 [0/11093 (0%)]\tLoss: 1340466176.000000\n",
      "Train Epoch: 350 [5120/11093 (45%)]\tLoss: 1269441536.000000\n",
      "Train Epoch: 350 [8530/11093 (91%)]\tLoss: 1181116067.864009\n",
      "Train Epoch: 351 [0/11093 (0%)]\tLoss: 1149861888.000000\n",
      "Train Epoch: 351 [5120/11093 (45%)]\tLoss: 1274162688.000000\n",
      "Train Epoch: 351 [8530/11093 (91%)]\tLoss: 1468983063.109027\n",
      "Train Epoch: 352 [0/11093 (0%)]\tLoss: 1489145088.000000\n",
      "Train Epoch: 352 [5120/11093 (45%)]\tLoss: 1114086784.000000\n",
      "Train Epoch: 352 [8530/11093 (91%)]\tLoss: 1186849891.638921\n",
      "Train Epoch: 353 [0/11093 (0%)]\tLoss: 1492391936.000000\n",
      "Train Epoch: 353 [5120/11093 (45%)]\tLoss: 1223829504.000000\n",
      "Train Epoch: 353 [8530/11093 (91%)]\tLoss: 1200834720.862837\n",
      "Train Epoch: 354 [0/11093 (0%)]\tLoss: 1495766016.000000\n",
      "Train Epoch: 354 [5120/11093 (45%)]\tLoss: 1585133696.000000\n",
      "Train Epoch: 354 [8530/11093 (91%)]\tLoss: 1236103153.594373\n",
      "Train Epoch: 355 [0/11093 (0%)]\tLoss: 1333230720.000000\n",
      "Train Epoch: 355 [5120/11093 (45%)]\tLoss: 1212274432.000000\n",
      "Train Epoch: 355 [8530/11093 (91%)]\tLoss: 1118965198.180539\n",
      "Train Epoch: 356 [0/11093 (0%)]\tLoss: 1123637504.000000\n",
      "Train Epoch: 356 [5120/11093 (45%)]\tLoss: 1374464640.000000\n",
      "Train Epoch: 356 [8530/11093 (91%)]\tLoss: 1176737371.835873\n",
      "Train Epoch: 357 [0/11093 (0%)]\tLoss: 1206407040.000000\n",
      "Train Epoch: 357 [5120/11093 (45%)]\tLoss: 1281090816.000000\n",
      "Train Epoch: 357 [8530/11093 (91%)]\tLoss: 1239936279.709261\n",
      "Train Epoch: 358 [0/11093 (0%)]\tLoss: 1448794112.000000\n",
      "Train Epoch: 358 [5120/11093 (45%)]\tLoss: 1301516544.000000\n",
      "Train Epoch: 358 [8530/11093 (91%)]\tLoss: 1362117126.602579\n",
      "Train Epoch: 359 [0/11093 (0%)]\tLoss: 1585373568.000000\n",
      "Train Epoch: 359 [5120/11093 (45%)]\tLoss: 1264788224.000000\n",
      "Train Epoch: 359 [8530/11093 (91%)]\tLoss: 1203543439.756155\n",
      "Train Epoch: 360 [0/11093 (0%)]\tLoss: 1449001984.000000\n",
      "Train Epoch: 360 [5120/11093 (45%)]\tLoss: 1265633536.000000\n",
      "Train Epoch: 360 [8530/11093 (91%)]\tLoss: 1299484071.765533\n",
      "Train Epoch: 361 [0/11093 (0%)]\tLoss: 1509994752.000000\n",
      "Train Epoch: 361 [5120/11093 (45%)]\tLoss: 1160339712.000000\n",
      "Train Epoch: 361 [8530/11093 (91%)]\tLoss: 1488283069.373974\n",
      "Train Epoch: 362 [0/11093 (0%)]\tLoss: 1111899904.000000\n",
      "Train Epoch: 362 [5120/11093 (45%)]\tLoss: 1188879616.000000\n",
      "Train Epoch: 362 [8530/11093 (91%)]\tLoss: 1289478038.358734\n",
      "Train Epoch: 363 [0/11093 (0%)]\tLoss: 1180742656.000000\n",
      "Train Epoch: 363 [5120/11093 (45%)]\tLoss: 1198465280.000000\n",
      "Train Epoch: 363 [8530/11093 (91%)]\tLoss: 1273600040.815944\n",
      "Train Epoch: 364 [0/11093 (0%)]\tLoss: 1189310464.000000\n",
      "Train Epoch: 364 [5120/11093 (45%)]\tLoss: 1043213952.000000\n",
      "Train Epoch: 364 [8530/11093 (91%)]\tLoss: 1164536765.974209\n",
      "Train Epoch: 365 [0/11093 (0%)]\tLoss: 1227364992.000000\n",
      "Train Epoch: 365 [5120/11093 (45%)]\tLoss: 1240679296.000000\n",
      "Train Epoch: 365 [8530/11093 (91%)]\tLoss: 1503201921.050410\n",
      "Train Epoch: 366 [0/11093 (0%)]\tLoss: 1256057728.000000\n",
      "Train Epoch: 366 [5120/11093 (45%)]\tLoss: 1301872768.000000\n",
      "Train Epoch: 366 [8530/11093 (91%)]\tLoss: 1283752051.245018\n",
      "Train Epoch: 367 [0/11093 (0%)]\tLoss: 1154934016.000000\n",
      "Train Epoch: 367 [5120/11093 (45%)]\tLoss: 1433836544.000000\n",
      "Train Epoch: 367 [8530/11093 (91%)]\tLoss: 1380654671.831184\n",
      "Train Epoch: 368 [0/11093 (0%)]\tLoss: 1175981568.000000\n",
      "Train Epoch: 368 [5120/11093 (45%)]\tLoss: 1566891520.000000\n",
      "Train Epoch: 368 [8530/11093 (91%)]\tLoss: 1165175684.351700\n",
      "Train Epoch: 369 [0/11093 (0%)]\tLoss: 1074346240.000000\n",
      "Train Epoch: 369 [5120/11093 (45%)]\tLoss: 1273205120.000000\n",
      "Train Epoch: 369 [8530/11093 (91%)]\tLoss: 1375112769.425557\n",
      "Train Epoch: 370 [0/11093 (0%)]\tLoss: 1326610176.000000\n",
      "Train Epoch: 370 [5120/11093 (45%)]\tLoss: 1236760704.000000\n",
      "Train Epoch: 370 [8530/11093 (91%)]\tLoss: 1287970326.208675\n",
      "Train Epoch: 371 [0/11093 (0%)]\tLoss: 1255822592.000000\n",
      "Train Epoch: 371 [5120/11093 (45%)]\tLoss: 1268113664.000000\n",
      "Train Epoch: 371 [8530/11093 (91%)]\tLoss: 1240178832.056272\n",
      "Train Epoch: 372 [0/11093 (0%)]\tLoss: 1067776576.000000\n",
      "Train Epoch: 372 [5120/11093 (45%)]\tLoss: 1138049536.000000\n",
      "Train Epoch: 372 [8530/11093 (91%)]\tLoss: 1233254680.909730\n",
      "Train Epoch: 373 [0/11093 (0%)]\tLoss: 1349069312.000000\n",
      "Train Epoch: 373 [5120/11093 (45%)]\tLoss: 1553730304.000000\n",
      "Train Epoch: 373 [8530/11093 (91%)]\tLoss: 1337370179.826495\n",
      "Train Epoch: 374 [0/11093 (0%)]\tLoss: 1436565504.000000\n",
      "Train Epoch: 374 [5120/11093 (45%)]\tLoss: 1066779264.000000\n",
      "Train Epoch: 374 [8530/11093 (91%)]\tLoss: 1312545481.078546\n",
      "Train Epoch: 375 [0/11093 (0%)]\tLoss: 1308868096.000000\n",
      "Train Epoch: 375 [5120/11093 (45%)]\tLoss: 1613609472.000000\n",
      "Train Epoch: 375 [8530/11093 (91%)]\tLoss: 1181110459.273154\n",
      "Train Epoch: 376 [0/11093 (0%)]\tLoss: 1363961856.000000\n",
      "Train Epoch: 376 [5120/11093 (45%)]\tLoss: 1167837440.000000\n",
      "Train Epoch: 376 [8530/11093 (91%)]\tLoss: 1713192787.132474\n",
      "Train Epoch: 377 [0/11093 (0%)]\tLoss: 1511684864.000000\n",
      "Train Epoch: 377 [5120/11093 (45%)]\tLoss: 1354280960.000000\n",
      "Train Epoch: 377 [8530/11093 (91%)]\tLoss: 1269634075.610785\n",
      "Train Epoch: 378 [0/11093 (0%)]\tLoss: 1223074816.000000\n",
      "Train Epoch: 378 [5120/11093 (45%)]\tLoss: 1244292096.000000\n",
      "Train Epoch: 378 [8530/11093 (91%)]\tLoss: 1762708654.067995\n",
      "Train Epoch: 379 [0/11093 (0%)]\tLoss: 1392454656.000000\n",
      "Train Epoch: 379 [5120/11093 (45%)]\tLoss: 1228484352.000000\n",
      "Train Epoch: 379 [8530/11093 (91%)]\tLoss: 1152638716.698710\n",
      "Train Epoch: 380 [0/11093 (0%)]\tLoss: 1137643776.000000\n",
      "Train Epoch: 380 [5120/11093 (45%)]\tLoss: 1241201664.000000\n",
      "Train Epoch: 380 [8530/11093 (91%)]\tLoss: 1366598467.526377\n",
      "Train Epoch: 381 [0/11093 (0%)]\tLoss: 1144148224.000000\n",
      "Train Epoch: 381 [5120/11093 (45%)]\tLoss: 1320960256.000000\n",
      "Train Epoch: 381 [8530/11093 (91%)]\tLoss: 1312806703.118406\n",
      "Train Epoch: 382 [0/11093 (0%)]\tLoss: 1252134912.000000\n",
      "Train Epoch: 382 [5120/11093 (45%)]\tLoss: 1309717504.000000\n",
      "Train Epoch: 382 [8530/11093 (91%)]\tLoss: 1556187431.315357\n",
      "Train Epoch: 383 [0/11093 (0%)]\tLoss: 1088882048.000000\n",
      "Train Epoch: 383 [5120/11093 (45%)]\tLoss: 1356751488.000000\n",
      "Train Epoch: 383 [8530/11093 (91%)]\tLoss: 1634239808.525205\n",
      "Train Epoch: 384 [0/11093 (0%)]\tLoss: 1432643584.000000\n",
      "Train Epoch: 384 [5120/11093 (45%)]\tLoss: 1434157440.000000\n",
      "Train Epoch: 384 [8530/11093 (91%)]\tLoss: 1265163414.058617\n",
      "Train Epoch: 385 [0/11093 (0%)]\tLoss: 1513810816.000000\n",
      "Train Epoch: 385 [5120/11093 (45%)]\tLoss: 1007500160.000000\n",
      "Train Epoch: 385 [8530/11093 (91%)]\tLoss: 1202402206.762016\n",
      "Train Epoch: 386 [0/11093 (0%)]\tLoss: 1118486656.000000\n",
      "Train Epoch: 386 [5120/11093 (45%)]\tLoss: 1161607040.000000\n",
      "Train Epoch: 386 [8530/11093 (91%)]\tLoss: 1296743852.567409\n",
      "Train Epoch: 387 [0/11093 (0%)]\tLoss: 1266481920.000000\n",
      "Train Epoch: 387 [5120/11093 (45%)]\tLoss: 1079017984.000000\n",
      "Train Epoch: 387 [8530/11093 (91%)]\tLoss: 1344971741.186401\n",
      "Train Epoch: 388 [0/11093 (0%)]\tLoss: 1556319744.000000\n",
      "Train Epoch: 388 [5120/11093 (45%)]\tLoss: 1143678208.000000\n",
      "Train Epoch: 388 [8530/11093 (91%)]\tLoss: 1283355224.234467\n",
      "Train Epoch: 389 [0/11093 (0%)]\tLoss: 1436680064.000000\n",
      "Train Epoch: 389 [5120/11093 (45%)]\tLoss: 1263793408.000000\n",
      "Train Epoch: 389 [8530/11093 (91%)]\tLoss: 1300763752.440797\n",
      "Train Epoch: 390 [0/11093 (0%)]\tLoss: 1531331072.000000\n",
      "Train Epoch: 390 [5120/11093 (45%)]\tLoss: 1223235584.000000\n",
      "Train Epoch: 390 [8530/11093 (91%)]\tLoss: 1175282441.903869\n",
      "Train Epoch: 391 [0/11093 (0%)]\tLoss: 1123512320.000000\n",
      "Train Epoch: 391 [5120/11093 (45%)]\tLoss: 1100557056.000000\n",
      "Train Epoch: 391 [8530/11093 (91%)]\tLoss: 1214857350.452521\n",
      "Train Epoch: 392 [0/11093 (0%)]\tLoss: 1419868288.000000\n",
      "Train Epoch: 392 [5120/11093 (45%)]\tLoss: 1261842944.000000\n",
      "Train Epoch: 392 [8530/11093 (91%)]\tLoss: 1255106903.334115\n",
      "Train Epoch: 393 [0/11093 (0%)]\tLoss: 1272457728.000000\n",
      "Train Epoch: 393 [5120/11093 (45%)]\tLoss: 1295305728.000000\n",
      "Train Epoch: 393 [8530/11093 (91%)]\tLoss: 1628943301.177022\n",
      "Train Epoch: 394 [0/11093 (0%)]\tLoss: 1322779648.000000\n",
      "Train Epoch: 394 [5120/11093 (45%)]\tLoss: 1157350400.000000\n",
      "Train Epoch: 394 [8530/11093 (91%)]\tLoss: 1257879160.647128\n",
      "Train Epoch: 395 [0/11093 (0%)]\tLoss: 1213892352.000000\n",
      "Train Epoch: 395 [5120/11093 (45%)]\tLoss: 1510173184.000000\n",
      "Train Epoch: 395 [8530/11093 (91%)]\tLoss: 1250560564.220399\n",
      "Train Epoch: 396 [0/11093 (0%)]\tLoss: 1405661184.000000\n",
      "Train Epoch: 396 [5120/11093 (45%)]\tLoss: 1351841792.000000\n",
      "Train Epoch: 396 [8530/11093 (91%)]\tLoss: 1283276166.152403\n",
      "Train Epoch: 397 [0/11093 (0%)]\tLoss: 1290828160.000000\n",
      "Train Epoch: 397 [5120/11093 (45%)]\tLoss: 1610702464.000000\n",
      "Train Epoch: 397 [8530/11093 (91%)]\tLoss: 1206014907.573271\n",
      "Train Epoch: 398 [0/11093 (0%)]\tLoss: 1350689664.000000\n",
      "Train Epoch: 398 [5120/11093 (45%)]\tLoss: 1264948224.000000\n",
      "Train Epoch: 398 [8530/11093 (91%)]\tLoss: 1436804963.939039\n",
      "Train Epoch: 399 [0/11093 (0%)]\tLoss: 1170984448.000000\n",
      "Train Epoch: 399 [5120/11093 (45%)]\tLoss: 1329684736.000000\n",
      "Train Epoch: 399 [8530/11093 (91%)]\tLoss: 1195228588.567409\n",
      "Train Epoch: 400 [0/11093 (0%)]\tLoss: 1365264768.000000\n",
      "Train Epoch: 400 [5120/11093 (45%)]\tLoss: 1275117184.000000\n",
      "Train Epoch: 400 [8530/11093 (91%)]\tLoss: 1117288690.494725\n",
      "====> Epoch: 400 Average loss: 1292649616.2813\n",
      "Train Epoch: 401 [0/11093 (0%)]\tLoss: 1260931968.000000\n",
      "Train Epoch: 401 [5120/11093 (45%)]\tLoss: 1380798976.000000\n",
      "Train Epoch: 401 [8530/11093 (91%)]\tLoss: 1316011129.247362\n",
      "Train Epoch: 402 [0/11093 (0%)]\tLoss: 1138413824.000000\n",
      "Train Epoch: 402 [5120/11093 (45%)]\tLoss: 1295110912.000000\n",
      "Train Epoch: 402 [8530/11093 (91%)]\tLoss: 1205268888.159437\n",
      "Train Epoch: 403 [0/11093 (0%)]\tLoss: 1206472192.000000\n",
      "Train Epoch: 403 [5120/11093 (45%)]\tLoss: 1323104768.000000\n",
      "Train Epoch: 403 [8530/11093 (91%)]\tLoss: 1245407959.484174\n",
      "Train Epoch: 404 [0/11093 (0%)]\tLoss: 1216456192.000000\n",
      "Train Epoch: 404 [5120/11093 (45%)]\tLoss: 1237013632.000000\n",
      "Train Epoch: 404 [8530/11093 (91%)]\tLoss: 1223659688.065651\n",
      "Train Epoch: 405 [0/11093 (0%)]\tLoss: 1404150272.000000\n",
      "Train Epoch: 405 [5120/11093 (45%)]\tLoss: 1335585280.000000\n",
      "Train Epoch: 405 [8530/11093 (91%)]\tLoss: 1288343873.725674\n",
      "Train Epoch: 406 [0/11093 (0%)]\tLoss: 1240078592.000000\n",
      "Train Epoch: 406 [5120/11093 (45%)]\tLoss: 1186510080.000000\n",
      "Train Epoch: 406 [8530/11093 (91%)]\tLoss: 1158899824.844080\n",
      "Train Epoch: 407 [0/11093 (0%)]\tLoss: 1263854464.000000\n",
      "Train Epoch: 407 [5120/11093 (45%)]\tLoss: 1227459328.000000\n",
      "Train Epoch: 407 [8530/11093 (91%)]\tLoss: 1283616907.254396\n",
      "Train Epoch: 408 [0/11093 (0%)]\tLoss: 1378786176.000000\n",
      "Train Epoch: 408 [5120/11093 (45%)]\tLoss: 1191907328.000000\n",
      "Train Epoch: 408 [8530/11093 (91%)]\tLoss: 1360265216.000000\n",
      "Train Epoch: 409 [0/11093 (0%)]\tLoss: 1492562560.000000\n",
      "Train Epoch: 409 [5120/11093 (45%)]\tLoss: 1332893952.000000\n",
      "Train Epoch: 409 [8530/11093 (91%)]\tLoss: 1225199591.990621\n",
      "Train Epoch: 410 [0/11093 (0%)]\tLoss: 1524642432.000000\n",
      "Train Epoch: 410 [5120/11093 (45%)]\tLoss: 1228658560.000000\n",
      "Train Epoch: 410 [8530/11093 (91%)]\tLoss: 1287972170.128957\n",
      "Train Epoch: 411 [0/11093 (0%)]\tLoss: 1034652352.000000\n",
      "Train Epoch: 411 [5120/11093 (45%)]\tLoss: 1348529920.000000\n",
      "Train Epoch: 411 [8530/11093 (91%)]\tLoss: 1197577358.855803\n",
      "Train Epoch: 412 [0/11093 (0%)]\tLoss: 1264511232.000000\n",
      "Train Epoch: 412 [5120/11093 (45%)]\tLoss: 1157234176.000000\n",
      "Train Epoch: 412 [8530/11093 (91%)]\tLoss: 1332416948.970692\n",
      "Train Epoch: 413 [0/11093 (0%)]\tLoss: 1261063680.000000\n",
      "Train Epoch: 413 [5120/11093 (45%)]\tLoss: 1298294016.000000\n",
      "Train Epoch: 413 [8530/11093 (91%)]\tLoss: 1404215363.226260\n",
      "Train Epoch: 414 [0/11093 (0%)]\tLoss: 1370873600.000000\n",
      "Train Epoch: 414 [5120/11093 (45%)]\tLoss: 1255703296.000000\n",
      "Train Epoch: 414 [8530/11093 (91%)]\tLoss: 1077515406.855803\n",
      "Train Epoch: 415 [0/11093 (0%)]\tLoss: 1235675136.000000\n",
      "Train Epoch: 415 [5120/11093 (45%)]\tLoss: 1337106432.000000\n",
      "Train Epoch: 415 [8530/11093 (91%)]\tLoss: 1202245704.028136\n",
      "Train Epoch: 416 [0/11093 (0%)]\tLoss: 1213873920.000000\n",
      "Train Epoch: 416 [5120/11093 (45%)]\tLoss: 1209825152.000000\n",
      "Train Epoch: 416 [8530/11093 (91%)]\tLoss: 1264882907.685815\n",
      "Train Epoch: 417 [0/11093 (0%)]\tLoss: 1245788288.000000\n",
      "Train Epoch: 417 [5120/11093 (45%)]\tLoss: 1274038784.000000\n",
      "Train Epoch: 417 [8530/11093 (91%)]\tLoss: 1133142409.753810\n",
      "Train Epoch: 418 [0/11093 (0%)]\tLoss: 1174678272.000000\n",
      "Train Epoch: 418 [5120/11093 (45%)]\tLoss: 1357611520.000000\n",
      "Train Epoch: 418 [8530/11093 (91%)]\tLoss: 1206574306.888628\n",
      "Train Epoch: 419 [0/11093 (0%)]\tLoss: 1378475520.000000\n",
      "Train Epoch: 419 [5120/11093 (45%)]\tLoss: 1429553152.000000\n",
      "Train Epoch: 419 [8530/11093 (91%)]\tLoss: 1358906246.752638\n",
      "Train Epoch: 420 [0/11093 (0%)]\tLoss: 1306010368.000000\n",
      "Train Epoch: 420 [5120/11093 (45%)]\tLoss: 1212318464.000000\n",
      "Train Epoch: 420 [8530/11093 (91%)]\tLoss: 1251180121.434936\n",
      "Train Epoch: 421 [0/11093 (0%)]\tLoss: 1120278016.000000\n",
      "Train Epoch: 421 [5120/11093 (45%)]\tLoss: 1248850816.000000\n",
      "Train Epoch: 421 [8530/11093 (91%)]\tLoss: 1140305655.896835\n",
      "Train Epoch: 422 [0/11093 (0%)]\tLoss: 1225145856.000000\n",
      "Train Epoch: 422 [5120/11093 (45%)]\tLoss: 1222578816.000000\n",
      "Train Epoch: 422 [8530/11093 (91%)]\tLoss: 1305596974.818288\n",
      "Train Epoch: 423 [0/11093 (0%)]\tLoss: 1064863360.000000\n",
      "Train Epoch: 423 [5120/11093 (45%)]\tLoss: 1285581824.000000\n",
      "Train Epoch: 423 [8530/11093 (91%)]\tLoss: 1261255839.662368\n",
      "Train Epoch: 424 [0/11093 (0%)]\tLoss: 1394141440.000000\n",
      "Train Epoch: 424 [5120/11093 (45%)]\tLoss: 1210790528.000000\n",
      "Train Epoch: 424 [8530/11093 (91%)]\tLoss: 1594181101.392731\n",
      "Train Epoch: 425 [0/11093 (0%)]\tLoss: 1232291840.000000\n",
      "Train Epoch: 425 [5120/11093 (45%)]\tLoss: 1408566144.000000\n",
      "Train Epoch: 425 [8530/11093 (91%)]\tLoss: 1236779334.527550\n",
      "Train Epoch: 426 [0/11093 (0%)]\tLoss: 1310430208.000000\n",
      "Train Epoch: 426 [5120/11093 (45%)]\tLoss: 1293885696.000000\n",
      "Train Epoch: 426 [8530/11093 (91%)]\tLoss: 1098093326.705745\n",
      "Train Epoch: 427 [0/11093 (0%)]\tLoss: 1469447168.000000\n",
      "Train Epoch: 427 [5120/11093 (45%)]\tLoss: 1148250368.000000\n",
      "Train Epoch: 427 [8530/11093 (91%)]\tLoss: 1477765962.729191\n",
      "Train Epoch: 428 [0/11093 (0%)]\tLoss: 1242619392.000000\n",
      "Train Epoch: 428 [5120/11093 (45%)]\tLoss: 1329275648.000000\n",
      "Train Epoch: 428 [8530/11093 (91%)]\tLoss: 1094598867.282532\n",
      "Train Epoch: 429 [0/11093 (0%)]\tLoss: 1576200704.000000\n",
      "Train Epoch: 429 [5120/11093 (45%)]\tLoss: 1237690624.000000\n",
      "Train Epoch: 429 [8530/11093 (91%)]\tLoss: 1377958399.399765\n",
      "Train Epoch: 430 [0/11093 (0%)]\tLoss: 1549967104.000000\n",
      "Train Epoch: 430 [5120/11093 (45%)]\tLoss: 1244347648.000000\n",
      "Train Epoch: 430 [8530/11093 (91%)]\tLoss: 1357630714.898007\n",
      "Train Epoch: 431 [0/11093 (0%)]\tLoss: 1262182144.000000\n",
      "Train Epoch: 431 [5120/11093 (45%)]\tLoss: 1326401024.000000\n",
      "Train Epoch: 431 [8530/11093 (91%)]\tLoss: 1304414407.277843\n",
      "Train Epoch: 432 [0/11093 (0%)]\tLoss: 1273839488.000000\n",
      "Train Epoch: 432 [5120/11093 (45%)]\tLoss: 1194587648.000000\n",
      "Train Epoch: 432 [8530/11093 (91%)]\tLoss: 1388110563.488863\n",
      "Train Epoch: 433 [0/11093 (0%)]\tLoss: 1106284800.000000\n",
      "Train Epoch: 433 [5120/11093 (45%)]\tLoss: 1189908480.000000\n",
      "Train Epoch: 433 [8530/11093 (91%)]\tLoss: 1229107934.686987\n",
      "Train Epoch: 434 [0/11093 (0%)]\tLoss: 1104269056.000000\n",
      "Train Epoch: 434 [5120/11093 (45%)]\tLoss: 1347554176.000000\n",
      "Train Epoch: 434 [8530/11093 (91%)]\tLoss: 1361200237.242673\n",
      "Train Epoch: 435 [0/11093 (0%)]\tLoss: 1216027904.000000\n",
      "Train Epoch: 435 [5120/11093 (45%)]\tLoss: 1206219264.000000\n",
      "Train Epoch: 435 [8530/11093 (91%)]\tLoss: 1315002197.533412\n",
      "Train Epoch: 436 [0/11093 (0%)]\tLoss: 1197434368.000000\n",
      "Train Epoch: 436 [5120/11093 (45%)]\tLoss: 1253713152.000000\n",
      "Train Epoch: 436 [8530/11093 (91%)]\tLoss: 1052880785.556858\n",
      "Train Epoch: 437 [0/11093 (0%)]\tLoss: 1635468800.000000\n",
      "Train Epoch: 437 [5120/11093 (45%)]\tLoss: 1173324416.000000\n",
      "Train Epoch: 437 [8530/11093 (91%)]\tLoss: 1281176555.592028\n",
      "Train Epoch: 438 [0/11093 (0%)]\tLoss: 1198485504.000000\n",
      "Train Epoch: 438 [5120/11093 (45%)]\tLoss: 1238687744.000000\n",
      "Train Epoch: 438 [8530/11093 (91%)]\tLoss: 1211756183.859320\n",
      "Train Epoch: 439 [0/11093 (0%)]\tLoss: 1285524736.000000\n",
      "Train Epoch: 439 [5120/11093 (45%)]\tLoss: 1475204480.000000\n",
      "Train Epoch: 439 [8530/11093 (91%)]\tLoss: 1250847831.634232\n",
      "Train Epoch: 440 [0/11093 (0%)]\tLoss: 1234742016.000000\n",
      "Train Epoch: 440 [5120/11093 (45%)]\tLoss: 1332257792.000000\n",
      "Train Epoch: 440 [8530/11093 (91%)]\tLoss: 1494021963.929660\n",
      "Train Epoch: 441 [0/11093 (0%)]\tLoss: 1202665728.000000\n",
      "Train Epoch: 441 [5120/11093 (45%)]\tLoss: 1481289472.000000\n",
      "Train Epoch: 441 [8530/11093 (91%)]\tLoss: 1477139029.833529\n",
      "Train Epoch: 442 [0/11093 (0%)]\tLoss: 1357080576.000000\n",
      "Train Epoch: 442 [5120/11093 (45%)]\tLoss: 1147676800.000000\n",
      "Train Epoch: 442 [8530/11093 (91%)]\tLoss: 1332265440.187573\n",
      "Train Epoch: 443 [0/11093 (0%)]\tLoss: 1392346752.000000\n",
      "Train Epoch: 443 [5120/11093 (45%)]\tLoss: 1207738240.000000\n",
      "Train Epoch: 443 [8530/11093 (91%)]\tLoss: 1325948015.643611\n",
      "Train Epoch: 444 [0/11093 (0%)]\tLoss: 1139613568.000000\n",
      "Train Epoch: 444 [5120/11093 (45%)]\tLoss: 1338897920.000000\n",
      "Train Epoch: 444 [8530/11093 (91%)]\tLoss: 1338884038.377491\n",
      "Train Epoch: 445 [0/11093 (0%)]\tLoss: 1173333376.000000\n",
      "Train Epoch: 445 [5120/11093 (45%)]\tLoss: 1329985280.000000\n",
      "Train Epoch: 445 [8530/11093 (91%)]\tLoss: 1266052721.444314\n",
      "Train Epoch: 446 [0/11093 (0%)]\tLoss: 1583645696.000000\n",
      "Train Epoch: 446 [5120/11093 (45%)]\tLoss: 1183104512.000000\n",
      "Train Epoch: 446 [8530/11093 (91%)]\tLoss: 1128106202.485346\n",
      "Train Epoch: 447 [0/11093 (0%)]\tLoss: 1496619520.000000\n",
      "Train Epoch: 447 [5120/11093 (45%)]\tLoss: 1261728896.000000\n",
      "Train Epoch: 447 [8530/11093 (91%)]\tLoss: 1168030072.947245\n",
      "Train Epoch: 448 [0/11093 (0%)]\tLoss: 1489344384.000000\n",
      "Train Epoch: 448 [5120/11093 (45%)]\tLoss: 1276023936.000000\n",
      "Train Epoch: 448 [8530/11093 (91%)]\tLoss: 1203682271.587339\n",
      "Train Epoch: 449 [0/11093 (0%)]\tLoss: 1366069632.000000\n",
      "Train Epoch: 449 [5120/11093 (45%)]\tLoss: 1341998592.000000\n",
      "Train Epoch: 449 [8530/11093 (91%)]\tLoss: 1368232027.235639\n",
      "Train Epoch: 450 [0/11093 (0%)]\tLoss: 1067029120.000000\n",
      "Train Epoch: 450 [5120/11093 (45%)]\tLoss: 1517244928.000000\n",
      "Train Epoch: 450 [8530/11093 (91%)]\tLoss: 1450391429.552169\n",
      "Train Epoch: 451 [0/11093 (0%)]\tLoss: 1156323072.000000\n",
      "Train Epoch: 451 [5120/11093 (45%)]\tLoss: 1372631296.000000\n",
      "Train Epoch: 451 [8530/11093 (91%)]\tLoss: 1302709549.317702\n",
      "Train Epoch: 452 [0/11093 (0%)]\tLoss: 1178181248.000000\n",
      "Train Epoch: 452 [5120/11093 (45%)]\tLoss: 1176314368.000000\n",
      "Train Epoch: 452 [8530/11093 (91%)]\tLoss: 1331208720.206331\n",
      "Train Epoch: 453 [0/11093 (0%)]\tLoss: 1654236928.000000\n",
      "Train Epoch: 453 [5120/11093 (45%)]\tLoss: 1199189504.000000\n",
      "Train Epoch: 453 [8530/11093 (91%)]\tLoss: 1239765332.933177\n",
      "Train Epoch: 454 [0/11093 (0%)]\tLoss: 1263449472.000000\n",
      "Train Epoch: 454 [5120/11093 (45%)]\tLoss: 1172541696.000000\n",
      "Train Epoch: 454 [8530/11093 (91%)]\tLoss: 1396992266.504103\n",
      "Train Epoch: 455 [0/11093 (0%)]\tLoss: 1219634304.000000\n",
      "Train Epoch: 455 [5120/11093 (45%)]\tLoss: 1203617792.000000\n",
      "Train Epoch: 455 [8530/11093 (91%)]\tLoss: 1148442722.438452\n",
      "Train Epoch: 456 [0/11093 (0%)]\tLoss: 1196795520.000000\n",
      "Train Epoch: 456 [5120/11093 (45%)]\tLoss: 1179745024.000000\n",
      "Train Epoch: 456 [8530/11093 (91%)]\tLoss: 1293558941.261430\n",
      "Train Epoch: 457 [0/11093 (0%)]\tLoss: 1362206848.000000\n",
      "Train Epoch: 457 [5120/11093 (45%)]\tLoss: 1440987776.000000\n",
      "Train Epoch: 457 [8530/11093 (91%)]\tLoss: 1566806721.875733\n",
      "Train Epoch: 458 [0/11093 (0%)]\tLoss: 1397307776.000000\n",
      "Train Epoch: 458 [5120/11093 (45%)]\tLoss: 1148518144.000000\n",
      "Train Epoch: 458 [8530/11093 (91%)]\tLoss: 1257489555.657679\n",
      "Train Epoch: 459 [0/11093 (0%)]\tLoss: 1447007744.000000\n",
      "Train Epoch: 459 [5120/11093 (45%)]\tLoss: 1226694144.000000\n",
      "Train Epoch: 459 [8530/11093 (91%)]\tLoss: 1369775542.171161\n",
      "Train Epoch: 460 [0/11093 (0%)]\tLoss: 1122007808.000000\n",
      "Train Epoch: 460 [5120/11093 (45%)]\tLoss: 1563710208.000000\n",
      "Train Epoch: 460 [8530/11093 (91%)]\tLoss: 1241158875.685815\n",
      "Train Epoch: 461 [0/11093 (0%)]\tLoss: 1260308864.000000\n",
      "Train Epoch: 461 [5120/11093 (45%)]\tLoss: 1280621824.000000\n",
      "Train Epoch: 461 [8530/11093 (91%)]\tLoss: 1272973568.900352\n",
      "Train Epoch: 462 [0/11093 (0%)]\tLoss: 1086111488.000000\n",
      "Train Epoch: 462 [5120/11093 (45%)]\tLoss: 1346347136.000000\n",
      "Train Epoch: 462 [8530/11093 (91%)]\tLoss: 1185686685.261430\n",
      "Train Epoch: 463 [0/11093 (0%)]\tLoss: 1371161472.000000\n",
      "Train Epoch: 463 [5120/11093 (45%)]\tLoss: 1312273664.000000\n",
      "Train Epoch: 463 [8530/11093 (91%)]\tLoss: 1325212906.091442\n",
      "Train Epoch: 464 [0/11093 (0%)]\tLoss: 1249235456.000000\n",
      "Train Epoch: 464 [5120/11093 (45%)]\tLoss: 1280857600.000000\n",
      "Train Epoch: 464 [8530/11093 (91%)]\tLoss: 1597346958.855803\n",
      "Train Epoch: 465 [0/11093 (0%)]\tLoss: 1240436992.000000\n",
      "Train Epoch: 465 [5120/11093 (45%)]\tLoss: 1179260672.000000\n",
      "Train Epoch: 465 [8530/11093 (91%)]\tLoss: 1188326564.464244\n",
      "Train Epoch: 466 [0/11093 (0%)]\tLoss: 1279825280.000000\n",
      "Train Epoch: 466 [5120/11093 (45%)]\tLoss: 1506842368.000000\n",
      "Train Epoch: 466 [8530/11093 (91%)]\tLoss: 1278425887.512310\n",
      "Train Epoch: 467 [0/11093 (0%)]\tLoss: 1343866368.000000\n",
      "Train Epoch: 467 [5120/11093 (45%)]\tLoss: 1203039488.000000\n",
      "Train Epoch: 467 [8530/11093 (91%)]\tLoss: 1445620746.804220\n",
      "Train Epoch: 468 [0/11093 (0%)]\tLoss: 1297690752.000000\n",
      "Train Epoch: 468 [5120/11093 (45%)]\tLoss: 1366156800.000000\n",
      "Train Epoch: 468 [8530/11093 (91%)]\tLoss: 1725337768.065651\n",
      "Train Epoch: 469 [0/11093 (0%)]\tLoss: 1147480576.000000\n",
      "Train Epoch: 469 [5120/11093 (45%)]\tLoss: 1297823616.000000\n",
      "Train Epoch: 469 [8530/11093 (91%)]\tLoss: 1165764663.221571\n",
      "Train Epoch: 470 [0/11093 (0%)]\tLoss: 1438870784.000000\n",
      "Train Epoch: 470 [5120/11093 (45%)]\tLoss: 1116046848.000000\n",
      "Train Epoch: 470 [8530/11093 (91%)]\tLoss: 1256359463.015240\n",
      "Train Epoch: 471 [0/11093 (0%)]\tLoss: 1248686848.000000\n",
      "Train Epoch: 471 [5120/11093 (45%)]\tLoss: 1543944960.000000\n",
      "Train Epoch: 471 [8530/11093 (91%)]\tLoss: 1426238532.426729\n",
      "Train Epoch: 472 [0/11093 (0%)]\tLoss: 1426118400.000000\n",
      "Train Epoch: 472 [5120/11093 (45%)]\tLoss: 1143448192.000000\n",
      "Train Epoch: 472 [8530/11093 (91%)]\tLoss: 1173439904.562720\n",
      "Train Epoch: 473 [0/11093 (0%)]\tLoss: 1418485376.000000\n",
      "Train Epoch: 473 [5120/11093 (45%)]\tLoss: 1188627200.000000\n",
      "Train Epoch: 473 [8530/11093 (91%)]\tLoss: 1283593243.610785\n",
      "Train Epoch: 474 [0/11093 (0%)]\tLoss: 1594729984.000000\n",
      "Train Epoch: 474 [5120/11093 (45%)]\tLoss: 1170797312.000000\n",
      "Train Epoch: 474 [8530/11093 (91%)]\tLoss: 1335017798.527550\n",
      "Train Epoch: 475 [0/11093 (0%)]\tLoss: 1149585792.000000\n",
      "Train Epoch: 475 [5120/11093 (45%)]\tLoss: 1261258752.000000\n",
      "Train Epoch: 475 [8530/11093 (91%)]\tLoss: 1263805750.921454\n",
      "Train Epoch: 476 [0/11093 (0%)]\tLoss: 1084631808.000000\n",
      "Train Epoch: 476 [5120/11093 (45%)]\tLoss: 1039834112.000000\n",
      "Train Epoch: 476 [8530/11093 (91%)]\tLoss: 1277778287.343493\n",
      "Train Epoch: 477 [0/11093 (0%)]\tLoss: 1309510400.000000\n",
      "Train Epoch: 477 [5120/11093 (45%)]\tLoss: 1113781504.000000\n",
      "Train Epoch: 477 [8530/11093 (91%)]\tLoss: 1383875232.262603\n",
      "Train Epoch: 478 [0/11093 (0%)]\tLoss: 1148039936.000000\n",
      "Train Epoch: 478 [5120/11093 (45%)]\tLoss: 1420330624.000000\n",
      "Train Epoch: 478 [8530/11093 (91%)]\tLoss: 1401375265.012896\n",
      "Train Epoch: 479 [0/11093 (0%)]\tLoss: 1247679232.000000\n",
      "Train Epoch: 479 [5120/11093 (45%)]\tLoss: 1312142592.000000\n",
      "Train Epoch: 479 [8530/11093 (91%)]\tLoss: 1156492586.916764\n",
      "Train Epoch: 480 [0/11093 (0%)]\tLoss: 1042278144.000000\n",
      "Train Epoch: 480 [5120/11093 (45%)]\tLoss: 1300202112.000000\n",
      "Train Epoch: 480 [8530/11093 (91%)]\tLoss: 1586360881.819461\n",
      "Train Epoch: 481 [0/11093 (0%)]\tLoss: 1087688448.000000\n",
      "Train Epoch: 481 [5120/11093 (45%)]\tLoss: 1344708992.000000\n",
      "Train Epoch: 481 [8530/11093 (91%)]\tLoss: 1072767926.771395\n",
      "Train Epoch: 482 [0/11093 (0%)]\tLoss: 1058322048.000000\n",
      "Train Epoch: 482 [5120/11093 (45%)]\tLoss: 1235861504.000000\n",
      "Train Epoch: 482 [8530/11093 (91%)]\tLoss: 1247090152.590856\n",
      "Train Epoch: 483 [0/11093 (0%)]\tLoss: 1116257280.000000\n",
      "Train Epoch: 483 [5120/11093 (45%)]\tLoss: 1179580672.000000\n",
      "Train Epoch: 483 [8530/11093 (91%)]\tLoss: 1100297810.232122\n",
      "Train Epoch: 484 [0/11093 (0%)]\tLoss: 1544633856.000000\n",
      "Train Epoch: 484 [5120/11093 (45%)]\tLoss: 1349124096.000000\n",
      "Train Epoch: 484 [8530/11093 (91%)]\tLoss: 1177389043.995311\n",
      "Train Epoch: 485 [0/11093 (0%)]\tLoss: 1233179648.000000\n",
      "Train Epoch: 485 [5120/11093 (45%)]\tLoss: 1395878016.000000\n",
      "Train Epoch: 485 [8530/11093 (91%)]\tLoss: 1269145052.586166\n",
      "Train Epoch: 486 [0/11093 (0%)]\tLoss: 1235824896.000000\n",
      "Train Epoch: 486 [5120/11093 (45%)]\tLoss: 1270081792.000000\n",
      "Train Epoch: 486 [8530/11093 (91%)]\tLoss: 1345821788.436108\n",
      "Train Epoch: 487 [0/11093 (0%)]\tLoss: 1172096512.000000\n",
      "Train Epoch: 487 [5120/11093 (45%)]\tLoss: 1208373376.000000\n",
      "Train Epoch: 487 [8530/11093 (91%)]\tLoss: 1243950570.991794\n",
      "Train Epoch: 488 [0/11093 (0%)]\tLoss: 1382819712.000000\n",
      "Train Epoch: 488 [5120/11093 (45%)]\tLoss: 1215266816.000000\n",
      "Train Epoch: 488 [8530/11093 (91%)]\tLoss: 1185012271.418523\n",
      "Train Epoch: 489 [0/11093 (0%)]\tLoss: 1163491072.000000\n",
      "Train Epoch: 489 [5120/11093 (45%)]\tLoss: 1356872320.000000\n",
      "Train Epoch: 489 [8530/11093 (91%)]\tLoss: 1330496659.657679\n",
      "Train Epoch: 490 [0/11093 (0%)]\tLoss: 1161435904.000000\n",
      "Train Epoch: 490 [5120/11093 (45%)]\tLoss: 1149338112.000000\n",
      "Train Epoch: 490 [8530/11093 (91%)]\tLoss: 1540985537.875733\n",
      "Train Epoch: 491 [0/11093 (0%)]\tLoss: 1276881920.000000\n",
      "Train Epoch: 491 [5120/11093 (45%)]\tLoss: 1490684928.000000\n",
      "Train Epoch: 491 [8530/11093 (91%)]\tLoss: 1580155782.752638\n",
      "Train Epoch: 492 [0/11093 (0%)]\tLoss: 1184299264.000000\n",
      "Train Epoch: 492 [5120/11093 (45%)]\tLoss: 1181833984.000000\n",
      "Train Epoch: 492 [8530/11093 (91%)]\tLoss: 1307732849.144197\n",
      "Train Epoch: 493 [0/11093 (0%)]\tLoss: 1194483968.000000\n",
      "Train Epoch: 493 [5120/11093 (45%)]\tLoss: 1432732416.000000\n",
      "Train Epoch: 493 [8530/11093 (91%)]\tLoss: 1227387249.744431\n",
      "Train Epoch: 494 [0/11093 (0%)]\tLoss: 1248552832.000000\n",
      "Train Epoch: 494 [5120/11093 (45%)]\tLoss: 1036427008.000000\n",
      "Train Epoch: 494 [8530/11093 (91%)]\tLoss: 1351165008.431418\n",
      "Train Epoch: 495 [0/11093 (0%)]\tLoss: 1195323136.000000\n",
      "Train Epoch: 495 [5120/11093 (45%)]\tLoss: 1236165760.000000\n",
      "Train Epoch: 495 [8530/11093 (91%)]\tLoss: 1191400610.063306\n",
      "Train Epoch: 496 [0/11093 (0%)]\tLoss: 1148399872.000000\n",
      "Train Epoch: 496 [5120/11093 (45%)]\tLoss: 1397462016.000000\n",
      "Train Epoch: 496 [8530/11093 (91%)]\tLoss: 1356647905.388042\n",
      "Train Epoch: 497 [0/11093 (0%)]\tLoss: 1319910400.000000\n",
      "Train Epoch: 497 [5120/11093 (45%)]\tLoss: 1206845184.000000\n",
      "Train Epoch: 497 [8530/11093 (91%)]\tLoss: 1386277553.069168\n",
      "Train Epoch: 498 [0/11093 (0%)]\tLoss: 1400444800.000000\n",
      "Train Epoch: 498 [5120/11093 (45%)]\tLoss: 1303569408.000000\n",
      "Train Epoch: 498 [8530/11093 (91%)]\tLoss: 1111347809.838218\n",
      "Train Epoch: 499 [0/11093 (0%)]\tLoss: 1428721536.000000\n",
      "Train Epoch: 499 [5120/11093 (45%)]\tLoss: 1169521152.000000\n",
      "Train Epoch: 499 [8530/11093 (91%)]\tLoss: 1118969500.661196\n",
      "Train Epoch: 500 [0/11093 (0%)]\tLoss: 1169975424.000000\n",
      "Train Epoch: 500 [5120/11093 (45%)]\tLoss: 1250059264.000000\n",
      "Train Epoch: 500 [8530/11093 (91%)]\tLoss: 1128890329.584994\n",
      "Train Epoch: 501 [0/11093 (0%)]\tLoss: 1041382272.000000\n",
      "Train Epoch: 501 [5120/11093 (45%)]\tLoss: 1302776320.000000\n",
      "Train Epoch: 501 [8530/11093 (91%)]\tLoss: 1190259300.239156\n",
      "Train Epoch: 502 [0/11093 (0%)]\tLoss: 1427403264.000000\n",
      "Train Epoch: 502 [5120/11093 (45%)]\tLoss: 1341292544.000000\n",
      "Train Epoch: 502 [8530/11093 (91%)]\tLoss: 1293739491.788980\n",
      "Train Epoch: 503 [0/11093 (0%)]\tLoss: 1342914816.000000\n",
      "Train Epoch: 503 [5120/11093 (45%)]\tLoss: 1396697088.000000\n",
      "Train Epoch: 503 [8530/11093 (91%)]\tLoss: 1624522348.642438\n",
      "Train Epoch: 504 [0/11093 (0%)]\tLoss: 1210561152.000000\n",
      "Train Epoch: 504 [5120/11093 (45%)]\tLoss: 1067486592.000000\n",
      "Train Epoch: 504 [8530/11093 (91%)]\tLoss: 1211430194.119578\n",
      "Train Epoch: 505 [0/11093 (0%)]\tLoss: 1475507840.000000\n",
      "Train Epoch: 505 [5120/11093 (45%)]\tLoss: 1077112320.000000\n",
      "Train Epoch: 505 [8530/11093 (91%)]\tLoss: 1245631304.328253\n",
      "Train Epoch: 506 [0/11093 (0%)]\tLoss: 1398376960.000000\n",
      "Train Epoch: 506 [5120/11093 (45%)]\tLoss: 1273786624.000000\n",
      "Train Epoch: 506 [8530/11093 (91%)]\tLoss: 1639174446.518171\n",
      "Train Epoch: 507 [0/11093 (0%)]\tLoss: 1573022720.000000\n",
      "Train Epoch: 507 [5120/11093 (45%)]\tLoss: 1241336320.000000\n",
      "Train Epoch: 507 [8530/11093 (91%)]\tLoss: 1141953966.968347\n",
      "Train Epoch: 508 [0/11093 (0%)]\tLoss: 1358932224.000000\n",
      "Train Epoch: 508 [5120/11093 (45%)]\tLoss: 1414834944.000000\n",
      "Train Epoch: 508 [8530/11093 (91%)]\tLoss: 1367688070.752638\n",
      "Train Epoch: 509 [0/11093 (0%)]\tLoss: 1216759680.000000\n",
      "Train Epoch: 509 [5120/11093 (45%)]\tLoss: 1419977984.000000\n",
      "Train Epoch: 509 [8530/11093 (91%)]\tLoss: 1146483249.819461\n",
      "Train Epoch: 510 [0/11093 (0%)]\tLoss: 1175721600.000000\n",
      "Train Epoch: 510 [5120/11093 (45%)]\tLoss: 1390703232.000000\n",
      "Train Epoch: 510 [8530/11093 (91%)]\tLoss: 1285586214.114889\n",
      "Train Epoch: 511 [0/11093 (0%)]\tLoss: 1274318208.000000\n",
      "Train Epoch: 511 [5120/11093 (45%)]\tLoss: 1291827584.000000\n",
      "Train Epoch: 511 [8530/11093 (91%)]\tLoss: 1176015938.025791\n",
      "Train Epoch: 512 [0/11093 (0%)]\tLoss: 1153838208.000000\n",
      "Train Epoch: 512 [5120/11093 (45%)]\tLoss: 1064117952.000000\n",
      "Train Epoch: 512 [8530/11093 (91%)]\tLoss: 1195781073.181712\n",
      "Train Epoch: 513 [0/11093 (0%)]\tLoss: 1287229440.000000\n",
      "Train Epoch: 513 [5120/11093 (45%)]\tLoss: 1163683456.000000\n",
      "Train Epoch: 513 [8530/11093 (91%)]\tLoss: 1332393899.967175\n",
      "Train Epoch: 514 [0/11093 (0%)]\tLoss: 1333997056.000000\n",
      "Train Epoch: 514 [5120/11093 (45%)]\tLoss: 1540601088.000000\n",
      "Train Epoch: 514 [8530/11093 (91%)]\tLoss: 1351676849.969519\n",
      "Train Epoch: 515 [0/11093 (0%)]\tLoss: 1381519616.000000\n",
      "Train Epoch: 515 [5120/11093 (45%)]\tLoss: 1145933056.000000\n",
      "Train Epoch: 515 [8530/11093 (91%)]\tLoss: 1525234924.492380\n",
      "Train Epoch: 516 [0/11093 (0%)]\tLoss: 1208153600.000000\n",
      "Train Epoch: 516 [5120/11093 (45%)]\tLoss: 1212812800.000000\n",
      "Train Epoch: 516 [8530/11093 (91%)]\tLoss: 1382457718.546307\n",
      "Train Epoch: 517 [0/11093 (0%)]\tLoss: 1208536832.000000\n",
      "Train Epoch: 517 [5120/11093 (45%)]\tLoss: 1325064960.000000\n",
      "Train Epoch: 517 [8530/11093 (91%)]\tLoss: 1199923286.433763\n",
      "Train Epoch: 518 [0/11093 (0%)]\tLoss: 1321593088.000000\n",
      "Train Epoch: 518 [5120/11093 (45%)]\tLoss: 1530344448.000000\n",
      "Train Epoch: 518 [8530/11093 (91%)]\tLoss: 1304736171.366940\n",
      "Train Epoch: 519 [0/11093 (0%)]\tLoss: 1132571264.000000\n",
      "Train Epoch: 519 [5120/11093 (45%)]\tLoss: 1339965440.000000\n",
      "Train Epoch: 519 [8530/11093 (91%)]\tLoss: 1228344859.010551\n",
      "Train Epoch: 520 [0/11093 (0%)]\tLoss: 1084760064.000000\n",
      "Train Epoch: 520 [5120/11093 (45%)]\tLoss: 1518322688.000000\n",
      "Train Epoch: 520 [8530/11093 (91%)]\tLoss: 1247353372.211020\n",
      "Train Epoch: 521 [0/11093 (0%)]\tLoss: 1157242880.000000\n",
      "Train Epoch: 521 [5120/11093 (45%)]\tLoss: 1195827456.000000\n",
      "Train Epoch: 521 [8530/11093 (91%)]\tLoss: 1171400912.881594\n",
      "Train Epoch: 522 [0/11093 (0%)]\tLoss: 1209354880.000000\n",
      "Train Epoch: 522 [5120/11093 (45%)]\tLoss: 1254544640.000000\n",
      "Train Epoch: 522 [8530/11093 (91%)]\tLoss: 1203645239.521688\n",
      "Train Epoch: 523 [0/11093 (0%)]\tLoss: 1555262592.000000\n",
      "Train Epoch: 523 [5120/11093 (45%)]\tLoss: 1240392832.000000\n",
      "Train Epoch: 523 [8530/11093 (91%)]\tLoss: 1164159530.616647\n",
      "Train Epoch: 524 [0/11093 (0%)]\tLoss: 1236339456.000000\n",
      "Train Epoch: 524 [5120/11093 (45%)]\tLoss: 1148005120.000000\n",
      "Train Epoch: 524 [8530/11093 (91%)]\tLoss: 1344894603.854631\n",
      "Train Epoch: 525 [0/11093 (0%)]\tLoss: 1259739392.000000\n",
      "Train Epoch: 525 [5120/11093 (45%)]\tLoss: 1471254528.000000\n",
      "Train Epoch: 525 [8530/11093 (91%)]\tLoss: 1341983361.050410\n",
      "Train Epoch: 526 [0/11093 (0%)]\tLoss: 1281502720.000000\n",
      "Train Epoch: 526 [5120/11093 (45%)]\tLoss: 1352720256.000000\n",
      "Train Epoch: 526 [8530/11093 (91%)]\tLoss: 1437941279.812427\n",
      "Train Epoch: 527 [0/11093 (0%)]\tLoss: 1192388608.000000\n",
      "Train Epoch: 527 [5120/11093 (45%)]\tLoss: 1289186816.000000\n",
      "Train Epoch: 527 [8530/11093 (91%)]\tLoss: 1397347067.498241\n",
      "Train Epoch: 528 [0/11093 (0%)]\tLoss: 1232498816.000000\n",
      "Train Epoch: 528 [5120/11093 (45%)]\tLoss: 1116175616.000000\n",
      "Train Epoch: 528 [8530/11093 (91%)]\tLoss: 1414434062.105510\n",
      "Train Epoch: 529 [0/11093 (0%)]\tLoss: 1319163008.000000\n",
      "Train Epoch: 529 [5120/11093 (45%)]\tLoss: 1372299136.000000\n",
      "Train Epoch: 529 [8530/11093 (91%)]\tLoss: 1290712542.987104\n",
      "Train Epoch: 530 [0/11093 (0%)]\tLoss: 1492277888.000000\n",
      "Train Epoch: 530 [5120/11093 (45%)]\tLoss: 1277705216.000000\n",
      "Train Epoch: 530 [8530/11093 (91%)]\tLoss: 1096916521.416178\n",
      "Train Epoch: 531 [0/11093 (0%)]\tLoss: 1230471680.000000\n",
      "Train Epoch: 531 [5120/11093 (45%)]\tLoss: 1220235392.000000\n",
      "Train Epoch: 531 [8530/11093 (91%)]\tLoss: 1303017023.024619\n",
      "Train Epoch: 532 [0/11093 (0%)]\tLoss: 1221144192.000000\n",
      "Train Epoch: 532 [5120/11093 (45%)]\tLoss: 1396934400.000000\n",
      "Train Epoch: 532 [8530/11093 (91%)]\tLoss: 1305150438.790152\n",
      "Train Epoch: 533 [0/11093 (0%)]\tLoss: 1138838912.000000\n",
      "Train Epoch: 533 [5120/11093 (45%)]\tLoss: 1397205376.000000\n",
      "Train Epoch: 533 [8530/11093 (91%)]\tLoss: 1152593386.991794\n",
      "Train Epoch: 534 [0/11093 (0%)]\tLoss: 1248897024.000000\n",
      "Train Epoch: 534 [5120/11093 (45%)]\tLoss: 1310619648.000000\n",
      "Train Epoch: 534 [8530/11093 (91%)]\tLoss: 1494755536.881594\n",
      "Train Epoch: 535 [0/11093 (0%)]\tLoss: 1224503296.000000\n",
      "Train Epoch: 535 [5120/11093 (45%)]\tLoss: 1271317632.000000\n",
      "Train Epoch: 535 [8530/11093 (91%)]\tLoss: 1280833893.739742\n",
      "Train Epoch: 536 [0/11093 (0%)]\tLoss: 1303260928.000000\n",
      "Train Epoch: 536 [5120/11093 (45%)]\tLoss: 1438740992.000000\n",
      "Train Epoch: 536 [8530/11093 (91%)]\tLoss: 1436150218.579133\n",
      "Train Epoch: 537 [0/11093 (0%)]\tLoss: 1041288448.000000\n",
      "Train Epoch: 537 [5120/11093 (45%)]\tLoss: 1607064064.000000\n",
      "Train Epoch: 537 [8530/11093 (91%)]\tLoss: 1220159773.711606\n",
      "Train Epoch: 538 [0/11093 (0%)]\tLoss: 1183982592.000000\n",
      "Train Epoch: 538 [5120/11093 (45%)]\tLoss: 1319920384.000000\n",
      "Train Epoch: 538 [8530/11093 (91%)]\tLoss: 1368035803.385698\n",
      "Train Epoch: 539 [0/11093 (0%)]\tLoss: 1344125952.000000\n",
      "Train Epoch: 539 [5120/11093 (45%)]\tLoss: 1795259904.000000\n",
      "Train Epoch: 539 [8530/11093 (91%)]\tLoss: 1080720293.964830\n",
      "Train Epoch: 540 [0/11093 (0%)]\tLoss: 1313623040.000000\n",
      "Train Epoch: 540 [5120/11093 (45%)]\tLoss: 1089972480.000000\n",
      "Train Epoch: 540 [8530/11093 (91%)]\tLoss: 1463642148.014068\n",
      "Train Epoch: 541 [0/11093 (0%)]\tLoss: 1256906496.000000\n",
      "Train Epoch: 541 [5120/11093 (45%)]\tLoss: 1272257152.000000\n",
      "Train Epoch: 541 [8530/11093 (91%)]\tLoss: 1364232717.805393\n",
      "Train Epoch: 542 [0/11093 (0%)]\tLoss: 1093156352.000000\n",
      "Train Epoch: 542 [5120/11093 (45%)]\tLoss: 1246375680.000000\n",
      "Train Epoch: 542 [8530/11093 (91%)]\tLoss: 1329568245.796014\n",
      "Train Epoch: 543 [0/11093 (0%)]\tLoss: 1365479680.000000\n",
      "Train Epoch: 543 [5120/11093 (45%)]\tLoss: 1123060736.000000\n",
      "Train Epoch: 543 [8530/11093 (91%)]\tLoss: 1279169064.215709\n",
      "Train Epoch: 544 [0/11093 (0%)]\tLoss: 1452624128.000000\n",
      "Train Epoch: 544 [5120/11093 (45%)]\tLoss: 1127844480.000000\n",
      "Train Epoch: 544 [8530/11093 (91%)]\tLoss: 1260025022.874560\n",
      "Train Epoch: 545 [0/11093 (0%)]\tLoss: 1187096576.000000\n",
      "Train Epoch: 545 [5120/11093 (45%)]\tLoss: 1219743616.000000\n",
      "Train Epoch: 545 [8530/11093 (91%)]\tLoss: 1517997230.067995\n",
      "Train Epoch: 546 [0/11093 (0%)]\tLoss: 1350435456.000000\n",
      "Train Epoch: 546 [5120/11093 (45%)]\tLoss: 1260657920.000000\n",
      "Train Epoch: 546 [8530/11093 (91%)]\tLoss: 1417246040.534584\n",
      "Train Epoch: 547 [0/11093 (0%)]\tLoss: 1396792064.000000\n",
      "Train Epoch: 547 [5120/11093 (45%)]\tLoss: 1345263488.000000\n",
      "Train Epoch: 547 [8530/11093 (91%)]\tLoss: 1233625232.056272\n",
      "Train Epoch: 548 [0/11093 (0%)]\tLoss: 1209174144.000000\n",
      "Train Epoch: 548 [5120/11093 (45%)]\tLoss: 1104481280.000000\n",
      "Train Epoch: 548 [8530/11093 (91%)]\tLoss: 1717521236.332942\n",
      "Train Epoch: 549 [0/11093 (0%)]\tLoss: 1304956928.000000\n",
      "Train Epoch: 549 [5120/11093 (45%)]\tLoss: 1336220928.000000\n",
      "Train Epoch: 549 [8530/11093 (91%)]\tLoss: 1355842573.205158\n",
      "Train Epoch: 550 [0/11093 (0%)]\tLoss: 1450559744.000000\n",
      "Train Epoch: 550 [5120/11093 (45%)]\tLoss: 1304476544.000000\n",
      "Train Epoch: 550 [8530/11093 (91%)]\tLoss: 1108737894.339977\n",
      "Train Epoch: 551 [0/11093 (0%)]\tLoss: 1124563840.000000\n",
      "Train Epoch: 551 [5120/11093 (45%)]\tLoss: 1252780032.000000\n",
      "Train Epoch: 551 [8530/11093 (91%)]\tLoss: 1277606725.927315\n",
      "Train Epoch: 552 [0/11093 (0%)]\tLoss: 1283315712.000000\n",
      "Train Epoch: 552 [5120/11093 (45%)]\tLoss: 1402461440.000000\n",
      "Train Epoch: 552 [8530/11093 (91%)]\tLoss: 1143992728.159437\n",
      "Train Epoch: 553 [0/11093 (0%)]\tLoss: 1290449152.000000\n",
      "Train Epoch: 553 [5120/11093 (45%)]\tLoss: 1393138816.000000\n",
      "Train Epoch: 553 [8530/11093 (91%)]\tLoss: 1164065183.362251\n",
      "Train Epoch: 554 [0/11093 (0%)]\tLoss: 1639150336.000000\n",
      "Train Epoch: 554 [5120/11093 (45%)]\tLoss: 1069919104.000000\n",
      "Train Epoch: 554 [8530/11093 (91%)]\tLoss: 1401856067.226260\n",
      "Train Epoch: 555 [0/11093 (0%)]\tLoss: 1510349056.000000\n",
      "Train Epoch: 555 [5120/11093 (45%)]\tLoss: 1297408000.000000\n",
      "Train Epoch: 555 [8530/11093 (91%)]\tLoss: 1131799421.148886\n",
      "Train Epoch: 556 [0/11093 (0%)]\tLoss: 1678375552.000000\n",
      "Train Epoch: 556 [5120/11093 (45%)]\tLoss: 1250888832.000000\n",
      "Train Epoch: 556 [8530/11093 (91%)]\tLoss: 1109430440.065651\n",
      "Train Epoch: 557 [0/11093 (0%)]\tLoss: 1248207872.000000\n",
      "Train Epoch: 557 [5120/11093 (45%)]\tLoss: 1388740224.000000\n",
      "Train Epoch: 557 [8530/11093 (91%)]\tLoss: 1384436552.328253\n",
      "Train Epoch: 558 [0/11093 (0%)]\tLoss: 1331025280.000000\n",
      "Train Epoch: 558 [5120/11093 (45%)]\tLoss: 1406035968.000000\n",
      "Train Epoch: 558 [8530/11093 (91%)]\tLoss: 1400372018.719812\n",
      "Train Epoch: 559 [0/11093 (0%)]\tLoss: 1297964928.000000\n",
      "Train Epoch: 559 [5120/11093 (45%)]\tLoss: 1158820096.000000\n",
      "Train Epoch: 559 [8530/11093 (91%)]\tLoss: 1212906790.114889\n",
      "Train Epoch: 560 [0/11093 (0%)]\tLoss: 1478373376.000000\n",
      "Train Epoch: 560 [5120/11093 (45%)]\tLoss: 1493464576.000000\n",
      "Train Epoch: 560 [8530/11093 (91%)]\tLoss: 1195973916.511137\n",
      "Train Epoch: 561 [0/11093 (0%)]\tLoss: 1174003456.000000\n",
      "Train Epoch: 561 [5120/11093 (45%)]\tLoss: 1304759296.000000\n",
      "Train Epoch: 561 [8530/11093 (91%)]\tLoss: 1224481615.531067\n",
      "Train Epoch: 562 [0/11093 (0%)]\tLoss: 1342780288.000000\n",
      "Train Epoch: 562 [5120/11093 (45%)]\tLoss: 1292093952.000000\n",
      "Train Epoch: 562 [8530/11093 (91%)]\tLoss: 1300945378.588511\n",
      "Train Epoch: 563 [0/11093 (0%)]\tLoss: 1293574912.000000\n",
      "Train Epoch: 563 [5120/11093 (45%)]\tLoss: 1364216192.000000\n",
      "Train Epoch: 563 [8530/11093 (91%)]\tLoss: 1190539345.631887\n",
      "Train Epoch: 564 [0/11093 (0%)]\tLoss: 1133089024.000000\n",
      "Train Epoch: 564 [5120/11093 (45%)]\tLoss: 1511543936.000000\n",
      "Train Epoch: 564 [8530/11093 (91%)]\tLoss: 1324855031.896835\n",
      "Train Epoch: 565 [0/11093 (0%)]\tLoss: 1165736192.000000\n",
      "Train Epoch: 565 [5120/11093 (45%)]\tLoss: 1221750656.000000\n",
      "Train Epoch: 565 [8530/11093 (91%)]\tLoss: 1252239914.616647\n",
      "Train Epoch: 566 [0/11093 (0%)]\tLoss: 1302051840.000000\n",
      "Train Epoch: 566 [5120/11093 (45%)]\tLoss: 1277331456.000000\n",
      "Train Epoch: 566 [8530/11093 (91%)]\tLoss: 1170903515.385698\n",
      "Train Epoch: 567 [0/11093 (0%)]\tLoss: 1504947328.000000\n",
      "Train Epoch: 567 [5120/11093 (45%)]\tLoss: 1247619840.000000\n",
      "Train Epoch: 567 [8530/11093 (91%)]\tLoss: 1196129881.434936\n",
      "Train Epoch: 568 [0/11093 (0%)]\tLoss: 1271648000.000000\n",
      "Train Epoch: 568 [5120/11093 (45%)]\tLoss: 1283484928.000000\n",
      "Train Epoch: 568 [8530/11093 (91%)]\tLoss: 1106317748.970692\n",
      "Train Epoch: 569 [0/11093 (0%)]\tLoss: 1113579136.000000\n",
      "Train Epoch: 569 [5120/11093 (45%)]\tLoss: 1262936064.000000\n",
      "Train Epoch: 569 [8530/11093 (91%)]\tLoss: 1145365526.808910\n",
      "Train Epoch: 570 [0/11093 (0%)]\tLoss: 1356051200.000000\n",
      "Train Epoch: 570 [5120/11093 (45%)]\tLoss: 1131311104.000000\n",
      "Train Epoch: 570 [8530/11093 (91%)]\tLoss: 1342926833.594373\n",
      "Train Epoch: 571 [0/11093 (0%)]\tLoss: 1266970240.000000\n",
      "Train Epoch: 571 [5120/11093 (45%)]\tLoss: 1542622336.000000\n",
      "Train Epoch: 571 [8530/11093 (91%)]\tLoss: 1127242249.003517\n",
      "Train Epoch: 572 [0/11093 (0%)]\tLoss: 1450971648.000000\n",
      "Train Epoch: 572 [5120/11093 (45%)]\tLoss: 1331713024.000000\n",
      "Train Epoch: 572 [8530/11093 (91%)]\tLoss: 1075476492.004689\n",
      "Train Epoch: 573 [0/11093 (0%)]\tLoss: 1174274560.000000\n",
      "Train Epoch: 573 [5120/11093 (45%)]\tLoss: 1233430144.000000\n",
      "Train Epoch: 573 [8530/11093 (91%)]\tLoss: 1109881432.234467\n",
      "Train Epoch: 574 [0/11093 (0%)]\tLoss: 1303353600.000000\n",
      "Train Epoch: 574 [5120/11093 (45%)]\tLoss: 1308937216.000000\n",
      "Train Epoch: 574 [8530/11093 (91%)]\tLoss: 1349023909.664713\n",
      "Train Epoch: 575 [0/11093 (0%)]\tLoss: 1235806592.000000\n",
      "Train Epoch: 575 [5120/11093 (45%)]\tLoss: 1137133824.000000\n",
      "Train Epoch: 575 [8530/11093 (91%)]\tLoss: 1417695035.123095\n",
      "Train Epoch: 576 [0/11093 (0%)]\tLoss: 1167349504.000000\n",
      "Train Epoch: 576 [5120/11093 (45%)]\tLoss: 1223630336.000000\n",
      "Train Epoch: 576 [8530/11093 (91%)]\tLoss: 1687040465.781946\n",
      "Train Epoch: 577 [0/11093 (0%)]\tLoss: 1171367168.000000\n",
      "Train Epoch: 577 [5120/11093 (45%)]\tLoss: 1188327424.000000\n",
      "Train Epoch: 577 [8530/11093 (91%)]\tLoss: 1425490361.772568\n",
      "Train Epoch: 578 [0/11093 (0%)]\tLoss: 1211124992.000000\n",
      "Train Epoch: 578 [5120/11093 (45%)]\tLoss: 1219757696.000000\n",
      "Train Epoch: 578 [8530/11093 (91%)]\tLoss: 1252430529.875733\n",
      "Train Epoch: 579 [0/11093 (0%)]\tLoss: 1236418816.000000\n",
      "Train Epoch: 579 [5120/11093 (45%)]\tLoss: 1134695680.000000\n",
      "Train Epoch: 579 [8530/11093 (91%)]\tLoss: 1319907025.481829\n",
      "Train Epoch: 580 [0/11093 (0%)]\tLoss: 1430841472.000000\n",
      "Train Epoch: 580 [5120/11093 (45%)]\tLoss: 1066983232.000000\n",
      "Train Epoch: 580 [8530/11093 (91%)]\tLoss: 1248447738.898007\n",
      "Train Epoch: 581 [0/11093 (0%)]\tLoss: 1518881792.000000\n",
      "Train Epoch: 581 [5120/11093 (45%)]\tLoss: 1198948864.000000\n",
      "Train Epoch: 581 [8530/11093 (91%)]\tLoss: 1102612775.315357\n",
      "Train Epoch: 582 [0/11093 (0%)]\tLoss: 1383232512.000000\n",
      "Train Epoch: 582 [5120/11093 (45%)]\tLoss: 1412704000.000000\n",
      "Train Epoch: 582 [8530/11093 (91%)]\tLoss: 1315290924.717468\n",
      "Train Epoch: 583 [0/11093 (0%)]\tLoss: 1227632512.000000\n",
      "Train Epoch: 583 [5120/11093 (45%)]\tLoss: 1233136640.000000\n",
      "Train Epoch: 583 [8530/11093 (91%)]\tLoss: 1156279998.274326\n",
      "Train Epoch: 584 [0/11093 (0%)]\tLoss: 1261650304.000000\n",
      "Train Epoch: 584 [5120/11093 (45%)]\tLoss: 1303775232.000000\n",
      "Train Epoch: 584 [8530/11093 (91%)]\tLoss: 1244284090.072685\n",
      "Train Epoch: 585 [0/11093 (0%)]\tLoss: 1302576512.000000\n",
      "Train Epoch: 585 [5120/11093 (45%)]\tLoss: 1242342912.000000\n",
      "Train Epoch: 585 [8530/11093 (91%)]\tLoss: 1195698250.429074\n",
      "Train Epoch: 586 [0/11093 (0%)]\tLoss: 1314460672.000000\n",
      "Train Epoch: 586 [5120/11093 (45%)]\tLoss: 1460308480.000000\n",
      "Train Epoch: 586 [8530/11093 (91%)]\tLoss: 1335004737.425557\n",
      "Train Epoch: 587 [0/11093 (0%)]\tLoss: 1410519552.000000\n",
      "Train Epoch: 587 [5120/11093 (45%)]\tLoss: 1250876672.000000\n",
      "Train Epoch: 587 [8530/11093 (91%)]\tLoss: 1289316695.334115\n",
      "Train Epoch: 588 [0/11093 (0%)]\tLoss: 1537605632.000000\n",
      "Train Epoch: 588 [5120/11093 (45%)]\tLoss: 1493759744.000000\n",
      "Train Epoch: 588 [8530/11093 (91%)]\tLoss: 1121811519.624853\n",
      "Train Epoch: 589 [0/11093 (0%)]\tLoss: 1202427776.000000\n",
      "Train Epoch: 589 [5120/11093 (45%)]\tLoss: 1162919936.000000\n",
      "Train Epoch: 589 [8530/11093 (91%)]\tLoss: 1380143137.613130\n",
      "Train Epoch: 590 [0/11093 (0%)]\tLoss: 1204243200.000000\n",
      "Train Epoch: 590 [5120/11093 (45%)]\tLoss: 1453836032.000000\n",
      "Train Epoch: 590 [8530/11093 (91%)]\tLoss: 1373965390.030481\n",
      "Train Epoch: 591 [0/11093 (0%)]\tLoss: 1378484352.000000\n",
      "Train Epoch: 591 [5120/11093 (45%)]\tLoss: 1223789312.000000\n",
      "Train Epoch: 591 [8530/11093 (91%)]\tLoss: 1381493194.579133\n",
      "Train Epoch: 592 [0/11093 (0%)]\tLoss: 1376343808.000000\n",
      "Train Epoch: 592 [5120/11093 (45%)]\tLoss: 1331078912.000000\n",
      "Train Epoch: 592 [8530/11093 (91%)]\tLoss: 1249285800.665885\n",
      "Train Epoch: 593 [0/11093 (0%)]\tLoss: 1214398976.000000\n",
      "Train Epoch: 593 [5120/11093 (45%)]\tLoss: 1111400960.000000\n",
      "Train Epoch: 593 [8530/11093 (91%)]\tLoss: 1275427365.814771\n",
      "Train Epoch: 594 [0/11093 (0%)]\tLoss: 1164291840.000000\n",
      "Train Epoch: 594 [5120/11093 (45%)]\tLoss: 1266001920.000000\n",
      "Train Epoch: 594 [8530/11093 (91%)]\tLoss: 1355332114.607269\n",
      "Train Epoch: 595 [0/11093 (0%)]\tLoss: 1242510336.000000\n",
      "Train Epoch: 595 [5120/11093 (45%)]\tLoss: 1437514752.000000\n",
      "Train Epoch: 595 [8530/11093 (91%)]\tLoss: 1291069034.241501\n",
      "Train Epoch: 596 [0/11093 (0%)]\tLoss: 1327560576.000000\n",
      "Train Epoch: 596 [5120/11093 (45%)]\tLoss: 1315011456.000000\n",
      "Train Epoch: 596 [8530/11093 (91%)]\tLoss: 1372418187.254396\n",
      "Train Epoch: 597 [0/11093 (0%)]\tLoss: 1242784512.000000\n",
      "Train Epoch: 597 [5120/11093 (45%)]\tLoss: 1230401536.000000\n",
      "Train Epoch: 597 [8530/11093 (91%)]\tLoss: 1155030127.643611\n",
      "Train Epoch: 598 [0/11093 (0%)]\tLoss: 1551256064.000000\n",
      "Train Epoch: 598 [5120/11093 (45%)]\tLoss: 1286288640.000000\n",
      "Train Epoch: 598 [8530/11093 (91%)]\tLoss: 1347340410.447831\n",
      "Train Epoch: 599 [0/11093 (0%)]\tLoss: 1110518272.000000\n",
      "Train Epoch: 599 [5120/11093 (45%)]\tLoss: 1146387456.000000\n",
      "Train Epoch: 599 [8530/11093 (91%)]\tLoss: 1115317462.883939\n",
      "Train Epoch: 600 [0/11093 (0%)]\tLoss: 1167592192.000000\n",
      "Train Epoch: 600 [5120/11093 (45%)]\tLoss: 1237270784.000000\n",
      "Train Epoch: 600 [8530/11093 (91%)]\tLoss: 1535947947.667058\n",
      "====> Epoch: 600 Average loss: 1292321120.9952\n",
      "Train Epoch: 601 [0/11093 (0%)]\tLoss: 1172297216.000000\n",
      "Train Epoch: 601 [5120/11093 (45%)]\tLoss: 1454458624.000000\n",
      "Train Epoch: 601 [8530/11093 (91%)]\tLoss: 1058706037.045721\n",
      "Train Epoch: 602 [0/11093 (0%)]\tLoss: 1385283584.000000\n",
      "Train Epoch: 602 [5120/11093 (45%)]\tLoss: 1185586432.000000\n",
      "Train Epoch: 602 [8530/11093 (91%)]\tLoss: 1145324653.242673\n",
      "Train Epoch: 603 [0/11093 (0%)]\tLoss: 1274228864.000000\n",
      "Train Epoch: 603 [5120/11093 (45%)]\tLoss: 1208019840.000000\n",
      "Train Epoch: 603 [8530/11093 (91%)]\tLoss: 1666613363.245018\n",
      "Train Epoch: 604 [0/11093 (0%)]\tLoss: 1392835456.000000\n",
      "Train Epoch: 604 [5120/11093 (45%)]\tLoss: 1234919680.000000\n",
      "Train Epoch: 604 [8530/11093 (91%)]\tLoss: 1273838213.852286\n",
      "Train Epoch: 605 [0/11093 (0%)]\tLoss: 1363400960.000000\n",
      "Train Epoch: 605 [5120/11093 (45%)]\tLoss: 1377292928.000000\n",
      "Train Epoch: 605 [8530/11093 (91%)]\tLoss: 1364061847.859320\n",
      "Train Epoch: 606 [0/11093 (0%)]\tLoss: 1234832128.000000\n",
      "Train Epoch: 606 [5120/11093 (45%)]\tLoss: 1228856704.000000\n",
      "Train Epoch: 606 [8530/11093 (91%)]\tLoss: 1091500773.889801\n",
      "Train Epoch: 607 [0/11093 (0%)]\tLoss: 1295847168.000000\n",
      "Train Epoch: 607 [5120/11093 (45%)]\tLoss: 1376241280.000000\n",
      "Train Epoch: 607 [8530/11093 (91%)]\tLoss: 1216340937.978898\n",
      "Train Epoch: 608 [0/11093 (0%)]\tLoss: 1263818368.000000\n",
      "Train Epoch: 608 [5120/11093 (45%)]\tLoss: 1210359808.000000\n",
      "Train Epoch: 608 [8530/11093 (91%)]\tLoss: 1208734152.178195\n",
      "Train Epoch: 609 [0/11093 (0%)]\tLoss: 1396744960.000000\n",
      "Train Epoch: 609 [5120/11093 (45%)]\tLoss: 1429021952.000000\n",
      "Train Epoch: 609 [8530/11093 (91%)]\tLoss: 1145097851.048066\n",
      "Train Epoch: 610 [0/11093 (0%)]\tLoss: 1368672256.000000\n",
      "Train Epoch: 610 [5120/11093 (45%)]\tLoss: 1384276608.000000\n",
      "Train Epoch: 610 [8530/11093 (91%)]\tLoss: 1299247128.009379\n",
      "Train Epoch: 611 [0/11093 (0%)]\tLoss: 1437476352.000000\n",
      "Train Epoch: 611 [5120/11093 (45%)]\tLoss: 1186843136.000000\n",
      "Train Epoch: 611 [8530/11093 (91%)]\tLoss: 1401522010.335287\n",
      "Train Epoch: 612 [0/11093 (0%)]\tLoss: 1370680320.000000\n",
      "Train Epoch: 612 [5120/11093 (45%)]\tLoss: 1240851328.000000\n",
      "Train Epoch: 612 [8530/11093 (91%)]\tLoss: 1192031461.289566\n",
      "Train Epoch: 613 [0/11093 (0%)]\tLoss: 1542453376.000000\n",
      "Train Epoch: 613 [5120/11093 (45%)]\tLoss: 1391372416.000000\n",
      "Train Epoch: 613 [8530/11093 (91%)]\tLoss: 1147347280.131301\n",
      "Train Epoch: 614 [0/11093 (0%)]\tLoss: 1251403520.000000\n",
      "Train Epoch: 614 [5120/11093 (45%)]\tLoss: 1263091200.000000\n",
      "Train Epoch: 614 [8530/11093 (91%)]\tLoss: 1534764765.486518\n",
      "Train Epoch: 615 [0/11093 (0%)]\tLoss: 1748350592.000000\n",
      "Train Epoch: 615 [5120/11093 (45%)]\tLoss: 1184607488.000000\n",
      "Train Epoch: 615 [8530/11093 (91%)]\tLoss: 1431068988.923798\n",
      "Train Epoch: 616 [0/11093 (0%)]\tLoss: 1391513088.000000\n",
      "Train Epoch: 616 [5120/11093 (45%)]\tLoss: 1020607040.000000\n",
      "Train Epoch: 616 [8530/11093 (91%)]\tLoss: 1450278950.415006\n",
      "Train Epoch: 617 [0/11093 (0%)]\tLoss: 1202600192.000000\n",
      "Train Epoch: 617 [5120/11093 (45%)]\tLoss: 1417081856.000000\n",
      "Train Epoch: 617 [8530/11093 (91%)]\tLoss: 1500526546.382180\n",
      "Train Epoch: 618 [0/11093 (0%)]\tLoss: 1193612928.000000\n",
      "Train Epoch: 618 [5120/11093 (45%)]\tLoss: 1160736384.000000\n",
      "Train Epoch: 618 [8530/11093 (91%)]\tLoss: 1199877495.746776\n",
      "Train Epoch: 619 [0/11093 (0%)]\tLoss: 1607443200.000000\n",
      "Train Epoch: 619 [5120/11093 (45%)]\tLoss: 1127476608.000000\n",
      "Train Epoch: 619 [8530/11093 (91%)]\tLoss: 1227356210.419695\n",
      "Train Epoch: 620 [0/11093 (0%)]\tLoss: 1364488064.000000\n",
      "Train Epoch: 620 [5120/11093 (45%)]\tLoss: 1265725696.000000\n",
      "Train Epoch: 620 [8530/11093 (91%)]\tLoss: 1184186656.112544\n",
      "Train Epoch: 621 [0/11093 (0%)]\tLoss: 1145399936.000000\n",
      "Train Epoch: 621 [5120/11093 (45%)]\tLoss: 1254913408.000000\n",
      "Train Epoch: 621 [8530/11093 (91%)]\tLoss: 1308674938.747948\n",
      "Train Epoch: 622 [0/11093 (0%)]\tLoss: 1267195776.000000\n",
      "Train Epoch: 622 [5120/11093 (45%)]\tLoss: 1478534656.000000\n",
      "Train Epoch: 622 [8530/11093 (91%)]\tLoss: 1026605997.167644\n",
      "Train Epoch: 623 [0/11093 (0%)]\tLoss: 1207184896.000000\n",
      "Train Epoch: 623 [5120/11093 (45%)]\tLoss: 1109374208.000000\n",
      "Train Epoch: 623 [8530/11093 (91%)]\tLoss: 1314194099.470105\n",
      "Train Epoch: 624 [0/11093 (0%)]\tLoss: 1123325440.000000\n",
      "Train Epoch: 624 [5120/11093 (45%)]\tLoss: 1476825088.000000\n",
      "Train Epoch: 624 [8530/11093 (91%)]\tLoss: 1046309360.994138\n",
      "Train Epoch: 625 [0/11093 (0%)]\tLoss: 1259776768.000000\n",
      "Train Epoch: 625 [5120/11093 (45%)]\tLoss: 1480552960.000000\n",
      "Train Epoch: 625 [8530/11093 (91%)]\tLoss: 1068246173.261430\n",
      "Train Epoch: 626 [0/11093 (0%)]\tLoss: 1289395200.000000\n",
      "Train Epoch: 626 [5120/11093 (45%)]\tLoss: 1148894976.000000\n",
      "Train Epoch: 626 [8530/11093 (91%)]\tLoss: 1192307665.181712\n",
      "Train Epoch: 627 [0/11093 (0%)]\tLoss: 1387616256.000000\n",
      "Train Epoch: 627 [5120/11093 (45%)]\tLoss: 1445215104.000000\n",
      "Train Epoch: 627 [8530/11093 (91%)]\tLoss: 1199178188.980070\n",
      "Train Epoch: 628 [0/11093 (0%)]\tLoss: 1151044608.000000\n",
      "Train Epoch: 628 [5120/11093 (45%)]\tLoss: 1284291328.000000\n",
      "Train Epoch: 628 [8530/11093 (91%)]\tLoss: 1165158551.259086\n",
      "Train Epoch: 629 [0/11093 (0%)]\tLoss: 1224824320.000000\n",
      "Train Epoch: 629 [5120/11093 (45%)]\tLoss: 1112454656.000000\n",
      "Train Epoch: 629 [8530/11093 (91%)]\tLoss: 1269948617.678781\n",
      "Train Epoch: 630 [0/11093 (0%)]\tLoss: 1597266048.000000\n",
      "Train Epoch: 630 [5120/11093 (45%)]\tLoss: 1221457152.000000\n",
      "Train Epoch: 630 [8530/11093 (91%)]\tLoss: 1301202912.787808\n",
      "Train Epoch: 631 [0/11093 (0%)]\tLoss: 1375934592.000000\n",
      "Train Epoch: 631 [5120/11093 (45%)]\tLoss: 1575106944.000000\n",
      "Train Epoch: 631 [8530/11093 (91%)]\tLoss: 1265166640.919109\n",
      "Train Epoch: 632 [0/11093 (0%)]\tLoss: 1296240384.000000\n",
      "Train Epoch: 632 [5120/11093 (45%)]\tLoss: 1457041024.000000\n",
      "Train Epoch: 632 [8530/11093 (91%)]\tLoss: 1470633371.760844\n",
      "Train Epoch: 633 [0/11093 (0%)]\tLoss: 1216339840.000000\n",
      "Train Epoch: 633 [5120/11093 (45%)]\tLoss: 1346435072.000000\n",
      "Train Epoch: 633 [8530/11093 (91%)]\tLoss: 1686285687.746776\n",
      "Train Epoch: 634 [0/11093 (0%)]\tLoss: 1403875328.000000\n",
      "Train Epoch: 634 [5120/11093 (45%)]\tLoss: 1457215232.000000\n",
      "Train Epoch: 634 [8530/11093 (91%)]\tLoss: 1152555509.796014\n",
      "Train Epoch: 635 [0/11093 (0%)]\tLoss: 1532834432.000000\n",
      "Train Epoch: 635 [5120/11093 (45%)]\tLoss: 1124225024.000000\n",
      "Train Epoch: 635 [8530/11093 (91%)]\tLoss: 1288117993.491208\n",
      "Train Epoch: 636 [0/11093 (0%)]\tLoss: 1111216128.000000\n",
      "Train Epoch: 636 [5120/11093 (45%)]\tLoss: 1254242944.000000\n",
      "Train Epoch: 636 [8530/11093 (91%)]\tLoss: 1324122841.885111\n",
      "Train Epoch: 637 [0/11093 (0%)]\tLoss: 1426864128.000000\n",
      "Train Epoch: 637 [5120/11093 (45%)]\tLoss: 1136049408.000000\n",
      "Train Epoch: 637 [8530/11093 (91%)]\tLoss: 1285010526.837046\n",
      "Train Epoch: 638 [0/11093 (0%)]\tLoss: 1239621504.000000\n",
      "Train Epoch: 638 [5120/11093 (45%)]\tLoss: 1251966464.000000\n",
      "Train Epoch: 638 [8530/11093 (91%)]\tLoss: 1193846493.486518\n",
      "Train Epoch: 639 [0/11093 (0%)]\tLoss: 1075411328.000000\n",
      "Train Epoch: 639 [5120/11093 (45%)]\tLoss: 1201962240.000000\n",
      "Train Epoch: 639 [8530/11093 (91%)]\tLoss: 1201914105.697538\n",
      "Train Epoch: 640 [0/11093 (0%)]\tLoss: 1278705280.000000\n",
      "Train Epoch: 640 [5120/11093 (45%)]\tLoss: 1318734336.000000\n",
      "Train Epoch: 640 [8530/11093 (91%)]\tLoss: 1143949165.542790\n",
      "Train Epoch: 641 [0/11093 (0%)]\tLoss: 1418136576.000000\n",
      "Train Epoch: 641 [5120/11093 (45%)]\tLoss: 1338849408.000000\n",
      "Train Epoch: 641 [8530/11093 (91%)]\tLoss: 1034922845.936694\n",
      "Train Epoch: 642 [0/11093 (0%)]\tLoss: 1387679488.000000\n",
      "Train Epoch: 642 [5120/11093 (45%)]\tLoss: 1253592064.000000\n",
      "Train Epoch: 642 [8530/11093 (91%)]\tLoss: 1182592740.689332\n",
      "Train Epoch: 643 [0/11093 (0%)]\tLoss: 1589102208.000000\n",
      "Train Epoch: 643 [5120/11093 (45%)]\tLoss: 1184504320.000000\n",
      "Train Epoch: 643 [8530/11093 (91%)]\tLoss: 1252403255.221571\n",
      "Train Epoch: 644 [0/11093 (0%)]\tLoss: 1180835328.000000\n",
      "Train Epoch: 644 [5120/11093 (45%)]\tLoss: 1233645568.000000\n",
      "Train Epoch: 644 [8530/11093 (91%)]\tLoss: 1526544722.532239\n",
      "Train Epoch: 645 [0/11093 (0%)]\tLoss: 1277757696.000000\n",
      "Train Epoch: 645 [5120/11093 (45%)]\tLoss: 1355320320.000000\n",
      "Train Epoch: 645 [8530/11093 (91%)]\tLoss: 1095753545.528722\n",
      "Train Epoch: 646 [0/11093 (0%)]\tLoss: 1301893376.000000\n",
      "Train Epoch: 646 [5120/11093 (45%)]\tLoss: 1342374144.000000\n",
      "Train Epoch: 646 [8530/11093 (91%)]\tLoss: 1273521981.524033\n",
      "Train Epoch: 647 [0/11093 (0%)]\tLoss: 1447550080.000000\n",
      "Train Epoch: 647 [5120/11093 (45%)]\tLoss: 1257973760.000000\n",
      "Train Epoch: 647 [8530/11093 (91%)]\tLoss: 1321523528.928488\n",
      "Train Epoch: 648 [0/11093 (0%)]\tLoss: 1316299520.000000\n",
      "Train Epoch: 648 [5120/11093 (45%)]\tLoss: 1294646528.000000\n",
      "Train Epoch: 648 [8530/11093 (91%)]\tLoss: 1172041214.199297\n",
      "Train Epoch: 649 [0/11093 (0%)]\tLoss: 1300164864.000000\n",
      "Train Epoch: 649 [5120/11093 (45%)]\tLoss: 1501863680.000000\n",
      "Train Epoch: 649 [8530/11093 (91%)]\tLoss: 1380568007.577960\n",
      "Train Epoch: 650 [0/11093 (0%)]\tLoss: 1199666944.000000\n",
      "Train Epoch: 650 [5120/11093 (45%)]\tLoss: 1157375488.000000\n",
      "Train Epoch: 650 [8530/11093 (91%)]\tLoss: 1199656455.803048\n",
      "Train Epoch: 651 [0/11093 (0%)]\tLoss: 1229493504.000000\n",
      "Train Epoch: 651 [5120/11093 (45%)]\tLoss: 1359909888.000000\n",
      "Train Epoch: 651 [8530/11093 (91%)]\tLoss: 1017735434.504103\n",
      "Train Epoch: 652 [0/11093 (0%)]\tLoss: 1168287744.000000\n",
      "Train Epoch: 652 [5120/11093 (45%)]\tLoss: 1404061440.000000\n",
      "Train Epoch: 652 [8530/11093 (91%)]\tLoss: 1376478499.713951\n",
      "Train Epoch: 653 [0/11093 (0%)]\tLoss: 1110708608.000000\n",
      "Train Epoch: 653 [5120/11093 (45%)]\tLoss: 1584610816.000000\n",
      "Train Epoch: 653 [8530/11093 (91%)]\tLoss: 1464370496.525205\n",
      "Train Epoch: 654 [0/11093 (0%)]\tLoss: 1304913024.000000\n",
      "Train Epoch: 654 [5120/11093 (45%)]\tLoss: 1366033664.000000\n",
      "Train Epoch: 654 [8530/11093 (91%)]\tLoss: 1304531957.195780\n",
      "Train Epoch: 655 [0/11093 (0%)]\tLoss: 1137401984.000000\n",
      "Train Epoch: 655 [5120/11093 (45%)]\tLoss: 1480477952.000000\n",
      "Train Epoch: 655 [8530/11093 (91%)]\tLoss: 1274259780.126612\n",
      "Train Epoch: 656 [0/11093 (0%)]\tLoss: 1328571136.000000\n",
      "Train Epoch: 656 [5120/11093 (45%)]\tLoss: 1123210752.000000\n",
      "Train Epoch: 656 [8530/11093 (91%)]\tLoss: 1246119789.542790\n",
      "Train Epoch: 657 [0/11093 (0%)]\tLoss: 1241807104.000000\n",
      "Train Epoch: 657 [5120/11093 (45%)]\tLoss: 1086608000.000000\n",
      "Train Epoch: 657 [8530/11093 (91%)]\tLoss: 1311577422.930832\n",
      "Train Epoch: 658 [0/11093 (0%)]\tLoss: 1392365568.000000\n",
      "Train Epoch: 658 [5120/11093 (45%)]\tLoss: 1260480512.000000\n",
      "Train Epoch: 658 [8530/11093 (91%)]\tLoss: 1475592288.037515\n",
      "Train Epoch: 659 [0/11093 (0%)]\tLoss: 1253958912.000000\n",
      "Train Epoch: 659 [5120/11093 (45%)]\tLoss: 1257029120.000000\n",
      "Train Epoch: 659 [8530/11093 (91%)]\tLoss: 1535689952.487690\n",
      "Train Epoch: 660 [0/11093 (0%)]\tLoss: 1151710592.000000\n",
      "Train Epoch: 660 [5120/11093 (45%)]\tLoss: 1235340032.000000\n",
      "Train Epoch: 660 [8530/11093 (91%)]\tLoss: 1607934749.111372\n",
      "Train Epoch: 661 [0/11093 (0%)]\tLoss: 1329522560.000000\n",
      "Train Epoch: 661 [5120/11093 (45%)]\tLoss: 1297843968.000000\n",
      "Train Epoch: 661 [8530/11093 (91%)]\tLoss: 1024096728.984760\n",
      "Train Epoch: 662 [0/11093 (0%)]\tLoss: 1273452800.000000\n",
      "Train Epoch: 662 [5120/11093 (45%)]\tLoss: 1360081408.000000\n",
      "Train Epoch: 662 [8530/11093 (91%)]\tLoss: 1143494255.043376\n",
      "Train Epoch: 663 [0/11093 (0%)]\tLoss: 1275174400.000000\n",
      "Train Epoch: 663 [5120/11093 (45%)]\tLoss: 1222113536.000000\n",
      "Train Epoch: 663 [8530/11093 (91%)]\tLoss: 1214095657.716295\n",
      "Train Epoch: 664 [0/11093 (0%)]\tLoss: 1250499328.000000\n",
      "Train Epoch: 664 [5120/11093 (45%)]\tLoss: 1193562368.000000\n",
      "Train Epoch: 664 [8530/11093 (91%)]\tLoss: 1415810394.935522\n",
      "Train Epoch: 665 [0/11093 (0%)]\tLoss: 1127742976.000000\n",
      "Train Epoch: 665 [5120/11093 (45%)]\tLoss: 1304889600.000000\n",
      "Train Epoch: 665 [8530/11093 (91%)]\tLoss: 1214633237.308324\n",
      "Train Epoch: 666 [0/11093 (0%)]\tLoss: 1317022208.000000\n",
      "Train Epoch: 666 [5120/11093 (45%)]\tLoss: 1314305792.000000\n",
      "Train Epoch: 666 [8530/11093 (91%)]\tLoss: 1352913198.518171\n",
      "Train Epoch: 667 [0/11093 (0%)]\tLoss: 1318445568.000000\n",
      "Train Epoch: 667 [5120/11093 (45%)]\tLoss: 1341583872.000000\n",
      "Train Epoch: 667 [8530/11093 (91%)]\tLoss: 1184167679.099648\n",
      "Train Epoch: 668 [0/11093 (0%)]\tLoss: 1168417408.000000\n",
      "Train Epoch: 668 [5120/11093 (45%)]\tLoss: 1369097472.000000\n",
      "Train Epoch: 668 [8530/11093 (91%)]\tLoss: 1244993922.550997\n",
      "Train Epoch: 669 [0/11093 (0%)]\tLoss: 1355643520.000000\n",
      "Train Epoch: 669 [5120/11093 (45%)]\tLoss: 1230987008.000000\n",
      "Train Epoch: 669 [8530/11093 (91%)]\tLoss: 1149962112.750293\n",
      "Train Epoch: 670 [0/11093 (0%)]\tLoss: 1134869760.000000\n",
      "Train Epoch: 670 [5120/11093 (45%)]\tLoss: 1172044288.000000\n",
      "Train Epoch: 670 [8530/11093 (91%)]\tLoss: 1298411524.801876\n",
      "Train Epoch: 671 [0/11093 (0%)]\tLoss: 1250614528.000000\n",
      "Train Epoch: 671 [5120/11093 (45%)]\tLoss: 1210141440.000000\n",
      "Train Epoch: 671 [8530/11093 (91%)]\tLoss: 1054813521.331770\n",
      "Train Epoch: 672 [0/11093 (0%)]\tLoss: 1274274304.000000\n",
      "Train Epoch: 672 [5120/11093 (45%)]\tLoss: 1121366784.000000\n",
      "Train Epoch: 672 [8530/11093 (91%)]\tLoss: 1212109755.573271\n",
      "Train Epoch: 673 [0/11093 (0%)]\tLoss: 1358735616.000000\n",
      "Train Epoch: 673 [5120/11093 (45%)]\tLoss: 1256856832.000000\n",
      "Train Epoch: 673 [8530/11093 (91%)]\tLoss: 1255173053.974209\n",
      "Train Epoch: 674 [0/11093 (0%)]\tLoss: 1354098176.000000\n",
      "Train Epoch: 674 [5120/11093 (45%)]\tLoss: 1252248704.000000\n",
      "Train Epoch: 674 [8530/11093 (91%)]\tLoss: 1316223948.379836\n",
      "Train Epoch: 675 [0/11093 (0%)]\tLoss: 1122025088.000000\n",
      "Train Epoch: 675 [5120/11093 (45%)]\tLoss: 1305848320.000000\n",
      "Train Epoch: 675 [8530/11093 (91%)]\tLoss: 1053360819.470106\n",
      "Train Epoch: 676 [0/11093 (0%)]\tLoss: 1442389760.000000\n",
      "Train Epoch: 676 [5120/11093 (45%)]\tLoss: 1211390336.000000\n",
      "Train Epoch: 676 [8530/11093 (91%)]\tLoss: 1244105767.615475\n",
      "Train Epoch: 677 [0/11093 (0%)]\tLoss: 1171845888.000000\n",
      "Train Epoch: 677 [5120/11093 (45%)]\tLoss: 1216082816.000000\n",
      "Train Epoch: 677 [8530/11093 (91%)]\tLoss: 1179700859.048066\n",
      "Train Epoch: 678 [0/11093 (0%)]\tLoss: 1110444288.000000\n",
      "Train Epoch: 678 [5120/11093 (45%)]\tLoss: 1526224384.000000\n",
      "Train Epoch: 678 [8530/11093 (91%)]\tLoss: 1258430185.491208\n",
      "Train Epoch: 679 [0/11093 (0%)]\tLoss: 1379562240.000000\n",
      "Train Epoch: 679 [5120/11093 (45%)]\tLoss: 1215881472.000000\n",
      "Train Epoch: 679 [8530/11093 (91%)]\tLoss: 1208284542.949590\n",
      "Train Epoch: 680 [0/11093 (0%)]\tLoss: 1210883584.000000\n",
      "Train Epoch: 680 [5120/11093 (45%)]\tLoss: 1261117312.000000\n",
      "Train Epoch: 680 [8530/11093 (91%)]\tLoss: 1025078155.554513\n",
      "Train Epoch: 681 [0/11093 (0%)]\tLoss: 1311330304.000000\n",
      "Train Epoch: 681 [5120/11093 (45%)]\tLoss: 1399474688.000000\n",
      "Train Epoch: 681 [8530/11093 (91%)]\tLoss: 1150061838.105510\n",
      "Train Epoch: 682 [0/11093 (0%)]\tLoss: 1356982784.000000\n",
      "Train Epoch: 682 [5120/11093 (45%)]\tLoss: 1072619264.000000\n",
      "Train Epoch: 682 [8530/11093 (91%)]\tLoss: 1374940823.859320\n",
      "Train Epoch: 683 [0/11093 (0%)]\tLoss: 1221974144.000000\n",
      "Train Epoch: 683 [5120/11093 (45%)]\tLoss: 1181607168.000000\n",
      "Train Epoch: 683 [8530/11093 (91%)]\tLoss: 1354963023.230950\n",
      "Train Epoch: 684 [0/11093 (0%)]\tLoss: 1245333248.000000\n",
      "Train Epoch: 684 [5120/11093 (45%)]\tLoss: 1325323008.000000\n",
      "Train Epoch: 684 [8530/11093 (91%)]\tLoss: 1205890289.294255\n",
      "Train Epoch: 685 [0/11093 (0%)]\tLoss: 1283589120.000000\n",
      "Train Epoch: 685 [5120/11093 (45%)]\tLoss: 1478012160.000000\n",
      "Train Epoch: 685 [8530/11093 (91%)]\tLoss: 1201380905.416178\n",
      "Train Epoch: 686 [0/11093 (0%)]\tLoss: 1231210112.000000\n",
      "Train Epoch: 686 [5120/11093 (45%)]\tLoss: 1374464256.000000\n",
      "Train Epoch: 686 [8530/11093 (91%)]\tLoss: 1372732268.342321\n",
      "Train Epoch: 687 [0/11093 (0%)]\tLoss: 1251550336.000000\n",
      "Train Epoch: 687 [5120/11093 (45%)]\tLoss: 1213132800.000000\n",
      "Train Epoch: 687 [8530/11093 (91%)]\tLoss: 1351602785.838218\n",
      "Train Epoch: 688 [0/11093 (0%)]\tLoss: 1216799744.000000\n",
      "Train Epoch: 688 [5120/11093 (45%)]\tLoss: 1350853632.000000\n",
      "Train Epoch: 688 [8530/11093 (91%)]\tLoss: 1309308479.024619\n",
      "Train Epoch: 689 [0/11093 (0%)]\tLoss: 1197387520.000000\n",
      "Train Epoch: 689 [5120/11093 (45%)]\tLoss: 1228093184.000000\n",
      "Train Epoch: 689 [8530/11093 (91%)]\tLoss: 1305238639.643611\n",
      "Train Epoch: 690 [0/11093 (0%)]\tLoss: 1427657984.000000\n",
      "Train Epoch: 690 [5120/11093 (45%)]\tLoss: 1395343744.000000\n",
      "Train Epoch: 690 [8530/11093 (91%)]\tLoss: 1140913842.269637\n",
      "Train Epoch: 691 [0/11093 (0%)]\tLoss: 1363063680.000000\n",
      "Train Epoch: 691 [5120/11093 (45%)]\tLoss: 1072580288.000000\n",
      "Train Epoch: 691 [8530/11093 (91%)]\tLoss: 1139863883.329426\n",
      "Train Epoch: 692 [0/11093 (0%)]\tLoss: 1204560768.000000\n",
      "Train Epoch: 692 [5120/11093 (45%)]\tLoss: 1197870464.000000\n",
      "Train Epoch: 692 [8530/11093 (91%)]\tLoss: 1306923060.820633\n",
      "Train Epoch: 693 [0/11093 (0%)]\tLoss: 1186792448.000000\n",
      "Train Epoch: 693 [5120/11093 (45%)]\tLoss: 1645246592.000000\n",
      "Train Epoch: 693 [8530/11093 (91%)]\tLoss: 1182964751.606096\n",
      "Train Epoch: 694 [0/11093 (0%)]\tLoss: 1243850496.000000\n",
      "Train Epoch: 694 [5120/11093 (45%)]\tLoss: 1264241024.000000\n",
      "Train Epoch: 694 [8530/11093 (91%)]\tLoss: 1395465500.511137\n",
      "Train Epoch: 695 [0/11093 (0%)]\tLoss: 1095747456.000000\n",
      "Train Epoch: 695 [5120/11093 (45%)]\tLoss: 1171471616.000000\n",
      "Train Epoch: 695 [8530/11093 (91%)]\tLoss: 1175847296.150059\n",
      "Train Epoch: 696 [0/11093 (0%)]\tLoss: 1251254016.000000\n",
      "Train Epoch: 696 [5120/11093 (45%)]\tLoss: 1471437312.000000\n",
      "Train Epoch: 696 [8530/11093 (91%)]\tLoss: 1255350147.151231\n",
      "Train Epoch: 697 [0/11093 (0%)]\tLoss: 1377958912.000000\n",
      "Train Epoch: 697 [5120/11093 (45%)]\tLoss: 1475168512.000000\n",
      "Train Epoch: 697 [8530/11093 (91%)]\tLoss: 1259940048.881594\n",
      "Train Epoch: 698 [0/11093 (0%)]\tLoss: 1223358976.000000\n",
      "Train Epoch: 698 [5120/11093 (45%)]\tLoss: 1147271424.000000\n",
      "Train Epoch: 698 [8530/11093 (91%)]\tLoss: 1256591873.800703\n",
      "Train Epoch: 699 [0/11093 (0%)]\tLoss: 1097038080.000000\n",
      "Train Epoch: 699 [5120/11093 (45%)]\tLoss: 1213571200.000000\n",
      "Train Epoch: 699 [8530/11093 (91%)]\tLoss: 1158005984.487690\n",
      "Train Epoch: 700 [0/11093 (0%)]\tLoss: 1552564224.000000\n",
      "Train Epoch: 700 [5120/11093 (45%)]\tLoss: 1243438848.000000\n",
      "Train Epoch: 700 [8530/11093 (91%)]\tLoss: 1551981295.493552\n",
      "Train Epoch: 701 [0/11093 (0%)]\tLoss: 1526027776.000000\n",
      "Train Epoch: 701 [5120/11093 (45%)]\tLoss: 1315733760.000000\n",
      "Train Epoch: 701 [8530/11093 (91%)]\tLoss: 1173935073.988277\n",
      "Train Epoch: 702 [0/11093 (0%)]\tLoss: 1146805376.000000\n",
      "Train Epoch: 702 [5120/11093 (45%)]\tLoss: 1203470592.000000\n",
      "Train Epoch: 702 [8530/11093 (91%)]\tLoss: 1756562099.470105\n",
      "Train Epoch: 703 [0/11093 (0%)]\tLoss: 1152078336.000000\n",
      "Train Epoch: 703 [5120/11093 (45%)]\tLoss: 1487279104.000000\n",
      "Train Epoch: 703 [8530/11093 (91%)]\tLoss: 1174757616.093787\n",
      "Train Epoch: 704 [0/11093 (0%)]\tLoss: 1239165952.000000\n",
      "Train Epoch: 704 [5120/11093 (45%)]\tLoss: 1093741312.000000\n",
      "Train Epoch: 704 [8530/11093 (91%)]\tLoss: 1222661589.383353\n",
      "Train Epoch: 705 [0/11093 (0%)]\tLoss: 1154083328.000000\n",
      "Train Epoch: 705 [5120/11093 (45%)]\tLoss: 1235770752.000000\n",
      "Train Epoch: 705 [8530/11093 (91%)]\tLoss: 1566641076.370457\n",
      "Train Epoch: 706 [0/11093 (0%)]\tLoss: 1157474560.000000\n",
      "Train Epoch: 706 [5120/11093 (45%)]\tLoss: 1271055744.000000\n",
      "Train Epoch: 706 [8530/11093 (91%)]\tLoss: 1275535081.491208\n",
      "Train Epoch: 707 [0/11093 (0%)]\tLoss: 1364644608.000000\n",
      "Train Epoch: 707 [5120/11093 (45%)]\tLoss: 1315388544.000000\n",
      "Train Epoch: 707 [8530/11093 (91%)]\tLoss: 1240335257.960141\n",
      "Train Epoch: 708 [0/11093 (0%)]\tLoss: 1387012352.000000\n",
      "Train Epoch: 708 [5120/11093 (45%)]\tLoss: 1467484928.000000\n",
      "Train Epoch: 708 [8530/11093 (91%)]\tLoss: 1195624570.447831\n",
      "Train Epoch: 709 [0/11093 (0%)]\tLoss: 1548280320.000000\n",
      "Train Epoch: 709 [5120/11093 (45%)]\tLoss: 1320458752.000000\n",
      "Train Epoch: 709 [8530/11093 (91%)]\tLoss: 1300163556.389215\n",
      "Train Epoch: 710 [0/11093 (0%)]\tLoss: 1166031360.000000\n",
      "Train Epoch: 710 [5120/11093 (45%)]\tLoss: 1411926528.000000\n",
      "Train Epoch: 710 [8530/11093 (91%)]\tLoss: 1446996464.994138\n",
      "Train Epoch: 711 [0/11093 (0%)]\tLoss: 1129955968.000000\n",
      "Train Epoch: 711 [5120/11093 (45%)]\tLoss: 1254234880.000000\n",
      "Train Epoch: 711 [8530/11093 (91%)]\tLoss: 1211823563.779601\n",
      "Train Epoch: 712 [0/11093 (0%)]\tLoss: 1579552384.000000\n",
      "Train Epoch: 712 [5120/11093 (45%)]\tLoss: 1286431232.000000\n",
      "Train Epoch: 712 [8530/11093 (91%)]\tLoss: 1263887267.563892\n",
      "Train Epoch: 713 [0/11093 (0%)]\tLoss: 1499733248.000000\n",
      "Train Epoch: 713 [5120/11093 (45%)]\tLoss: 1089584256.000000\n",
      "Train Epoch: 713 [8530/11093 (91%)]\tLoss: 1413131486.086753\n",
      "Train Epoch: 714 [0/11093 (0%)]\tLoss: 1175049216.000000\n",
      "Train Epoch: 714 [5120/11093 (45%)]\tLoss: 1464868992.000000\n",
      "Train Epoch: 714 [8530/11093 (91%)]\tLoss: 1267828109.355217\n",
      "Train Epoch: 715 [0/11093 (0%)]\tLoss: 1578042624.000000\n",
      "Train Epoch: 715 [5120/11093 (45%)]\tLoss: 1486396032.000000\n",
      "Train Epoch: 715 [8530/11093 (91%)]\tLoss: 1103832374.921454\n",
      "Train Epoch: 716 [0/11093 (0%)]\tLoss: 1384589568.000000\n",
      "Train Epoch: 716 [5120/11093 (45%)]\tLoss: 1357074944.000000\n",
      "Train Epoch: 716 [8530/11093 (91%)]\tLoss: 1306756493.355217\n",
      "Train Epoch: 717 [0/11093 (0%)]\tLoss: 1500784640.000000\n",
      "Train Epoch: 717 [5120/11093 (45%)]\tLoss: 1167796992.000000\n",
      "Train Epoch: 717 [8530/11093 (91%)]\tLoss: 1227497423.981243\n",
      "Train Epoch: 718 [0/11093 (0%)]\tLoss: 1383167232.000000\n",
      "Train Epoch: 718 [5120/11093 (45%)]\tLoss: 1248680960.000000\n",
      "Train Epoch: 718 [8530/11093 (91%)]\tLoss: 1350374734.930832\n",
      "Train Epoch: 719 [0/11093 (0%)]\tLoss: 1114128768.000000\n",
      "Train Epoch: 719 [5120/11093 (45%)]\tLoss: 1228020736.000000\n",
      "Train Epoch: 719 [8530/11093 (91%)]\tLoss: 1173214715.798359\n",
      "Train Epoch: 720 [0/11093 (0%)]\tLoss: 1468301824.000000\n",
      "Train Epoch: 720 [5120/11093 (45%)]\tLoss: 1172133888.000000\n",
      "Train Epoch: 720 [8530/11093 (91%)]\tLoss: 1537240382.124267\n",
      "Train Epoch: 721 [0/11093 (0%)]\tLoss: 1173864832.000000\n",
      "Train Epoch: 721 [5120/11093 (45%)]\tLoss: 1468540672.000000\n",
      "Train Epoch: 721 [8530/11093 (91%)]\tLoss: 1172848236.642438\n",
      "Train Epoch: 722 [0/11093 (0%)]\tLoss: 1172370688.000000\n",
      "Train Epoch: 722 [5120/11093 (45%)]\tLoss: 1398906368.000000\n",
      "Train Epoch: 722 [8530/11093 (91%)]\tLoss: 1156955103.587339\n",
      "Train Epoch: 723 [0/11093 (0%)]\tLoss: 1399213056.000000\n",
      "Train Epoch: 723 [5120/11093 (45%)]\tLoss: 1356439808.000000\n",
      "Train Epoch: 723 [8530/11093 (91%)]\tLoss: 1201272651.929660\n",
      "Train Epoch: 724 [0/11093 (0%)]\tLoss: 1445084928.000000\n",
      "Train Epoch: 724 [5120/11093 (45%)]\tLoss: 1396990208.000000\n",
      "Train Epoch: 724 [8530/11093 (91%)]\tLoss: 1086817523.695194\n",
      "Train Epoch: 725 [0/11093 (0%)]\tLoss: 1170072832.000000\n",
      "Train Epoch: 725 [5120/11093 (45%)]\tLoss: 1218820096.000000\n",
      "Train Epoch: 725 [8530/11093 (91%)]\tLoss: 1336941468.361079\n",
      "Train Epoch: 726 [0/11093 (0%)]\tLoss: 1551581952.000000\n",
      "Train Epoch: 726 [5120/11093 (45%)]\tLoss: 1157760512.000000\n",
      "Train Epoch: 726 [8530/11093 (91%)]\tLoss: 1322668603.423212\n",
      "Train Epoch: 727 [0/11093 (0%)]\tLoss: 1495562496.000000\n",
      "Train Epoch: 727 [5120/11093 (45%)]\tLoss: 1326298368.000000\n",
      "Train Epoch: 727 [8530/11093 (91%)]\tLoss: 1542163341.955451\n",
      "Train Epoch: 728 [0/11093 (0%)]\tLoss: 1401509504.000000\n",
      "Train Epoch: 728 [5120/11093 (45%)]\tLoss: 1296652928.000000\n",
      "Train Epoch: 728 [8530/11093 (91%)]\tLoss: 1521684763.310668\n",
      "Train Epoch: 729 [0/11093 (0%)]\tLoss: 1147500544.000000\n",
      "Train Epoch: 729 [5120/11093 (45%)]\tLoss: 1091782272.000000\n",
      "Train Epoch: 729 [8530/11093 (91%)]\tLoss: 1262657295.906213\n",
      "Train Epoch: 730 [0/11093 (0%)]\tLoss: 1315426304.000000\n",
      "Train Epoch: 730 [5120/11093 (45%)]\tLoss: 1265304576.000000\n",
      "Train Epoch: 730 [8530/11093 (91%)]\tLoss: 1154832981.833529\n",
      "Train Epoch: 731 [0/11093 (0%)]\tLoss: 1443323520.000000\n",
      "Train Epoch: 731 [5120/11093 (45%)]\tLoss: 1353125120.000000\n",
      "Train Epoch: 731 [8530/11093 (91%)]\tLoss: 1183202617.322392\n",
      "Train Epoch: 732 [0/11093 (0%)]\tLoss: 1324319104.000000\n",
      "Train Epoch: 732 [5120/11093 (45%)]\tLoss: 1217766912.000000\n",
      "Train Epoch: 732 [8530/11093 (91%)]\tLoss: 1164570571.179367\n",
      "Train Epoch: 733 [0/11093 (0%)]\tLoss: 1168831488.000000\n",
      "Train Epoch: 733 [5120/11093 (45%)]\tLoss: 1363979008.000000\n",
      "Train Epoch: 733 [8530/11093 (91%)]\tLoss: 1300203200.675264\n",
      "Train Epoch: 734 [0/11093 (0%)]\tLoss: 1310488832.000000\n",
      "Train Epoch: 734 [5120/11093 (45%)]\tLoss: 1314419840.000000\n",
      "Train Epoch: 734 [8530/11093 (91%)]\tLoss: 1234379625.941383\n",
      "Train Epoch: 735 [0/11093 (0%)]\tLoss: 1208442880.000000\n",
      "Train Epoch: 735 [5120/11093 (45%)]\tLoss: 1351577600.000000\n",
      "Train Epoch: 735 [8530/11093 (91%)]\tLoss: 1430260583.540446\n",
      "Train Epoch: 736 [0/11093 (0%)]\tLoss: 1479310848.000000\n",
      "Train Epoch: 736 [5120/11093 (45%)]\tLoss: 1363268480.000000\n",
      "Train Epoch: 736 [8530/11093 (91%)]\tLoss: 1237174624.937866\n",
      "Train Epoch: 737 [0/11093 (0%)]\tLoss: 1405089664.000000\n",
      "Train Epoch: 737 [5120/11093 (45%)]\tLoss: 1447597824.000000\n",
      "Train Epoch: 737 [8530/11093 (91%)]\tLoss: 1187832931.638921\n",
      "Train Epoch: 738 [0/11093 (0%)]\tLoss: 1415124608.000000\n",
      "Train Epoch: 738 [5120/11093 (45%)]\tLoss: 1276131712.000000\n",
      "Train Epoch: 738 [8530/11093 (91%)]\tLoss: 1172470156.154748\n",
      "Train Epoch: 739 [0/11093 (0%)]\tLoss: 1313975552.000000\n",
      "Train Epoch: 739 [5120/11093 (45%)]\tLoss: 1266050304.000000\n",
      "Train Epoch: 739 [8530/11093 (91%)]\tLoss: 1166731953.069168\n",
      "Train Epoch: 740 [0/11093 (0%)]\tLoss: 1293291776.000000\n",
      "Train Epoch: 740 [5120/11093 (45%)]\tLoss: 1118353920.000000\n",
      "Train Epoch: 740 [8530/11093 (91%)]\tLoss: 1416560716.830012\n",
      "Train Epoch: 741 [0/11093 (0%)]\tLoss: 1251808128.000000\n",
      "Train Epoch: 741 [5120/11093 (45%)]\tLoss: 1262625792.000000\n",
      "Train Epoch: 741 [8530/11093 (91%)]\tLoss: 1315586412.942556\n",
      "Train Epoch: 742 [0/11093 (0%)]\tLoss: 1187609856.000000\n",
      "Train Epoch: 742 [5120/11093 (45%)]\tLoss: 1265328384.000000\n",
      "Train Epoch: 742 [8530/11093 (91%)]\tLoss: 1465107910.977726\n",
      "Train Epoch: 743 [0/11093 (0%)]\tLoss: 1390070016.000000\n",
      "Train Epoch: 743 [5120/11093 (45%)]\tLoss: 1296756096.000000\n",
      "Train Epoch: 743 [8530/11093 (91%)]\tLoss: 1201726409.978898\n",
      "Train Epoch: 744 [0/11093 (0%)]\tLoss: 1443459712.000000\n",
      "Train Epoch: 744 [5120/11093 (45%)]\tLoss: 1162405888.000000\n",
      "Train Epoch: 744 [8530/11093 (91%)]\tLoss: 1280899660.229777\n",
      "Train Epoch: 745 [0/11093 (0%)]\tLoss: 1385547136.000000\n",
      "Train Epoch: 745 [5120/11093 (45%)]\tLoss: 1261528320.000000\n",
      "Train Epoch: 745 [8530/11093 (91%)]\tLoss: 1389152378.447831\n",
      "Train Epoch: 746 [0/11093 (0%)]\tLoss: 1225278848.000000\n",
      "Train Epoch: 746 [5120/11093 (45%)]\tLoss: 1225803392.000000\n",
      "Train Epoch: 746 [8530/11093 (91%)]\tLoss: 1228242367.774912\n",
      "Train Epoch: 747 [0/11093 (0%)]\tLoss: 1187527552.000000\n",
      "Train Epoch: 747 [5120/11093 (45%)]\tLoss: 1168289664.000000\n",
      "Train Epoch: 747 [8530/11093 (91%)]\tLoss: 1204837564.473623\n",
      "Train Epoch: 748 [0/11093 (0%)]\tLoss: 1455472128.000000\n",
      "Train Epoch: 748 [5120/11093 (45%)]\tLoss: 1366763776.000000\n",
      "Train Epoch: 748 [8530/11093 (91%)]\tLoss: 1200066497.575615\n",
      "Train Epoch: 749 [0/11093 (0%)]\tLoss: 1332403200.000000\n",
      "Train Epoch: 749 [5120/11093 (45%)]\tLoss: 1264205312.000000\n",
      "Train Epoch: 749 [8530/11093 (91%)]\tLoss: 1392722669.092614\n",
      "Train Epoch: 750 [0/11093 (0%)]\tLoss: 1235563008.000000\n",
      "Train Epoch: 750 [5120/11093 (45%)]\tLoss: 1330322176.000000\n",
      "Train Epoch: 750 [8530/11093 (91%)]\tLoss: 1102164625.856975\n",
      "Train Epoch: 751 [0/11093 (0%)]\tLoss: 1232422784.000000\n",
      "Train Epoch: 751 [5120/11093 (45%)]\tLoss: 1331075072.000000\n",
      "Train Epoch: 751 [8530/11093 (91%)]\tLoss: 1327318663.052755\n",
      "Train Epoch: 752 [0/11093 (0%)]\tLoss: 1181455872.000000\n",
      "Train Epoch: 752 [5120/11093 (45%)]\tLoss: 1169538560.000000\n",
      "Train Epoch: 752 [8530/11093 (91%)]\tLoss: 1511437790.987104\n",
      "Train Epoch: 753 [0/11093 (0%)]\tLoss: 1124780928.000000\n",
      "Train Epoch: 753 [5120/11093 (45%)]\tLoss: 1208417024.000000\n",
      "Train Epoch: 753 [8530/11093 (91%)]\tLoss: 1204988381.786635\n",
      "Train Epoch: 754 [0/11093 (0%)]\tLoss: 1186999552.000000\n",
      "Train Epoch: 754 [5120/11093 (45%)]\tLoss: 1442254464.000000\n",
      "Train Epoch: 754 [8530/11093 (91%)]\tLoss: 1285415420.998828\n",
      "Train Epoch: 755 [0/11093 (0%)]\tLoss: 1461957120.000000\n",
      "Train Epoch: 755 [5120/11093 (45%)]\tLoss: 1506314112.000000\n",
      "Train Epoch: 755 [8530/11093 (91%)]\tLoss: 1170295021.692849\n",
      "Train Epoch: 756 [0/11093 (0%)]\tLoss: 1234103296.000000\n",
      "Train Epoch: 756 [5120/11093 (45%)]\tLoss: 1447672576.000000\n",
      "Train Epoch: 756 [8530/11093 (91%)]\tLoss: 1367888904.403283\n",
      "Train Epoch: 757 [0/11093 (0%)]\tLoss: 1479229440.000000\n",
      "Train Epoch: 757 [5120/11093 (45%)]\tLoss: 1462679424.000000\n",
      "Train Epoch: 757 [8530/11093 (91%)]\tLoss: 1194639379.207503\n",
      "Train Epoch: 758 [0/11093 (0%)]\tLoss: 1092304000.000000\n",
      "Train Epoch: 758 [5120/11093 (45%)]\tLoss: 1207945216.000000\n",
      "Train Epoch: 758 [8530/11093 (91%)]\tLoss: 1333939412.483001\n",
      "Train Epoch: 759 [0/11093 (0%)]\tLoss: 1243345920.000000\n",
      "Train Epoch: 759 [5120/11093 (45%)]\tLoss: 1303036672.000000\n",
      "Train Epoch: 759 [8530/11093 (91%)]\tLoss: 1090741847.033998\n",
      "Train Epoch: 760 [0/11093 (0%)]\tLoss: 1517089024.000000\n",
      "Train Epoch: 760 [5120/11093 (45%)]\tLoss: 1122195968.000000\n",
      "Train Epoch: 760 [8530/11093 (91%)]\tLoss: 1236738076.811255\n",
      "Train Epoch: 761 [0/11093 (0%)]\tLoss: 1330498432.000000\n",
      "Train Epoch: 761 [5120/11093 (45%)]\tLoss: 1656626048.000000\n",
      "Train Epoch: 761 [8530/11093 (91%)]\tLoss: 1169377825.012896\n",
      "Train Epoch: 762 [0/11093 (0%)]\tLoss: 1298246144.000000\n",
      "Train Epoch: 762 [5120/11093 (45%)]\tLoss: 1299726080.000000\n",
      "Train Epoch: 762 [8530/11093 (91%)]\tLoss: 1071934935.784291\n",
      "Train Epoch: 763 [0/11093 (0%)]\tLoss: 1320589568.000000\n",
      "Train Epoch: 763 [5120/11093 (45%)]\tLoss: 1358562304.000000\n",
      "Train Epoch: 763 [8530/11093 (91%)]\tLoss: 1028063769.810082\n",
      "Train Epoch: 764 [0/11093 (0%)]\tLoss: 1118123520.000000\n",
      "Train Epoch: 764 [5120/11093 (45%)]\tLoss: 1081982208.000000\n",
      "Train Epoch: 764 [8530/11093 (91%)]\tLoss: 1284431535.868699\n",
      "Train Epoch: 765 [0/11093 (0%)]\tLoss: 1158270208.000000\n",
      "Train Epoch: 765 [5120/11093 (45%)]\tLoss: 1129761280.000000\n",
      "Train Epoch: 765 [8530/11093 (91%)]\tLoss: 1084784217.434936\n",
      "Train Epoch: 766 [0/11093 (0%)]\tLoss: 1476112000.000000\n",
      "Train Epoch: 766 [5120/11093 (45%)]\tLoss: 1246585088.000000\n",
      "Train Epoch: 766 [8530/11093 (91%)]\tLoss: 1516688661.308324\n",
      "Train Epoch: 767 [0/11093 (0%)]\tLoss: 1313035520.000000\n",
      "Train Epoch: 767 [5120/11093 (45%)]\tLoss: 1282498432.000000\n",
      "Train Epoch: 767 [8530/11093 (91%)]\tLoss: 1133477772.754982\n",
      "Train Epoch: 768 [0/11093 (0%)]\tLoss: 1412067456.000000\n",
      "Train Epoch: 768 [5120/11093 (45%)]\tLoss: 1134324224.000000\n",
      "Train Epoch: 768 [8530/11093 (91%)]\tLoss: 1139528597.158265\n",
      "Train Epoch: 769 [0/11093 (0%)]\tLoss: 1160636928.000000\n",
      "Train Epoch: 769 [5120/11093 (45%)]\tLoss: 1421043968.000000\n",
      "Train Epoch: 769 [8530/11093 (91%)]\tLoss: 1230379855.531067\n",
      "Train Epoch: 770 [0/11093 (0%)]\tLoss: 1471623296.000000\n",
      "Train Epoch: 770 [5120/11093 (45%)]\tLoss: 1382403584.000000\n",
      "Train Epoch: 770 [8530/11093 (91%)]\tLoss: 1131688939.592028\n",
      "Train Epoch: 771 [0/11093 (0%)]\tLoss: 1270132480.000000\n",
      "Train Epoch: 771 [5120/11093 (45%)]\tLoss: 1244298880.000000\n",
      "Train Epoch: 771 [8530/11093 (91%)]\tLoss: 1153252588.492380\n",
      "Train Epoch: 772 [0/11093 (0%)]\tLoss: 1221791744.000000\n",
      "Train Epoch: 772 [5120/11093 (45%)]\tLoss: 1481656192.000000\n",
      "Train Epoch: 772 [8530/11093 (91%)]\tLoss: 1130393124.614302\n",
      "Train Epoch: 773 [0/11093 (0%)]\tLoss: 1103472128.000000\n",
      "Train Epoch: 773 [5120/11093 (45%)]\tLoss: 1271353344.000000\n",
      "Train Epoch: 773 [8530/11093 (91%)]\tLoss: 1399510139.648300\n",
      "Train Epoch: 774 [0/11093 (0%)]\tLoss: 1232094848.000000\n",
      "Train Epoch: 774 [5120/11093 (45%)]\tLoss: 1219358720.000000\n",
      "Train Epoch: 774 [8530/11093 (91%)]\tLoss: 1506194296.347011\n",
      "Train Epoch: 775 [0/11093 (0%)]\tLoss: 1428961280.000000\n",
      "Train Epoch: 775 [5120/11093 (45%)]\tLoss: 1265357056.000000\n",
      "Train Epoch: 775 [8530/11093 (91%)]\tLoss: 1212818819.751465\n",
      "Train Epoch: 776 [0/11093 (0%)]\tLoss: 1283742976.000000\n",
      "Train Epoch: 776 [5120/11093 (45%)]\tLoss: 1362989056.000000\n",
      "Train Epoch: 776 [8530/11093 (91%)]\tLoss: 1278505176.084408\n",
      "Train Epoch: 777 [0/11093 (0%)]\tLoss: 1218263168.000000\n",
      "Train Epoch: 777 [5120/11093 (45%)]\tLoss: 1127374976.000000\n",
      "Train Epoch: 777 [8530/11093 (91%)]\tLoss: 1329822553.134818\n",
      "Train Epoch: 778 [0/11093 (0%)]\tLoss: 1298441984.000000\n",
      "Train Epoch: 778 [5120/11093 (45%)]\tLoss: 1321962752.000000\n",
      "Train Epoch: 778 [8530/11093 (91%)]\tLoss: 1228353233.481829\n",
      "Train Epoch: 779 [0/11093 (0%)]\tLoss: 1340643584.000000\n",
      "Train Epoch: 779 [5120/11093 (45%)]\tLoss: 1249801088.000000\n",
      "Train Epoch: 779 [8530/11093 (91%)]\tLoss: 1094043847.277843\n",
      "Train Epoch: 780 [0/11093 (0%)]\tLoss: 1188372352.000000\n",
      "Train Epoch: 780 [5120/11093 (45%)]\tLoss: 1357693184.000000\n",
      "Train Epoch: 780 [8530/11093 (91%)]\tLoss: 1483402673.369285\n",
      "Train Epoch: 781 [0/11093 (0%)]\tLoss: 1346585600.000000\n",
      "Train Epoch: 781 [5120/11093 (45%)]\tLoss: 1244735232.000000\n",
      "Train Epoch: 781 [8530/11093 (91%)]\tLoss: 1344208972.830012\n",
      "Train Epoch: 782 [0/11093 (0%)]\tLoss: 1324748288.000000\n",
      "Train Epoch: 782 [5120/11093 (45%)]\tLoss: 1407651328.000000\n",
      "Train Epoch: 782 [8530/11093 (91%)]\tLoss: 1165578580.933177\n",
      "Train Epoch: 783 [0/11093 (0%)]\tLoss: 1155936256.000000\n",
      "Train Epoch: 783 [5120/11093 (45%)]\tLoss: 1317674240.000000\n",
      "Train Epoch: 783 [8530/11093 (91%)]\tLoss: 1388834148.539273\n",
      "Train Epoch: 784 [0/11093 (0%)]\tLoss: 1300175616.000000\n",
      "Train Epoch: 784 [5120/11093 (45%)]\tLoss: 1267609728.000000\n",
      "Train Epoch: 784 [8530/11093 (91%)]\tLoss: 1244049912.196952\n",
      "Train Epoch: 785 [0/11093 (0%)]\tLoss: 1512877184.000000\n",
      "Train Epoch: 785 [5120/11093 (45%)]\tLoss: 1174570752.000000\n",
      "Train Epoch: 785 [8530/11093 (91%)]\tLoss: 1168122268.961313\n",
      "Train Epoch: 786 [0/11093 (0%)]\tLoss: 1393768704.000000\n",
      "Train Epoch: 786 [5120/11093 (45%)]\tLoss: 1248706048.000000\n",
      "Train Epoch: 786 [8530/11093 (91%)]\tLoss: 1483952776.253224\n",
      "Train Epoch: 787 [0/11093 (0%)]\tLoss: 1249053568.000000\n",
      "Train Epoch: 787 [5120/11093 (45%)]\tLoss: 1231357184.000000\n",
      "Train Epoch: 787 [8530/11093 (91%)]\tLoss: 1116178880.975381\n",
      "Train Epoch: 788 [0/11093 (0%)]\tLoss: 1386411392.000000\n",
      "Train Epoch: 788 [5120/11093 (45%)]\tLoss: 1142439168.000000\n",
      "Train Epoch: 788 [8530/11093 (91%)]\tLoss: 1227541831.728019\n",
      "Train Epoch: 789 [0/11093 (0%)]\tLoss: 1163976960.000000\n",
      "Train Epoch: 789 [5120/11093 (45%)]\tLoss: 1289738880.000000\n",
      "Train Epoch: 789 [8530/11093 (91%)]\tLoss: 1268778650.260258\n",
      "Train Epoch: 790 [0/11093 (0%)]\tLoss: 1199254016.000000\n",
      "Train Epoch: 790 [5120/11093 (45%)]\tLoss: 1501542656.000000\n",
      "Train Epoch: 790 [8530/11093 (91%)]\tLoss: 1394384809.566237\n",
      "Train Epoch: 791 [0/11093 (0%)]\tLoss: 1053471104.000000\n",
      "Train Epoch: 791 [5120/11093 (45%)]\tLoss: 1637901696.000000\n",
      "Train Epoch: 791 [8530/11093 (91%)]\tLoss: 1474798019.376319\n",
      "Train Epoch: 792 [0/11093 (0%)]\tLoss: 1223786496.000000\n",
      "Train Epoch: 792 [5120/11093 (45%)]\tLoss: 1473325568.000000\n",
      "Train Epoch: 792 [8530/11093 (91%)]\tLoss: 1334404234.053927\n",
      "Train Epoch: 793 [0/11093 (0%)]\tLoss: 1444962048.000000\n",
      "Train Epoch: 793 [5120/11093 (45%)]\tLoss: 1210981376.000000\n",
      "Train Epoch: 793 [8530/11093 (91%)]\tLoss: 1281827075.301290\n",
      "Train Epoch: 794 [0/11093 (0%)]\tLoss: 1162769536.000000\n",
      "Train Epoch: 794 [5120/11093 (45%)]\tLoss: 1207972992.000000\n",
      "Train Epoch: 794 [8530/11093 (91%)]\tLoss: 1177849332.595545\n",
      "Train Epoch: 795 [0/11093 (0%)]\tLoss: 1169782016.000000\n",
      "Train Epoch: 795 [5120/11093 (45%)]\tLoss: 1301616896.000000\n",
      "Train Epoch: 795 [8530/11093 (91%)]\tLoss: 1103480339.807737\n",
      "Train Epoch: 796 [0/11093 (0%)]\tLoss: 1722040448.000000\n",
      "Train Epoch: 796 [5120/11093 (45%)]\tLoss: 1179552384.000000\n",
      "Train Epoch: 796 [8530/11093 (91%)]\tLoss: 1339200117.045721\n",
      "Train Epoch: 797 [0/11093 (0%)]\tLoss: 1493576448.000000\n",
      "Train Epoch: 797 [5120/11093 (45%)]\tLoss: 1303893120.000000\n",
      "Train Epoch: 797 [8530/11093 (91%)]\tLoss: 1110908726.321219\n",
      "Train Epoch: 798 [0/11093 (0%)]\tLoss: 1174226048.000000\n",
      "Train Epoch: 798 [5120/11093 (45%)]\tLoss: 1196807168.000000\n",
      "Train Epoch: 798 [8530/11093 (91%)]\tLoss: 1337028286.274326\n",
      "Train Epoch: 799 [0/11093 (0%)]\tLoss: 1266679808.000000\n",
      "Train Epoch: 799 [5120/11093 (45%)]\tLoss: 1131271424.000000\n",
      "Train Epoch: 799 [8530/11093 (91%)]\tLoss: 1467007763.507620\n",
      "Train Epoch: 800 [0/11093 (0%)]\tLoss: 1099390464.000000\n",
      "Train Epoch: 800 [5120/11093 (45%)]\tLoss: 1426876672.000000\n",
      "Train Epoch: 800 [8530/11093 (91%)]\tLoss: 1103419951.418523\n",
      "====> Epoch: 800 Average loss: 1292019258.3864\n",
      "Train Epoch: 801 [0/11093 (0%)]\tLoss: 1469973248.000000\n",
      "Train Epoch: 801 [5120/11093 (45%)]\tLoss: 1152317440.000000\n",
      "Train Epoch: 801 [8530/11093 (91%)]\tLoss: 1312011358.837046\n",
      "Train Epoch: 802 [0/11093 (0%)]\tLoss: 1218989056.000000\n",
      "Train Epoch: 802 [5120/11093 (45%)]\tLoss: 1098883328.000000\n",
      "Train Epoch: 802 [8530/11093 (91%)]\tLoss: 1630909995.817116\n",
      "Train Epoch: 803 [0/11093 (0%)]\tLoss: 1210942976.000000\n",
      "Train Epoch: 803 [5120/11093 (45%)]\tLoss: 1353473024.000000\n",
      "Train Epoch: 803 [8530/11093 (91%)]\tLoss: 1612953746.457210\n",
      "Train Epoch: 804 [0/11093 (0%)]\tLoss: 1165051648.000000\n",
      "Train Epoch: 804 [5120/11093 (45%)]\tLoss: 1463834368.000000\n",
      "Train Epoch: 804 [8530/11093 (91%)]\tLoss: 1381685730.588511\n",
      "Train Epoch: 805 [0/11093 (0%)]\tLoss: 1682744320.000000\n",
      "Train Epoch: 805 [5120/11093 (45%)]\tLoss: 1265876736.000000\n",
      "Train Epoch: 805 [8530/11093 (91%)]\tLoss: 1419707981.430246\n",
      "Train Epoch: 806 [0/11093 (0%)]\tLoss: 1338729600.000000\n",
      "Train Epoch: 806 [5120/11093 (45%)]\tLoss: 1248552704.000000\n",
      "Train Epoch: 806 [8530/11093 (91%)]\tLoss: 1406334181.289566\n",
      "Train Epoch: 807 [0/11093 (0%)]\tLoss: 1284173952.000000\n",
      "Train Epoch: 807 [5120/11093 (45%)]\tLoss: 995095552.000000\n",
      "Train Epoch: 807 [8530/11093 (91%)]\tLoss: 1332565538.213365\n",
      "Train Epoch: 808 [0/11093 (0%)]\tLoss: 1170344960.000000\n",
      "Train Epoch: 808 [5120/11093 (45%)]\tLoss: 1416395776.000000\n",
      "Train Epoch: 808 [8530/11093 (91%)]\tLoss: 1310436650.916764\n",
      "Train Epoch: 809 [0/11093 (0%)]\tLoss: 1581703808.000000\n",
      "Train Epoch: 809 [5120/11093 (45%)]\tLoss: 1187176832.000000\n",
      "Train Epoch: 809 [8530/11093 (91%)]\tLoss: 1148385176.759672\n",
      "Train Epoch: 810 [0/11093 (0%)]\tLoss: 1345302272.000000\n",
      "Train Epoch: 810 [5120/11093 (45%)]\tLoss: 1071780224.000000\n",
      "Train Epoch: 810 [8530/11093 (91%)]\tLoss: 1257238475.179367\n",
      "Train Epoch: 811 [0/11093 (0%)]\tLoss: 1268317696.000000\n",
      "Train Epoch: 811 [5120/11093 (45%)]\tLoss: 1200845312.000000\n",
      "Train Epoch: 811 [8530/11093 (91%)]\tLoss: 1177458114.175850\n",
      "Train Epoch: 812 [0/11093 (0%)]\tLoss: 1352539392.000000\n",
      "Train Epoch: 812 [5120/11093 (45%)]\tLoss: 1239653376.000000\n",
      "Train Epoch: 812 [8530/11093 (91%)]\tLoss: 1263480145.331770\n",
      "Train Epoch: 813 [0/11093 (0%)]\tLoss: 1220465792.000000\n",
      "Train Epoch: 813 [5120/11093 (45%)]\tLoss: 1290516608.000000\n",
      "Train Epoch: 813 [8530/11093 (91%)]\tLoss: 1265106483.019930\n",
      "Train Epoch: 814 [0/11093 (0%)]\tLoss: 1226814592.000000\n",
      "Train Epoch: 814 [5120/11093 (45%)]\tLoss: 1195158528.000000\n",
      "Train Epoch: 814 [8530/11093 (91%)]\tLoss: 1293021745.819461\n",
      "Train Epoch: 815 [0/11093 (0%)]\tLoss: 1359639040.000000\n",
      "Train Epoch: 815 [5120/11093 (45%)]\tLoss: 1163835136.000000\n",
      "Train Epoch: 815 [8530/11093 (91%)]\tLoss: 1107602269.936694\n",
      "Train Epoch: 816 [0/11093 (0%)]\tLoss: 1269724544.000000\n",
      "Train Epoch: 816 [5120/11093 (45%)]\tLoss: 1276614784.000000\n",
      "Train Epoch: 816 [8530/11093 (91%)]\tLoss: 1309387767.596717\n",
      "Train Epoch: 817 [0/11093 (0%)]\tLoss: 1455173632.000000\n",
      "Train Epoch: 817 [5120/11093 (45%)]\tLoss: 1309371136.000000\n",
      "Train Epoch: 817 [8530/11093 (91%)]\tLoss: 1565583280.769050\n",
      "Train Epoch: 818 [0/11093 (0%)]\tLoss: 1407793664.000000\n",
      "Train Epoch: 818 [5120/11093 (45%)]\tLoss: 1434511360.000000\n",
      "Train Epoch: 818 [8530/11093 (91%)]\tLoss: 1361405988.014068\n",
      "Train Epoch: 819 [0/11093 (0%)]\tLoss: 1309827072.000000\n",
      "Train Epoch: 819 [5120/11093 (45%)]\tLoss: 1310865920.000000\n",
      "Train Epoch: 819 [8530/11093 (91%)]\tLoss: 1300736861.936694\n",
      "Train Epoch: 820 [0/11093 (0%)]\tLoss: 1179806208.000000\n",
      "Train Epoch: 820 [5120/11093 (45%)]\tLoss: 1336014848.000000\n",
      "Train Epoch: 820 [8530/11093 (91%)]\tLoss: 1296161634.738570\n",
      "Train Epoch: 821 [0/11093 (0%)]\tLoss: 1264571776.000000\n",
      "Train Epoch: 821 [5120/11093 (45%)]\tLoss: 1249648128.000000\n",
      "Train Epoch: 821 [8530/11093 (91%)]\tLoss: 1192455025.144197\n",
      "Train Epoch: 822 [0/11093 (0%)]\tLoss: 1284177152.000000\n",
      "Train Epoch: 822 [5120/11093 (45%)]\tLoss: 1162875904.000000\n",
      "Train Epoch: 822 [8530/11093 (91%)]\tLoss: 1330679361.425557\n",
      "Train Epoch: 823 [0/11093 (0%)]\tLoss: 1283233792.000000\n",
      "Train Epoch: 823 [5120/11093 (45%)]\tLoss: 1320222976.000000\n",
      "Train Epoch: 823 [8530/11093 (91%)]\tLoss: 1137926691.413834\n",
      "Train Epoch: 824 [0/11093 (0%)]\tLoss: 1315989504.000000\n",
      "Train Epoch: 824 [5120/11093 (45%)]\tLoss: 1440185728.000000\n",
      "Train Epoch: 824 [8530/11093 (91%)]\tLoss: 1277586442.804220\n",
      "Train Epoch: 825 [0/11093 (0%)]\tLoss: 1201924096.000000\n",
      "Train Epoch: 825 [5120/11093 (45%)]\tLoss: 1173453824.000000\n",
      "Train Epoch: 825 [8530/11093 (91%)]\tLoss: 1395428161.125440\n",
      "Train Epoch: 826 [0/11093 (0%)]\tLoss: 1157052672.000000\n",
      "Train Epoch: 826 [5120/11093 (45%)]\tLoss: 1757934848.000000\n",
      "Train Epoch: 826 [8530/11093 (91%)]\tLoss: 1408843756.792497\n",
      "Train Epoch: 827 [0/11093 (0%)]\tLoss: 1272474112.000000\n",
      "Train Epoch: 827 [5120/11093 (45%)]\tLoss: 1173184896.000000\n",
      "Train Epoch: 827 [8530/11093 (91%)]\tLoss: 1217792564.220399\n",
      "Train Epoch: 828 [0/11093 (0%)]\tLoss: 1149940096.000000\n",
      "Train Epoch: 828 [5120/11093 (45%)]\tLoss: 1122513024.000000\n",
      "Train Epoch: 828 [8530/11093 (91%)]\tLoss: 1262352818.569754\n",
      "Train Epoch: 829 [0/11093 (0%)]\tLoss: 1206718464.000000\n",
      "Train Epoch: 829 [5120/11093 (45%)]\tLoss: 1292514304.000000\n",
      "Train Epoch: 829 [8530/11093 (91%)]\tLoss: 1506370698.053927\n",
      "Train Epoch: 830 [0/11093 (0%)]\tLoss: 1232914048.000000\n",
      "Train Epoch: 830 [5120/11093 (45%)]\tLoss: 1384232448.000000\n",
      "Train Epoch: 830 [8530/11093 (91%)]\tLoss: 1268355240.065651\n",
      "Train Epoch: 831 [0/11093 (0%)]\tLoss: 1075192832.000000\n",
      "Train Epoch: 831 [5120/11093 (45%)]\tLoss: 1507407488.000000\n",
      "Train Epoch: 831 [8530/11093 (91%)]\tLoss: 1187791212.942556\n",
      "Train Epoch: 832 [0/11093 (0%)]\tLoss: 1254578944.000000\n",
      "Train Epoch: 832 [5120/11093 (45%)]\tLoss: 1374131328.000000\n",
      "Train Epoch: 832 [8530/11093 (91%)]\tLoss: 1261513834.841735\n",
      "Train Epoch: 833 [0/11093 (0%)]\tLoss: 1427060736.000000\n",
      "Train Epoch: 833 [5120/11093 (45%)]\tLoss: 1044145024.000000\n",
      "Train Epoch: 833 [8530/11093 (91%)]\tLoss: 1318660842.691676\n",
      "Train Epoch: 834 [0/11093 (0%)]\tLoss: 1339364608.000000\n",
      "Train Epoch: 834 [5120/11093 (45%)]\tLoss: 1193603584.000000\n",
      "Train Epoch: 834 [8530/11093 (91%)]\tLoss: 1365679580.586166\n",
      "Train Epoch: 835 [0/11093 (0%)]\tLoss: 1455343232.000000\n",
      "Train Epoch: 835 [5120/11093 (45%)]\tLoss: 1121830528.000000\n",
      "Train Epoch: 835 [8530/11093 (91%)]\tLoss: 1090455885.730363\n",
      "Train Epoch: 836 [0/11093 (0%)]\tLoss: 1145814912.000000\n",
      "Train Epoch: 836 [5120/11093 (45%)]\tLoss: 1367684096.000000\n",
      "Train Epoch: 836 [8530/11093 (91%)]\tLoss: 1354970091.592028\n",
      "Train Epoch: 837 [0/11093 (0%)]\tLoss: 1273490688.000000\n",
      "Train Epoch: 837 [5120/11093 (45%)]\tLoss: 1224268544.000000\n",
      "Train Epoch: 837 [8530/11093 (91%)]\tLoss: 1620878147.526377\n",
      "Train Epoch: 838 [0/11093 (0%)]\tLoss: 1304206336.000000\n",
      "Train Epoch: 838 [5120/11093 (45%)]\tLoss: 1195343872.000000\n",
      "Train Epoch: 838 [8530/11093 (91%)]\tLoss: 1252647728.318875\n",
      "Train Epoch: 839 [0/11093 (0%)]\tLoss: 1222001920.000000\n",
      "Train Epoch: 839 [5120/11093 (45%)]\tLoss: 1294721792.000000\n",
      "Train Epoch: 839 [8530/11093 (91%)]\tLoss: 1243937509.889801\n",
      "Train Epoch: 840 [0/11093 (0%)]\tLoss: 1538108160.000000\n",
      "Train Epoch: 840 [5120/11093 (45%)]\tLoss: 1092193536.000000\n",
      "Train Epoch: 840 [8530/11093 (91%)]\tLoss: 1050834034.044549\n",
      "Train Epoch: 841 [0/11093 (0%)]\tLoss: 1207043840.000000\n",
      "Train Epoch: 841 [5120/11093 (45%)]\tLoss: 1097723136.000000\n",
      "Train Epoch: 841 [8530/11093 (91%)]\tLoss: 1192586711.784291\n",
      "Train Epoch: 842 [0/11093 (0%)]\tLoss: 1558246656.000000\n",
      "Train Epoch: 842 [5120/11093 (45%)]\tLoss: 1632764032.000000\n",
      "Train Epoch: 842 [8530/11093 (91%)]\tLoss: 1166713974.846424\n",
      "Train Epoch: 843 [0/11093 (0%)]\tLoss: 1247281536.000000\n",
      "Train Epoch: 843 [5120/11093 (45%)]\tLoss: 1247242624.000000\n",
      "Train Epoch: 843 [8530/11093 (91%)]\tLoss: 1839564480.675264\n",
      "Train Epoch: 844 [0/11093 (0%)]\tLoss: 1404918400.000000\n",
      "Train Epoch: 844 [5120/11093 (45%)]\tLoss: 1407652352.000000\n",
      "Train Epoch: 844 [8530/11093 (91%)]\tLoss: 1106174537.828839\n",
      "Train Epoch: 845 [0/11093 (0%)]\tLoss: 1064462080.000000\n",
      "Train Epoch: 845 [5120/11093 (45%)]\tLoss: 1252333056.000000\n",
      "Train Epoch: 845 [8530/11093 (91%)]\tLoss: 1294769782.246190\n",
      "Train Epoch: 846 [0/11093 (0%)]\tLoss: 1341578880.000000\n",
      "Train Epoch: 846 [5120/11093 (45%)]\tLoss: 1275386240.000000\n",
      "Train Epoch: 846 [8530/11093 (91%)]\tLoss: 1134215340.867526\n",
      "Train Epoch: 847 [0/11093 (0%)]\tLoss: 1481873664.000000\n",
      "Train Epoch: 847 [5120/11093 (45%)]\tLoss: 1056635264.000000\n",
      "Train Epoch: 847 [8530/11093 (91%)]\tLoss: 1223446638.443142\n",
      "Train Epoch: 848 [0/11093 (0%)]\tLoss: 1200756992.000000\n",
      "Train Epoch: 848 [5120/11093 (45%)]\tLoss: 1191528960.000000\n",
      "Train Epoch: 848 [8530/11093 (91%)]\tLoss: 1157047760.581477\n",
      "Train Epoch: 849 [0/11093 (0%)]\tLoss: 1227382016.000000\n",
      "Train Epoch: 849 [5120/11093 (45%)]\tLoss: 1216784128.000000\n",
      "Train Epoch: 849 [8530/11093 (91%)]\tLoss: 1367052532.895662\n",
      "Train Epoch: 850 [0/11093 (0%)]\tLoss: 1159949824.000000\n",
      "Train Epoch: 850 [5120/11093 (45%)]\tLoss: 1313728256.000000\n",
      "Train Epoch: 850 [8530/11093 (91%)]\tLoss: 1536397095.915592\n",
      "Train Epoch: 851 [0/11093 (0%)]\tLoss: 1308302080.000000\n",
      "Train Epoch: 851 [5120/11093 (45%)]\tLoss: 1314547968.000000\n",
      "Train Epoch: 851 [8530/11093 (91%)]\tLoss: 1249707904.750293\n",
      "Train Epoch: 852 [0/11093 (0%)]\tLoss: 1487712768.000000\n",
      "Train Epoch: 852 [5120/11093 (45%)]\tLoss: 1362796672.000000\n",
      "Train Epoch: 852 [8530/11093 (91%)]\tLoss: 1094296464.356389\n",
      "Train Epoch: 853 [0/11093 (0%)]\tLoss: 1225602816.000000\n",
      "Train Epoch: 853 [5120/11093 (45%)]\tLoss: 1333605888.000000\n",
      "Train Epoch: 853 [8530/11093 (91%)]\tLoss: 1707619384.422040\n",
      "Train Epoch: 854 [0/11093 (0%)]\tLoss: 1386508928.000000\n",
      "Train Epoch: 854 [5120/11093 (45%)]\tLoss: 1088455680.000000\n",
      "Train Epoch: 854 [8530/11093 (91%)]\tLoss: 1230818170.747948\n",
      "Train Epoch: 855 [0/11093 (0%)]\tLoss: 1296226560.000000\n",
      "Train Epoch: 855 [5120/11093 (45%)]\tLoss: 1501205504.000000\n",
      "Train Epoch: 855 [8530/11093 (91%)]\tLoss: 1240996457.041032\n",
      "Train Epoch: 856 [0/11093 (0%)]\tLoss: 1272684288.000000\n",
      "Train Epoch: 856 [5120/11093 (45%)]\tLoss: 1148966912.000000\n",
      "Train Epoch: 856 [8530/11093 (91%)]\tLoss: 1102894818.288394\n",
      "Train Epoch: 857 [0/11093 (0%)]\tLoss: 1126749696.000000\n",
      "Train Epoch: 857 [5120/11093 (45%)]\tLoss: 1218973568.000000\n",
      "Train Epoch: 857 [8530/11093 (91%)]\tLoss: 1437258414.668230\n",
      "Train Epoch: 858 [0/11093 (0%)]\tLoss: 1164096768.000000\n",
      "Train Epoch: 858 [5120/11093 (45%)]\tLoss: 1377362176.000000\n",
      "Train Epoch: 858 [8530/11093 (91%)]\tLoss: 1241316684.529895\n",
      "Train Epoch: 859 [0/11093 (0%)]\tLoss: 1341107712.000000\n",
      "Train Epoch: 859 [5120/11093 (45%)]\tLoss: 1474862592.000000\n",
      "Train Epoch: 859 [8530/11093 (91%)]\tLoss: 1509882905.209848\n",
      "Train Epoch: 860 [0/11093 (0%)]\tLoss: 1315303680.000000\n",
      "Train Epoch: 860 [5120/11093 (45%)]\tLoss: 1475148928.000000\n",
      "Train Epoch: 860 [8530/11093 (91%)]\tLoss: 1231654081.275498\n",
      "Train Epoch: 861 [0/11093 (0%)]\tLoss: 1297490560.000000\n",
      "Train Epoch: 861 [5120/11093 (45%)]\tLoss: 1321010176.000000\n",
      "Train Epoch: 861 [8530/11093 (91%)]\tLoss: 1214019903.324736\n",
      "Train Epoch: 862 [0/11093 (0%)]\tLoss: 1144191488.000000\n",
      "Train Epoch: 862 [5120/11093 (45%)]\tLoss: 1279022080.000000\n",
      "Train Epoch: 862 [8530/11093 (91%)]\tLoss: 1260102467.526377\n",
      "Train Epoch: 863 [0/11093 (0%)]\tLoss: 1164046592.000000\n",
      "Train Epoch: 863 [5120/11093 (45%)]\tLoss: 1226742016.000000\n",
      "Train Epoch: 863 [8530/11093 (91%)]\tLoss: 1269729037.505275\n",
      "Train Epoch: 864 [0/11093 (0%)]\tLoss: 1225160960.000000\n",
      "Train Epoch: 864 [5120/11093 (45%)]\tLoss: 1263884544.000000\n",
      "Train Epoch: 864 [8530/11093 (91%)]\tLoss: 1497670928.506448\n",
      "Train Epoch: 865 [0/11093 (0%)]\tLoss: 1270623232.000000\n",
      "Train Epoch: 865 [5120/11093 (45%)]\tLoss: 1139103232.000000\n",
      "Train Epoch: 865 [8530/11093 (91%)]\tLoss: 1183600135.803048\n",
      "Train Epoch: 866 [0/11093 (0%)]\tLoss: 1284522240.000000\n",
      "Train Epoch: 866 [5120/11093 (45%)]\tLoss: 1194903680.000000\n",
      "Train Epoch: 866 [8530/11093 (91%)]\tLoss: 1199875959.146542\n",
      "Train Epoch: 867 [0/11093 (0%)]\tLoss: 1206193280.000000\n",
      "Train Epoch: 867 [5120/11093 (45%)]\tLoss: 1158443776.000000\n",
      "Train Epoch: 867 [8530/11093 (91%)]\tLoss: 1203651155.432591\n",
      "Train Epoch: 868 [0/11093 (0%)]\tLoss: 1221596288.000000\n",
      "Train Epoch: 868 [5120/11093 (45%)]\tLoss: 1242151168.000000\n",
      "Train Epoch: 868 [8530/11093 (91%)]\tLoss: 1253721427.732708\n",
      "Train Epoch: 869 [0/11093 (0%)]\tLoss: 1177560576.000000\n",
      "Train Epoch: 869 [5120/11093 (45%)]\tLoss: 1633250816.000000\n",
      "Train Epoch: 869 [8530/11093 (91%)]\tLoss: 1347061978.485346\n",
      "Train Epoch: 870 [0/11093 (0%)]\tLoss: 1288186624.000000\n",
      "Train Epoch: 870 [5120/11093 (45%)]\tLoss: 1215517696.000000\n",
      "Train Epoch: 870 [8530/11093 (91%)]\tLoss: 1117842711.709261\n",
      "Train Epoch: 871 [0/11093 (0%)]\tLoss: 1153323008.000000\n",
      "Train Epoch: 871 [5120/11093 (45%)]\tLoss: 1304382080.000000\n",
      "Train Epoch: 871 [8530/11093 (91%)]\tLoss: 1363603940.989449\n",
      "Train Epoch: 872 [0/11093 (0%)]\tLoss: 1385752576.000000\n",
      "Train Epoch: 872 [5120/11093 (45%)]\tLoss: 1131795968.000000\n",
      "Train Epoch: 872 [8530/11093 (91%)]\tLoss: 1206321536.150059\n",
      "Train Epoch: 873 [0/11093 (0%)]\tLoss: 1234149632.000000\n",
      "Train Epoch: 873 [5120/11093 (45%)]\tLoss: 1241145856.000000\n",
      "Train Epoch: 873 [8530/11093 (91%)]\tLoss: 1242966071.221571\n",
      "Train Epoch: 874 [0/11093 (0%)]\tLoss: 1403229440.000000\n",
      "Train Epoch: 874 [5120/11093 (45%)]\tLoss: 1204997632.000000\n",
      "Train Epoch: 874 [8530/11093 (91%)]\tLoss: 1133215475.094959\n",
      "Train Epoch: 875 [0/11093 (0%)]\tLoss: 1222716416.000000\n",
      "Train Epoch: 875 [5120/11093 (45%)]\tLoss: 1280011264.000000\n",
      "Train Epoch: 875 [8530/11093 (91%)]\tLoss: 1380011297.313013\n",
      "Train Epoch: 876 [0/11093 (0%)]\tLoss: 1440576256.000000\n",
      "Train Epoch: 876 [5120/11093 (45%)]\tLoss: 1269907840.000000\n",
      "Train Epoch: 876 [8530/11093 (91%)]\tLoss: 1282289899.291911\n",
      "Train Epoch: 877 [0/11093 (0%)]\tLoss: 1187116032.000000\n",
      "Train Epoch: 877 [5120/11093 (45%)]\tLoss: 1468663680.000000\n",
      "Train Epoch: 877 [8530/11093 (91%)]\tLoss: 1162020659.920281\n",
      "Train Epoch: 878 [0/11093 (0%)]\tLoss: 1288919808.000000\n",
      "Train Epoch: 878 [5120/11093 (45%)]\tLoss: 1467213824.000000\n",
      "Train Epoch: 878 [8530/11093 (91%)]\tLoss: 1395834438.227432\n",
      "Train Epoch: 879 [0/11093 (0%)]\tLoss: 1289328896.000000\n",
      "Train Epoch: 879 [5120/11093 (45%)]\tLoss: 1297230080.000000\n",
      "Train Epoch: 879 [8530/11093 (91%)]\tLoss: 1277863030.846424\n",
      "Train Epoch: 880 [0/11093 (0%)]\tLoss: 1148677760.000000\n",
      "Train Epoch: 880 [5120/11093 (45%)]\tLoss: 1371527424.000000\n",
      "Train Epoch: 880 [8530/11093 (91%)]\tLoss: 1270586767.756155\n",
      "Train Epoch: 881 [0/11093 (0%)]\tLoss: 1259887616.000000\n",
      "Train Epoch: 881 [5120/11093 (45%)]\tLoss: 1411041024.000000\n",
      "Train Epoch: 881 [8530/11093 (91%)]\tLoss: 1339262349.355217\n",
      "Train Epoch: 882 [0/11093 (0%)]\tLoss: 1477622272.000000\n",
      "Train Epoch: 882 [5120/11093 (45%)]\tLoss: 1372496896.000000\n",
      "Train Epoch: 882 [8530/11093 (91%)]\tLoss: 1360003072.000000\n",
      "Train Epoch: 883 [0/11093 (0%)]\tLoss: 1212607232.000000\n",
      "Train Epoch: 883 [5120/11093 (45%)]\tLoss: 1258908416.000000\n",
      "Train Epoch: 883 [8530/11093 (91%)]\tLoss: 1259090539.441970\n",
      "Train Epoch: 884 [0/11093 (0%)]\tLoss: 1261502976.000000\n",
      "Train Epoch: 884 [5120/11093 (45%)]\tLoss: 1226018560.000000\n",
      "Train Epoch: 884 [8530/11093 (91%)]\tLoss: 1438229238.696366\n",
      "Train Epoch: 885 [0/11093 (0%)]\tLoss: 1304014080.000000\n",
      "Train Epoch: 885 [5120/11093 (45%)]\tLoss: 1128033152.000000\n",
      "Train Epoch: 885 [8530/11093 (91%)]\tLoss: 1178254764.567409\n",
      "Train Epoch: 886 [0/11093 (0%)]\tLoss: 1587952896.000000\n",
      "Train Epoch: 886 [5120/11093 (45%)]\tLoss: 1293836160.000000\n",
      "Train Epoch: 886 [8530/11093 (91%)]\tLoss: 1262320165.814771\n",
      "Train Epoch: 887 [0/11093 (0%)]\tLoss: 1236383232.000000\n",
      "Train Epoch: 887 [5120/11093 (45%)]\tLoss: 1415643776.000000\n",
      "Train Epoch: 887 [8530/11093 (91%)]\tLoss: 1203782842.072685\n",
      "Train Epoch: 888 [0/11093 (0%)]\tLoss: 1109144064.000000\n",
      "Train Epoch: 888 [5120/11093 (45%)]\tLoss: 1233011456.000000\n",
      "Train Epoch: 888 [8530/11093 (91%)]\tLoss: 1678291217.706917\n",
      "Train Epoch: 889 [0/11093 (0%)]\tLoss: 1329122560.000000\n",
      "Train Epoch: 889 [5120/11093 (45%)]\tLoss: 1327491968.000000\n",
      "Train Epoch: 889 [8530/11093 (91%)]\tLoss: 1343144262.527550\n",
      "Train Epoch: 890 [0/11093 (0%)]\tLoss: 1314568448.000000\n",
      "Train Epoch: 890 [5120/11093 (45%)]\tLoss: 1081914368.000000\n",
      "Train Epoch: 890 [8530/11093 (91%)]\tLoss: 1394379431.465416\n",
      "Train Epoch: 891 [0/11093 (0%)]\tLoss: 1282441344.000000\n",
      "Train Epoch: 891 [5120/11093 (45%)]\tLoss: 1217699840.000000\n",
      "Train Epoch: 891 [8530/11093 (91%)]\tLoss: 1295856465.932005\n",
      "Train Epoch: 892 [0/11093 (0%)]\tLoss: 1408134656.000000\n",
      "Train Epoch: 892 [5120/11093 (45%)]\tLoss: 1085774592.000000\n",
      "Train Epoch: 892 [8530/11093 (91%)]\tLoss: 1273519138.813599\n",
      "Train Epoch: 893 [0/11093 (0%)]\tLoss: 1357667712.000000\n",
      "Train Epoch: 893 [5120/11093 (45%)]\tLoss: 1280458752.000000\n",
      "Train Epoch: 893 [8530/11093 (91%)]\tLoss: 1400375706.560375\n",
      "Train Epoch: 894 [0/11093 (0%)]\tLoss: 1260390912.000000\n",
      "Train Epoch: 894 [5120/11093 (45%)]\tLoss: 1156258560.000000\n",
      "Train Epoch: 894 [8530/11093 (91%)]\tLoss: 1436688335.981243\n",
      "Train Epoch: 895 [0/11093 (0%)]\tLoss: 1187803648.000000\n",
      "Train Epoch: 895 [5120/11093 (45%)]\tLoss: 1214458112.000000\n",
      "Train Epoch: 895 [8530/11093 (91%)]\tLoss: 1591293675.892145\n",
      "Train Epoch: 896 [0/11093 (0%)]\tLoss: 1768948224.000000\n",
      "Train Epoch: 896 [5120/11093 (45%)]\tLoss: 1325773440.000000\n",
      "Train Epoch: 896 [8530/11093 (91%)]\tLoss: 1187644467.620164\n",
      "Train Epoch: 897 [0/11093 (0%)]\tLoss: 1256585216.000000\n",
      "Train Epoch: 897 [5120/11093 (45%)]\tLoss: 1503143424.000000\n",
      "Train Epoch: 897 [8530/11093 (91%)]\tLoss: 1353941798.715123\n",
      "Train Epoch: 898 [0/11093 (0%)]\tLoss: 1264027520.000000\n",
      "Train Epoch: 898 [5120/11093 (45%)]\tLoss: 1184328704.000000\n",
      "Train Epoch: 898 [8530/11093 (91%)]\tLoss: 1175158054.114889\n",
      "Train Epoch: 899 [0/11093 (0%)]\tLoss: 1348839040.000000\n",
      "Train Epoch: 899 [5120/11093 (45%)]\tLoss: 1344340480.000000\n",
      "Train Epoch: 899 [8530/11093 (91%)]\tLoss: 1420899461.252052\n",
      "Train Epoch: 900 [0/11093 (0%)]\tLoss: 1112257792.000000\n",
      "Train Epoch: 900 [5120/11093 (45%)]\tLoss: 1313977088.000000\n",
      "Train Epoch: 900 [8530/11093 (91%)]\tLoss: 1429179277.955451\n",
      "Train Epoch: 901 [0/11093 (0%)]\tLoss: 1373133952.000000\n",
      "Train Epoch: 901 [5120/11093 (45%)]\tLoss: 1196902528.000000\n",
      "Train Epoch: 901 [8530/11093 (91%)]\tLoss: 1193488619.291911\n",
      "Train Epoch: 902 [0/11093 (0%)]\tLoss: 1245982336.000000\n",
      "Train Epoch: 902 [5120/11093 (45%)]\tLoss: 1264760320.000000\n",
      "Train Epoch: 902 [8530/11093 (91%)]\tLoss: 1153066583.033998\n",
      "Train Epoch: 903 [0/11093 (0%)]\tLoss: 1297908608.000000\n",
      "Train Epoch: 903 [5120/11093 (45%)]\tLoss: 1463522688.000000\n",
      "Train Epoch: 903 [8530/11093 (91%)]\tLoss: 1221797789.561548\n",
      "Train Epoch: 904 [0/11093 (0%)]\tLoss: 1119008768.000000\n",
      "Train Epoch: 904 [5120/11093 (45%)]\tLoss: 1366752128.000000\n",
      "Train Epoch: 904 [8530/11093 (91%)]\tLoss: 1398183285.345838\n",
      "Train Epoch: 905 [0/11093 (0%)]\tLoss: 1336412416.000000\n",
      "Train Epoch: 905 [5120/11093 (45%)]\tLoss: 1313175040.000000\n",
      "Train Epoch: 905 [8530/11093 (91%)]\tLoss: 1287545456.243845\n",
      "Train Epoch: 906 [0/11093 (0%)]\tLoss: 1127905024.000000\n",
      "Train Epoch: 906 [5120/11093 (45%)]\tLoss: 1441438592.000000\n",
      "Train Epoch: 906 [8530/11093 (91%)]\tLoss: 1100457616.656507\n",
      "Train Epoch: 907 [0/11093 (0%)]\tLoss: 1238625920.000000\n",
      "Train Epoch: 907 [5120/11093 (45%)]\tLoss: 1120993280.000000\n",
      "Train Epoch: 907 [8530/11093 (91%)]\tLoss: 1225827907.826495\n",
      "Train Epoch: 908 [0/11093 (0%)]\tLoss: 1375363840.000000\n",
      "Train Epoch: 908 [5120/11093 (45%)]\tLoss: 1272712704.000000\n",
      "Train Epoch: 908 [8530/11093 (91%)]\tLoss: 1541385514.916764\n",
      "Train Epoch: 909 [0/11093 (0%)]\tLoss: 1643514880.000000\n",
      "Train Epoch: 909 [5120/11093 (45%)]\tLoss: 1228401152.000000\n",
      "Train Epoch: 909 [8530/11093 (91%)]\tLoss: 1463221887.849941\n",
      "Train Epoch: 910 [0/11093 (0%)]\tLoss: 1365607936.000000\n",
      "Train Epoch: 910 [5120/11093 (45%)]\tLoss: 1171784448.000000\n",
      "Train Epoch: 910 [8530/11093 (91%)]\tLoss: 1230423802.297773\n",
      "Train Epoch: 911 [0/11093 (0%)]\tLoss: 1205145088.000000\n",
      "Train Epoch: 911 [5120/11093 (45%)]\tLoss: 1270358528.000000\n",
      "Train Epoch: 911 [8530/11093 (91%)]\tLoss: 1228886741.083236\n",
      "Train Epoch: 912 [0/11093 (0%)]\tLoss: 1248019712.000000\n",
      "Train Epoch: 912 [5120/11093 (45%)]\tLoss: 1355245952.000000\n",
      "Train Epoch: 912 [8530/11093 (91%)]\tLoss: 1191757869.617820\n",
      "Train Epoch: 913 [0/11093 (0%)]\tLoss: 1344996608.000000\n",
      "Train Epoch: 913 [5120/11093 (45%)]\tLoss: 1292645120.000000\n",
      "Train Epoch: 913 [8530/11093 (91%)]\tLoss: 1286380559.606096\n",
      "Train Epoch: 914 [0/11093 (0%)]\tLoss: 1188365824.000000\n",
      "Train Epoch: 914 [5120/11093 (45%)]\tLoss: 1593412864.000000\n",
      "Train Epoch: 914 [8530/11093 (91%)]\tLoss: 1130444754.382180\n",
      "Train Epoch: 915 [0/11093 (0%)]\tLoss: 1259826304.000000\n",
      "Train Epoch: 915 [5120/11093 (45%)]\tLoss: 1355692288.000000\n",
      "Train Epoch: 915 [8530/11093 (91%)]\tLoss: 1455163802.560375\n",
      "Train Epoch: 916 [0/11093 (0%)]\tLoss: 1266016768.000000\n",
      "Train Epoch: 916 [5120/11093 (45%)]\tLoss: 1311858304.000000\n",
      "Train Epoch: 916 [8530/11093 (91%)]\tLoss: 1432429033.791325\n",
      "Train Epoch: 917 [0/11093 (0%)]\tLoss: 1360322816.000000\n",
      "Train Epoch: 917 [5120/11093 (45%)]\tLoss: 1323293696.000000\n",
      "Train Epoch: 917 [8530/11093 (91%)]\tLoss: 1302320482.138335\n",
      "Train Epoch: 918 [0/11093 (0%)]\tLoss: 1281250304.000000\n",
      "Train Epoch: 918 [5120/11093 (45%)]\tLoss: 1259046400.000000\n",
      "Train Epoch: 918 [8530/11093 (91%)]\tLoss: 1382736918.808910\n",
      "Train Epoch: 919 [0/11093 (0%)]\tLoss: 1529146624.000000\n",
      "Train Epoch: 919 [5120/11093 (45%)]\tLoss: 1365408256.000000\n",
      "Train Epoch: 919 [8530/11093 (91%)]\tLoss: 1376834376.328253\n",
      "Train Epoch: 920 [0/11093 (0%)]\tLoss: 1265595520.000000\n",
      "Train Epoch: 920 [5120/11093 (45%)]\tLoss: 1188731648.000000\n",
      "Train Epoch: 920 [8530/11093 (91%)]\tLoss: 1132684426.053927\n",
      "Train Epoch: 921 [0/11093 (0%)]\tLoss: 1159549568.000000\n",
      "Train Epoch: 921 [5120/11093 (45%)]\tLoss: 1206158336.000000\n",
      "Train Epoch: 921 [8530/11093 (91%)]\tLoss: 1259422982.902696\n",
      "Train Epoch: 922 [0/11093 (0%)]\tLoss: 1123114368.000000\n",
      "Train Epoch: 922 [5120/11093 (45%)]\tLoss: 1483320832.000000\n",
      "Train Epoch: 922 [8530/11093 (91%)]\tLoss: 1278418742.321219\n",
      "Train Epoch: 923 [0/11093 (0%)]\tLoss: 1262998272.000000\n",
      "Train Epoch: 923 [5120/11093 (45%)]\tLoss: 1491436800.000000\n",
      "Train Epoch: 923 [8530/11093 (91%)]\tLoss: 1321696089.134818\n",
      "Train Epoch: 924 [0/11093 (0%)]\tLoss: 1514269312.000000\n",
      "Train Epoch: 924 [5120/11093 (45%)]\tLoss: 1222739840.000000\n",
      "Train Epoch: 924 [8530/11093 (91%)]\tLoss: 1221388516.089097\n",
      "Train Epoch: 925 [0/11093 (0%)]\tLoss: 1365216512.000000\n",
      "Train Epoch: 925 [5120/11093 (45%)]\tLoss: 1084149760.000000\n",
      "Train Epoch: 925 [8530/11093 (91%)]\tLoss: 1034717402.485346\n",
      "Train Epoch: 926 [0/11093 (0%)]\tLoss: 1414153728.000000\n",
      "Train Epoch: 926 [5120/11093 (45%)]\tLoss: 1462326016.000000\n",
      "Train Epoch: 926 [8530/11093 (91%)]\tLoss: 1249329286.452521\n",
      "Train Epoch: 927 [0/11093 (0%)]\tLoss: 1277549056.000000\n",
      "Train Epoch: 927 [5120/11093 (45%)]\tLoss: 1208167680.000000\n",
      "Train Epoch: 927 [8530/11093 (91%)]\tLoss: 1181319821.055100\n",
      "Train Epoch: 928 [0/11093 (0%)]\tLoss: 1163028224.000000\n",
      "Train Epoch: 928 [5120/11093 (45%)]\tLoss: 1516524032.000000\n",
      "Train Epoch: 928 [8530/11093 (91%)]\tLoss: 1084643080.703400\n",
      "Train Epoch: 929 [0/11093 (0%)]\tLoss: 1470703104.000000\n",
      "Train Epoch: 929 [5120/11093 (45%)]\tLoss: 1065526656.000000\n",
      "Train Epoch: 929 [8530/11093 (91%)]\tLoss: 1385090222.067995\n",
      "Train Epoch: 930 [0/11093 (0%)]\tLoss: 1130660096.000000\n",
      "Train Epoch: 930 [5120/11093 (45%)]\tLoss: 1335186048.000000\n",
      "Train Epoch: 930 [8530/11093 (91%)]\tLoss: 1389280223.587339\n",
      "Train Epoch: 931 [0/11093 (0%)]\tLoss: 1420421888.000000\n",
      "Train Epoch: 931 [5120/11093 (45%)]\tLoss: 1201607680.000000\n",
      "Train Epoch: 931 [8530/11093 (91%)]\tLoss: 1482641748.933177\n",
      "Train Epoch: 932 [0/11093 (0%)]\tLoss: 1466650368.000000\n",
      "Train Epoch: 932 [5120/11093 (45%)]\tLoss: 1499132160.000000\n",
      "Train Epoch: 932 [8530/11093 (91%)]\tLoss: 1300559384.609613\n",
      "Train Epoch: 933 [0/11093 (0%)]\tLoss: 1199675392.000000\n",
      "Train Epoch: 933 [5120/11093 (45%)]\tLoss: 1400506624.000000\n",
      "Train Epoch: 933 [8530/11093 (91%)]\tLoss: 1291651252.070340\n",
      "Train Epoch: 934 [0/11093 (0%)]\tLoss: 1268709888.000000\n",
      "Train Epoch: 934 [5120/11093 (45%)]\tLoss: 1364514816.000000\n",
      "Train Epoch: 934 [8530/11093 (91%)]\tLoss: 1660848500.145369\n",
      "Train Epoch: 935 [0/11093 (0%)]\tLoss: 1455070976.000000\n",
      "Train Epoch: 935 [5120/11093 (45%)]\tLoss: 1359280256.000000\n",
      "Train Epoch: 935 [8530/11093 (91%)]\tLoss: 1197020418.100821\n",
      "Train Epoch: 936 [0/11093 (0%)]\tLoss: 1174241664.000000\n",
      "Train Epoch: 936 [5120/11093 (45%)]\tLoss: 1204796928.000000\n",
      "Train Epoch: 936 [8530/11093 (91%)]\tLoss: 1277962986.691676\n",
      "Train Epoch: 937 [0/11093 (0%)]\tLoss: 1439416448.000000\n",
      "Train Epoch: 937 [5120/11093 (45%)]\tLoss: 1151047040.000000\n",
      "Train Epoch: 937 [8530/11093 (91%)]\tLoss: 1192085472.787808\n",
      "Train Epoch: 938 [0/11093 (0%)]\tLoss: 1219307904.000000\n",
      "Train Epoch: 938 [5120/11093 (45%)]\tLoss: 1410098688.000000\n",
      "Train Epoch: 938 [8530/11093 (91%)]\tLoss: 1390314048.225088\n",
      "Train Epoch: 939 [0/11093 (0%)]\tLoss: 1141598208.000000\n",
      "Train Epoch: 939 [5120/11093 (45%)]\tLoss: 1223819008.000000\n",
      "Train Epoch: 939 [8530/11093 (91%)]\tLoss: 1340619935.662368\n",
      "Train Epoch: 940 [0/11093 (0%)]\tLoss: 1355112192.000000\n",
      "Train Epoch: 940 [5120/11093 (45%)]\tLoss: 1149497856.000000\n",
      "Train Epoch: 940 [8530/11093 (91%)]\tLoss: 1128876961.162954\n",
      "Train Epoch: 941 [0/11093 (0%)]\tLoss: 1601926400.000000\n",
      "Train Epoch: 941 [5120/11093 (45%)]\tLoss: 1310262272.000000\n",
      "Train Epoch: 941 [8530/11093 (91%)]\tLoss: 1185836350.124267\n",
      "Train Epoch: 942 [0/11093 (0%)]\tLoss: 1359441152.000000\n",
      "Train Epoch: 942 [5120/11093 (45%)]\tLoss: 1174012160.000000\n",
      "Train Epoch: 942 [8530/11093 (91%)]\tLoss: 1300340111.756155\n",
      "Train Epoch: 943 [0/11093 (0%)]\tLoss: 1175695616.000000\n",
      "Train Epoch: 943 [5120/11093 (45%)]\tLoss: 1106241664.000000\n",
      "Train Epoch: 943 [8530/11093 (91%)]\tLoss: 1476041128.966002\n",
      "Train Epoch: 944 [0/11093 (0%)]\tLoss: 1424036352.000000\n",
      "Train Epoch: 944 [5120/11093 (45%)]\tLoss: 1068692160.000000\n",
      "Train Epoch: 944 [8530/11093 (91%)]\tLoss: 1404327688.703400\n",
      "Train Epoch: 945 [0/11093 (0%)]\tLoss: 1210730368.000000\n",
      "Train Epoch: 945 [5120/11093 (45%)]\tLoss: 1323122688.000000\n",
      "Train Epoch: 945 [8530/11093 (91%)]\tLoss: 1397916838.865182\n",
      "Train Epoch: 946 [0/11093 (0%)]\tLoss: 1329794688.000000\n",
      "Train Epoch: 946 [5120/11093 (45%)]\tLoss: 1444648192.000000\n",
      "Train Epoch: 946 [8530/11093 (91%)]\tLoss: 1597758767.718640\n",
      "Train Epoch: 947 [0/11093 (0%)]\tLoss: 1229129728.000000\n",
      "Train Epoch: 947 [5120/11093 (45%)]\tLoss: 1507321344.000000\n",
      "Train Epoch: 947 [8530/11093 (91%)]\tLoss: 1293093197.730363\n",
      "Train Epoch: 948 [0/11093 (0%)]\tLoss: 1357766400.000000\n",
      "Train Epoch: 948 [5120/11093 (45%)]\tLoss: 1391325568.000000\n",
      "Train Epoch: 948 [8530/11093 (91%)]\tLoss: 1288756604.548652\n",
      "Train Epoch: 949 [0/11093 (0%)]\tLoss: 1167043840.000000\n",
      "Train Epoch: 949 [5120/11093 (45%)]\tLoss: 1250829440.000000\n",
      "Train Epoch: 949 [8530/11093 (91%)]\tLoss: 1208547455.249707\n",
      "Train Epoch: 950 [0/11093 (0%)]\tLoss: 1324432128.000000\n",
      "Train Epoch: 950 [5120/11093 (45%)]\tLoss: 1207213568.000000\n",
      "Train Epoch: 950 [8530/11093 (91%)]\tLoss: 1478197747.395076\n",
      "Train Epoch: 951 [0/11093 (0%)]\tLoss: 1190923520.000000\n",
      "Train Epoch: 951 [5120/11093 (45%)]\tLoss: 1233369728.000000\n",
      "Train Epoch: 951 [8530/11093 (91%)]\tLoss: 1315333488.543962\n",
      "Train Epoch: 952 [0/11093 (0%)]\tLoss: 1467645440.000000\n",
      "Train Epoch: 952 [5120/11093 (45%)]\tLoss: 1316130816.000000\n",
      "Train Epoch: 952 [8530/11093 (91%)]\tLoss: 1141538777.584994\n",
      "Train Epoch: 953 [0/11093 (0%)]\tLoss: 1304285696.000000\n",
      "Train Epoch: 953 [5120/11093 (45%)]\tLoss: 1208369536.000000\n",
      "Train Epoch: 953 [8530/11093 (91%)]\tLoss: 1021890094.218054\n",
      "Train Epoch: 954 [0/11093 (0%)]\tLoss: 1159320576.000000\n",
      "Train Epoch: 954 [5120/11093 (45%)]\tLoss: 1308206080.000000\n",
      "Train Epoch: 954 [8530/11093 (91%)]\tLoss: 1176139634.344666\n",
      "Train Epoch: 955 [0/11093 (0%)]\tLoss: 1266195968.000000\n",
      "Train Epoch: 955 [5120/11093 (45%)]\tLoss: 1143964672.000000\n",
      "Train Epoch: 955 [8530/11093 (91%)]\tLoss: 1494722960.956624\n",
      "Train Epoch: 956 [0/11093 (0%)]\tLoss: 1080008192.000000\n",
      "Train Epoch: 956 [5120/11093 (45%)]\tLoss: 1247036416.000000\n",
      "Train Epoch: 956 [8530/11093 (91%)]\tLoss: 1189807386.110199\n",
      "Train Epoch: 957 [0/11093 (0%)]\tLoss: 1297541632.000000\n",
      "Train Epoch: 957 [5120/11093 (45%)]\tLoss: 1397220096.000000\n",
      "Train Epoch: 957 [8530/11093 (91%)]\tLoss: 1156146851.864009\n",
      "Train Epoch: 958 [0/11093 (0%)]\tLoss: 1285344768.000000\n",
      "Train Epoch: 958 [5120/11093 (45%)]\tLoss: 1494151680.000000\n",
      "Train Epoch: 958 [8530/11093 (91%)]\tLoss: 1241422402.626026\n",
      "Train Epoch: 959 [0/11093 (0%)]\tLoss: 1256722176.000000\n",
      "Train Epoch: 959 [5120/11093 (45%)]\tLoss: 1302802048.000000\n",
      "Train Epoch: 959 [8530/11093 (91%)]\tLoss: 1237198519.071512\n",
      "Train Epoch: 960 [0/11093 (0%)]\tLoss: 1304018176.000000\n",
      "Train Epoch: 960 [5120/11093 (45%)]\tLoss: 1200928000.000000\n",
      "Train Epoch: 960 [8530/11093 (91%)]\tLoss: 1181497067.892145\n",
      "Train Epoch: 961 [0/11093 (0%)]\tLoss: 1492899328.000000\n",
      "Train Epoch: 961 [5120/11093 (45%)]\tLoss: 1149386752.000000\n",
      "Train Epoch: 961 [8530/11093 (91%)]\tLoss: 1036681331.245018\n",
      "Train Epoch: 962 [0/11093 (0%)]\tLoss: 1297152000.000000\n",
      "Train Epoch: 962 [5120/11093 (45%)]\tLoss: 1383533824.000000\n",
      "Train Epoch: 962 [8530/11093 (91%)]\tLoss: 1217645972.558030\n",
      "Train Epoch: 963 [0/11093 (0%)]\tLoss: 1194467072.000000\n",
      "Train Epoch: 963 [5120/11093 (45%)]\tLoss: 1505521920.000000\n",
      "Train Epoch: 963 [8530/11093 (91%)]\tLoss: 1287412386.663540\n",
      "Train Epoch: 964 [0/11093 (0%)]\tLoss: 1379420288.000000\n",
      "Train Epoch: 964 [5120/11093 (45%)]\tLoss: 1425340160.000000\n",
      "Train Epoch: 964 [8530/11093 (91%)]\tLoss: 1515089675.104338\n",
      "Train Epoch: 965 [0/11093 (0%)]\tLoss: 1148806912.000000\n",
      "Train Epoch: 965 [5120/11093 (45%)]\tLoss: 1329296384.000000\n",
      "Train Epoch: 965 [8530/11093 (91%)]\tLoss: 1317373171.695194\n",
      "Train Epoch: 966 [0/11093 (0%)]\tLoss: 1205718144.000000\n",
      "Train Epoch: 966 [5120/11093 (45%)]\tLoss: 1428959360.000000\n",
      "Train Epoch: 966 [8530/11093 (91%)]\tLoss: 1323942291.357562\n",
      "Train Epoch: 967 [0/11093 (0%)]\tLoss: 1222152960.000000\n",
      "Train Epoch: 967 [5120/11093 (45%)]\tLoss: 1147885952.000000\n",
      "Train Epoch: 967 [8530/11093 (91%)]\tLoss: 1318596920.121923\n",
      "Train Epoch: 968 [0/11093 (0%)]\tLoss: 1196555520.000000\n",
      "Train Epoch: 968 [5120/11093 (45%)]\tLoss: 1283286784.000000\n",
      "Train Epoch: 968 [8530/11093 (91%)]\tLoss: 1281774754.063306\n",
      "Train Epoch: 969 [0/11093 (0%)]\tLoss: 1390742912.000000\n",
      "Train Epoch: 969 [5120/11093 (45%)]\tLoss: 1701782144.000000\n",
      "Train Epoch: 969 [8530/11093 (91%)]\tLoss: 1397885338.560375\n",
      "Train Epoch: 970 [0/11093 (0%)]\tLoss: 1365902848.000000\n",
      "Train Epoch: 970 [5120/11093 (45%)]\tLoss: 1324795904.000000\n",
      "Train Epoch: 970 [8530/11093 (91%)]\tLoss: 1291846553.960141\n",
      "Train Epoch: 971 [0/11093 (0%)]\tLoss: 1323420800.000000\n",
      "Train Epoch: 971 [5120/11093 (45%)]\tLoss: 1071209216.000000\n",
      "Train Epoch: 971 [8530/11093 (91%)]\tLoss: 1303120897.200469\n",
      "Train Epoch: 972 [0/11093 (0%)]\tLoss: 1497310464.000000\n",
      "Train Epoch: 972 [5120/11093 (45%)]\tLoss: 1086506112.000000\n",
      "Train Epoch: 972 [8530/11093 (91%)]\tLoss: 1493690672.919109\n",
      "Train Epoch: 973 [0/11093 (0%)]\tLoss: 1052747648.000000\n",
      "Train Epoch: 973 [5120/11093 (45%)]\tLoss: 1447758848.000000\n",
      "Train Epoch: 973 [8530/11093 (91%)]\tLoss: 1173806691.038687\n",
      "Train Epoch: 974 [0/11093 (0%)]\tLoss: 1198430464.000000\n",
      "Train Epoch: 974 [5120/11093 (45%)]\tLoss: 1461279360.000000\n",
      "Train Epoch: 974 [8530/11093 (91%)]\tLoss: 1586000395.404455\n",
      "Train Epoch: 975 [0/11093 (0%)]\tLoss: 1696444928.000000\n",
      "Train Epoch: 975 [5120/11093 (45%)]\tLoss: 1160319232.000000\n",
      "Train Epoch: 975 [8530/11093 (91%)]\tLoss: 1206277973.533412\n",
      "Train Epoch: 976 [0/11093 (0%)]\tLoss: 1159630592.000000\n",
      "Train Epoch: 976 [5120/11093 (45%)]\tLoss: 1457751552.000000\n",
      "Train Epoch: 976 [8530/11093 (91%)]\tLoss: 1067383295.399765\n",
      "Train Epoch: 977 [0/11093 (0%)]\tLoss: 1243184384.000000\n",
      "Train Epoch: 977 [5120/11093 (45%)]\tLoss: 1166675968.000000\n",
      "Train Epoch: 977 [8530/11093 (91%)]\tLoss: 1350349227.366940\n",
      "Train Epoch: 978 [0/11093 (0%)]\tLoss: 1219211008.000000\n",
      "Train Epoch: 978 [5120/11093 (45%)]\tLoss: 1449486848.000000\n",
      "Train Epoch: 978 [8530/11093 (91%)]\tLoss: 1367448207.456038\n",
      "Train Epoch: 979 [0/11093 (0%)]\tLoss: 1178145024.000000\n",
      "Train Epoch: 979 [5120/11093 (45%)]\tLoss: 1392675328.000000\n",
      "Train Epoch: 979 [8530/11093 (91%)]\tLoss: 1068121708.642438\n",
      "Train Epoch: 980 [0/11093 (0%)]\tLoss: 1287760512.000000\n",
      "Train Epoch: 980 [5120/11093 (45%)]\tLoss: 1102514560.000000\n",
      "Train Epoch: 980 [8530/11093 (91%)]\tLoss: 1281034881.050410\n",
      "Train Epoch: 981 [0/11093 (0%)]\tLoss: 1468504832.000000\n",
      "Train Epoch: 981 [5120/11093 (45%)]\tLoss: 1517153664.000000\n",
      "Train Epoch: 981 [8530/11093 (91%)]\tLoss: 1092867272.478312\n",
      "Train Epoch: 982 [0/11093 (0%)]\tLoss: 1295073024.000000\n",
      "Train Epoch: 982 [5120/11093 (45%)]\tLoss: 1285629696.000000\n",
      "Train Epoch: 982 [8530/11093 (91%)]\tLoss: 1220090088.890973\n",
      "Train Epoch: 983 [0/11093 (0%)]\tLoss: 1349017984.000000\n",
      "Train Epoch: 983 [5120/11093 (45%)]\tLoss: 1323392512.000000\n",
      "Train Epoch: 983 [8530/11093 (91%)]\tLoss: 1307390648.271981\n",
      "Train Epoch: 984 [0/11093 (0%)]\tLoss: 1286896384.000000\n",
      "Train Epoch: 984 [5120/11093 (45%)]\tLoss: 1313697792.000000\n",
      "Train Epoch: 984 [8530/11093 (91%)]\tLoss: 1221212498.532239\n",
      "Train Epoch: 985 [0/11093 (0%)]\tLoss: 1266464256.000000\n",
      "Train Epoch: 985 [5120/11093 (45%)]\tLoss: 1528794880.000000\n",
      "Train Epoch: 985 [8530/11093 (91%)]\tLoss: 1257864639.774912\n",
      "Train Epoch: 986 [0/11093 (0%)]\tLoss: 1488934784.000000\n",
      "Train Epoch: 986 [5120/11093 (45%)]\tLoss: 1242109440.000000\n",
      "Train Epoch: 986 [8530/11093 (91%)]\tLoss: 1281842364.473623\n",
      "Train Epoch: 987 [0/11093 (0%)]\tLoss: 1174418432.000000\n",
      "Train Epoch: 987 [5120/11093 (45%)]\tLoss: 1116389376.000000\n",
      "Train Epoch: 987 [8530/11093 (91%)]\tLoss: 1391913341.749121\n",
      "Train Epoch: 988 [0/11093 (0%)]\tLoss: 1684749952.000000\n",
      "Train Epoch: 988 [5120/11093 (45%)]\tLoss: 1237984256.000000\n",
      "Train Epoch: 988 [8530/11093 (91%)]\tLoss: 1384027816.665885\n",
      "Train Epoch: 989 [0/11093 (0%)]\tLoss: 1276415488.000000\n",
      "Train Epoch: 989 [5120/11093 (45%)]\tLoss: 1310143616.000000\n",
      "Train Epoch: 989 [8530/11093 (91%)]\tLoss: 1242822245.439625\n",
      "Train Epoch: 990 [0/11093 (0%)]\tLoss: 1244660096.000000\n",
      "Train Epoch: 990 [5120/11093 (45%)]\tLoss: 1157437184.000000\n",
      "Train Epoch: 990 [8530/11093 (91%)]\tLoss: 1267483910.902696\n",
      "Train Epoch: 991 [0/11093 (0%)]\tLoss: 1166087936.000000\n",
      "Train Epoch: 991 [5120/11093 (45%)]\tLoss: 1315088384.000000\n",
      "Train Epoch: 991 [8530/11093 (91%)]\tLoss: 1256386430.349355\n",
      "Train Epoch: 992 [0/11093 (0%)]\tLoss: 1266123648.000000\n",
      "Train Epoch: 992 [5120/11093 (45%)]\tLoss: 1434968064.000000\n",
      "Train Epoch: 992 [8530/11093 (91%)]\tLoss: 1374054973.824150\n",
      "Train Epoch: 993 [0/11093 (0%)]\tLoss: 1390717056.000000\n",
      "Train Epoch: 993 [5120/11093 (45%)]\tLoss: 1461898752.000000\n",
      "Train Epoch: 993 [8530/11093 (91%)]\tLoss: 1276690451.207503\n",
      "Train Epoch: 994 [0/11093 (0%)]\tLoss: 1551380224.000000\n",
      "Train Epoch: 994 [5120/11093 (45%)]\tLoss: 1274800128.000000\n",
      "Train Epoch: 994 [8530/11093 (91%)]\tLoss: 1221758452.595545\n",
      "Train Epoch: 995 [0/11093 (0%)]\tLoss: 1422594304.000000\n",
      "Train Epoch: 995 [5120/11093 (45%)]\tLoss: 1350771712.000000\n",
      "Train Epoch: 995 [8530/11093 (91%)]\tLoss: 1431404275.094959\n",
      "Train Epoch: 996 [0/11093 (0%)]\tLoss: 1287411200.000000\n",
      "Train Epoch: 996 [5120/11093 (45%)]\tLoss: 1257971456.000000\n",
      "Train Epoch: 996 [8530/11093 (91%)]\tLoss: 1172766105.359906\n",
      "Train Epoch: 997 [0/11093 (0%)]\tLoss: 1405898240.000000\n",
      "Train Epoch: 997 [5120/11093 (45%)]\tLoss: 1480973184.000000\n",
      "Train Epoch: 997 [8530/11093 (91%)]\tLoss: 1059783193.810082\n",
      "Train Epoch: 998 [0/11093 (0%)]\tLoss: 1604282368.000000\n",
      "Train Epoch: 998 [5120/11093 (45%)]\tLoss: 1273095936.000000\n",
      "Train Epoch: 998 [8530/11093 (91%)]\tLoss: 1339044459.441970\n",
      "Train Epoch: 999 [0/11093 (0%)]\tLoss: 1475131136.000000\n",
      "Train Epoch: 999 [5120/11093 (45%)]\tLoss: 1325246464.000000\n",
      "Train Epoch: 999 [8530/11093 (91%)]\tLoss: 1307403863.033998\n",
      "Train Epoch: 1000 [0/11093 (0%)]\tLoss: 1187221120.000000\n",
      "Train Epoch: 1000 [5120/11093 (45%)]\tLoss: 1297764352.000000\n",
      "Train Epoch: 1000 [8530/11093 (91%)]\tLoss: 1378424450.250879\n",
      "====> Epoch: 1000 Average loss: 1291727332.8146\n",
      "Train Epoch: 1001 [0/11093 (0%)]\tLoss: 1266451072.000000\n",
      "Train Epoch: 1001 [5120/11093 (45%)]\tLoss: 1208004608.000000\n",
      "Train Epoch: 1001 [8530/11093 (91%)]\tLoss: 1094694059.667058\n",
      "Train Epoch: 1002 [0/11093 (0%)]\tLoss: 1414067200.000000\n",
      "Train Epoch: 1002 [5120/11093 (45%)]\tLoss: 1281206016.000000\n",
      "Train Epoch: 1002 [8530/11093 (91%)]\tLoss: 1318100751.906213\n",
      "Train Epoch: 1003 [0/11093 (0%)]\tLoss: 1300835456.000000\n",
      "Train Epoch: 1003 [5120/11093 (45%)]\tLoss: 1330112000.000000\n",
      "Train Epoch: 1003 [8530/11093 (91%)]\tLoss: 1167424268.304806\n",
      "Train Epoch: 1004 [0/11093 (0%)]\tLoss: 1624838912.000000\n",
      "Train Epoch: 1004 [5120/11093 (45%)]\tLoss: 1339643648.000000\n",
      "Train Epoch: 1004 [8530/11093 (91%)]\tLoss: 1397725993.116061\n",
      "Train Epoch: 1005 [0/11093 (0%)]\tLoss: 1357432064.000000\n",
      "Train Epoch: 1005 [5120/11093 (45%)]\tLoss: 1130560256.000000\n",
      "Train Epoch: 1005 [8530/11093 (91%)]\tLoss: 1350170520.759672\n",
      "Train Epoch: 1006 [0/11093 (0%)]\tLoss: 1084287744.000000\n",
      "Train Epoch: 1006 [5120/11093 (45%)]\tLoss: 1274044160.000000\n",
      "Train Epoch: 1006 [8530/11093 (91%)]\tLoss: 1238219589.927315\n",
      "Train Epoch: 1007 [0/11093 (0%)]\tLoss: 1338786560.000000\n",
      "Train Epoch: 1007 [5120/11093 (45%)]\tLoss: 1225078272.000000\n",
      "Train Epoch: 1007 [8530/11093 (91%)]\tLoss: 1374899796.633060\n",
      "Train Epoch: 1008 [0/11093 (0%)]\tLoss: 1325250048.000000\n",
      "Train Epoch: 1008 [5120/11093 (45%)]\tLoss: 1152409344.000000\n",
      "Train Epoch: 1008 [8530/11093 (91%)]\tLoss: 1309783134.837046\n",
      "Train Epoch: 1009 [0/11093 (0%)]\tLoss: 1236766336.000000\n",
      "Train Epoch: 1009 [5120/11093 (45%)]\tLoss: 1145973632.000000\n",
      "Train Epoch: 1009 [8530/11093 (91%)]\tLoss: 1540512265.003517\n",
      "Train Epoch: 1010 [0/11093 (0%)]\tLoss: 1352920576.000000\n",
      "Train Epoch: 1010 [5120/11093 (45%)]\tLoss: 1326931584.000000\n",
      "Train Epoch: 1010 [8530/11093 (91%)]\tLoss: 1191586154.541618\n",
      "Train Epoch: 1011 [0/11093 (0%)]\tLoss: 1305646592.000000\n",
      "Train Epoch: 1011 [5120/11093 (45%)]\tLoss: 1181464832.000000\n",
      "Train Epoch: 1011 [8530/11093 (91%)]\tLoss: 1684242009.434936\n",
      "Train Epoch: 1012 [0/11093 (0%)]\tLoss: 1301752064.000000\n",
      "Train Epoch: 1012 [5120/11093 (45%)]\tLoss: 1561534976.000000\n",
      "Train Epoch: 1012 [8530/11093 (91%)]\tLoss: 1217141814.021102\n",
      "Train Epoch: 1013 [0/11093 (0%)]\tLoss: 1285335424.000000\n",
      "Train Epoch: 1013 [5120/11093 (45%)]\tLoss: 1074517248.000000\n",
      "Train Epoch: 1013 [8530/11093 (91%)]\tLoss: 1319757821.599062\n",
      "Train Epoch: 1014 [0/11093 (0%)]\tLoss: 1438920192.000000\n",
      "Train Epoch: 1014 [5120/11093 (45%)]\tLoss: 1181412736.000000\n",
      "Train Epoch: 1014 [8530/11093 (91%)]\tLoss: 1213836433.256741\n",
      "Train Epoch: 1015 [0/11093 (0%)]\tLoss: 1228762112.000000\n",
      "Train Epoch: 1015 [5120/11093 (45%)]\tLoss: 1307116544.000000\n",
      "Train Epoch: 1015 [8530/11093 (91%)]\tLoss: 1141909251.901524\n",
      "Train Epoch: 1016 [0/11093 (0%)]\tLoss: 1279485696.000000\n",
      "Train Epoch: 1016 [5120/11093 (45%)]\tLoss: 1187223808.000000\n",
      "Train Epoch: 1016 [8530/11093 (91%)]\tLoss: 1204731539.057444\n",
      "Train Epoch: 1017 [0/11093 (0%)]\tLoss: 1253074560.000000\n",
      "Train Epoch: 1017 [5120/11093 (45%)]\tLoss: 1365798144.000000\n",
      "Train Epoch: 1017 [8530/11093 (91%)]\tLoss: 1441621283.713951\n",
      "Train Epoch: 1018 [0/11093 (0%)]\tLoss: 1194174976.000000\n",
      "Train Epoch: 1018 [5120/11093 (45%)]\tLoss: 1319592192.000000\n",
      "Train Epoch: 1018 [8530/11093 (91%)]\tLoss: 1358958491.160610\n",
      "Train Epoch: 1019 [0/11093 (0%)]\tLoss: 1388125184.000000\n",
      "Train Epoch: 1019 [5120/11093 (45%)]\tLoss: 1255435520.000000\n",
      "Train Epoch: 1019 [8530/11093 (91%)]\tLoss: 1419131449.022274\n",
      "Train Epoch: 1020 [0/11093 (0%)]\tLoss: 1513166464.000000\n",
      "Train Epoch: 1020 [5120/11093 (45%)]\tLoss: 1491303936.000000\n",
      "Train Epoch: 1020 [8530/11093 (91%)]\tLoss: 1310501802.766706\n",
      "Train Epoch: 1021 [0/11093 (0%)]\tLoss: 1322540672.000000\n",
      "Train Epoch: 1021 [5120/11093 (45%)]\tLoss: 1512739456.000000\n",
      "Train Epoch: 1021 [8530/11093 (91%)]\tLoss: 1263794226.419695\n",
      "Train Epoch: 1022 [0/11093 (0%)]\tLoss: 1273077760.000000\n",
      "Train Epoch: 1022 [5120/11093 (45%)]\tLoss: 1420131712.000000\n",
      "Train Epoch: 1022 [8530/11093 (91%)]\tLoss: 1142941924.089097\n",
      "Train Epoch: 1023 [0/11093 (0%)]\tLoss: 1273843840.000000\n",
      "Train Epoch: 1023 [5120/11093 (45%)]\tLoss: 1101236352.000000\n",
      "Train Epoch: 1023 [8530/11093 (91%)]\tLoss: 1503099276.154748\n",
      "Train Epoch: 1024 [0/11093 (0%)]\tLoss: 1272247808.000000\n",
      "Train Epoch: 1024 [5120/11093 (45%)]\tLoss: 1131493888.000000\n",
      "Train Epoch: 1024 [8530/11093 (91%)]\tLoss: 1221805856.712778\n",
      "Train Epoch: 1025 [0/11093 (0%)]\tLoss: 1138312448.000000\n",
      "Train Epoch: 1025 [5120/11093 (45%)]\tLoss: 1364322048.000000\n",
      "Train Epoch: 1025 [8530/11093 (91%)]\tLoss: 1060783290.072685\n",
      "Train Epoch: 1026 [0/11093 (0%)]\tLoss: 1345162240.000000\n",
      "Train Epoch: 1026 [5120/11093 (45%)]\tLoss: 1170478976.000000\n",
      "Train Epoch: 1026 [8530/11093 (91%)]\tLoss: 1849833733.702227\n",
      "Train Epoch: 1027 [0/11093 (0%)]\tLoss: 1190489856.000000\n",
      "Train Epoch: 1027 [5120/11093 (45%)]\tLoss: 1414794496.000000\n",
      "Train Epoch: 1027 [8530/11093 (91%)]\tLoss: 1497296151.709261\n",
      "Train Epoch: 1028 [0/11093 (0%)]\tLoss: 1197215488.000000\n",
      "Train Epoch: 1028 [5120/11093 (45%)]\tLoss: 1416451584.000000\n",
      "Train Epoch: 1028 [8530/11093 (91%)]\tLoss: 1330995747.413834\n",
      "Train Epoch: 1029 [0/11093 (0%)]\tLoss: 1225190400.000000\n",
      "Train Epoch: 1029 [5120/11093 (45%)]\tLoss: 1241951488.000000\n",
      "Train Epoch: 1029 [8530/11093 (91%)]\tLoss: 1138391205.664713\n",
      "Train Epoch: 1030 [0/11093 (0%)]\tLoss: 1451893248.000000\n",
      "Train Epoch: 1030 [5120/11093 (45%)]\tLoss: 1252531968.000000\n",
      "Train Epoch: 1030 [8530/11093 (91%)]\tLoss: 1365786220.642438\n",
      "Train Epoch: 1031 [0/11093 (0%)]\tLoss: 1375529984.000000\n",
      "Train Epoch: 1031 [5120/11093 (45%)]\tLoss: 1200264064.000000\n",
      "Train Epoch: 1031 [8530/11093 (91%)]\tLoss: 1277514299.423212\n",
      "Train Epoch: 1032 [0/11093 (0%)]\tLoss: 1412193536.000000\n",
      "Train Epoch: 1032 [5120/11093 (45%)]\tLoss: 1417998336.000000\n",
      "Train Epoch: 1032 [8530/11093 (91%)]\tLoss: 1313606657.200469\n",
      "Train Epoch: 1033 [0/11093 (0%)]\tLoss: 1169907456.000000\n",
      "Train Epoch: 1033 [5120/11093 (45%)]\tLoss: 1127678720.000000\n",
      "Train Epoch: 1033 [8530/11093 (91%)]\tLoss: 1542303479.896835\n",
      "Train Epoch: 1034 [0/11093 (0%)]\tLoss: 1332317696.000000\n",
      "Train Epoch: 1034 [5120/11093 (45%)]\tLoss: 1234101632.000000\n",
      "Train Epoch: 1034 [8530/11093 (91%)]\tLoss: 1258023677.899179\n",
      "Train Epoch: 1035 [0/11093 (0%)]\tLoss: 1488331008.000000\n",
      "Train Epoch: 1035 [5120/11093 (45%)]\tLoss: 1137938176.000000\n",
      "Train Epoch: 1035 [8530/11093 (91%)]\tLoss: 1367091562.541618\n",
      "Train Epoch: 1036 [0/11093 (0%)]\tLoss: 1314058240.000000\n",
      "Train Epoch: 1036 [5120/11093 (45%)]\tLoss: 1275086848.000000\n",
      "Train Epoch: 1036 [8530/11093 (91%)]\tLoss: 1630943340.042204\n",
      "Train Epoch: 1037 [0/11093 (0%)]\tLoss: 1216744192.000000\n",
      "Train Epoch: 1037 [5120/11093 (45%)]\tLoss: 1485161216.000000\n",
      "Train Epoch: 1037 [8530/11093 (91%)]\tLoss: 1215175964.511137\n",
      "Train Epoch: 1038 [0/11093 (0%)]\tLoss: 1267302144.000000\n",
      "Train Epoch: 1038 [5120/11093 (45%)]\tLoss: 1287000576.000000\n",
      "Train Epoch: 1038 [8530/11093 (91%)]\tLoss: 1223579477.533412\n",
      "Train Epoch: 1039 [0/11093 (0%)]\tLoss: 1184978048.000000\n",
      "Train Epoch: 1039 [5120/11093 (45%)]\tLoss: 1293055232.000000\n",
      "Train Epoch: 1039 [8530/11093 (91%)]\tLoss: 1176830950.790152\n",
      "Train Epoch: 1040 [0/11093 (0%)]\tLoss: 1135894016.000000\n",
      "Train Epoch: 1040 [5120/11093 (45%)]\tLoss: 1185953792.000000\n",
      "Train Epoch: 1040 [8530/11093 (91%)]\tLoss: 1360534428.361079\n",
      "Train Epoch: 1041 [0/11093 (0%)]\tLoss: 1485304704.000000\n",
      "Train Epoch: 1041 [5120/11093 (45%)]\tLoss: 1206332032.000000\n",
      "Train Epoch: 1041 [8530/11093 (91%)]\tLoss: 1116207615.399765\n",
      "Train Epoch: 1042 [0/11093 (0%)]\tLoss: 1483408128.000000\n",
      "Train Epoch: 1042 [5120/11093 (45%)]\tLoss: 1264466688.000000\n",
      "Train Epoch: 1042 [8530/11093 (91%)]\tLoss: 1257878930.157093\n",
      "Train Epoch: 1043 [0/11093 (0%)]\tLoss: 1483486208.000000\n",
      "Train Epoch: 1043 [5120/11093 (45%)]\tLoss: 1320302464.000000\n",
      "Train Epoch: 1043 [8530/11093 (91%)]\tLoss: 1299355611.985932\n",
      "Train Epoch: 1044 [0/11093 (0%)]\tLoss: 1447892736.000000\n",
      "Train Epoch: 1044 [5120/11093 (45%)]\tLoss: 1309020416.000000\n",
      "Train Epoch: 1044 [8530/11093 (91%)]\tLoss: 1261158419.207503\n",
      "Train Epoch: 1045 [0/11093 (0%)]\tLoss: 1270729856.000000\n",
      "Train Epoch: 1045 [5120/11093 (45%)]\tLoss: 1364816640.000000\n",
      "Train Epoch: 1045 [8530/11093 (91%)]\tLoss: 1159161584.694021\n",
      "Train Epoch: 1046 [0/11093 (0%)]\tLoss: 1105675264.000000\n",
      "Train Epoch: 1046 [5120/11093 (45%)]\tLoss: 1128942208.000000\n",
      "Train Epoch: 1046 [8530/11093 (91%)]\tLoss: 1442824902.677608\n",
      "Train Epoch: 1047 [0/11093 (0%)]\tLoss: 1300510592.000000\n",
      "Train Epoch: 1047 [5120/11093 (45%)]\tLoss: 1558669312.000000\n",
      "Train Epoch: 1047 [8530/11093 (91%)]\tLoss: 1122961588.070340\n",
      "Train Epoch: 1048 [0/11093 (0%)]\tLoss: 1331453184.000000\n",
      "Train Epoch: 1048 [5120/11093 (45%)]\tLoss: 1284525824.000000\n",
      "Train Epoch: 1048 [8530/11093 (91%)]\tLoss: 1233774128.618992\n",
      "Train Epoch: 1049 [0/11093 (0%)]\tLoss: 1467652608.000000\n",
      "Train Epoch: 1049 [5120/11093 (45%)]\tLoss: 1122746880.000000\n",
      "Train Epoch: 1049 [8530/11093 (91%)]\tLoss: 1322303353.547479\n",
      "Train Epoch: 1050 [0/11093 (0%)]\tLoss: 1250265600.000000\n",
      "Train Epoch: 1050 [5120/11093 (45%)]\tLoss: 1163976192.000000\n",
      "Train Epoch: 1050 [8530/11093 (91%)]\tLoss: 1223100135.090270\n",
      "Train Epoch: 1051 [0/11093 (0%)]\tLoss: 1337714176.000000\n",
      "Train Epoch: 1051 [5120/11093 (45%)]\tLoss: 1259468928.000000\n",
      "Train Epoch: 1051 [8530/11093 (91%)]\tLoss: 1398031930.222743\n",
      "Train Epoch: 1052 [0/11093 (0%)]\tLoss: 1089905920.000000\n",
      "Train Epoch: 1052 [5120/11093 (45%)]\tLoss: 1501996544.000000\n",
      "Train Epoch: 1052 [8530/11093 (91%)]\tLoss: 1219360203.779601\n",
      "Train Epoch: 1053 [0/11093 (0%)]\tLoss: 1170803328.000000\n",
      "Train Epoch: 1053 [5120/11093 (45%)]\tLoss: 1285334912.000000\n",
      "Train Epoch: 1053 [8530/11093 (91%)]\tLoss: 1169574663.502931\n",
      "Train Epoch: 1054 [0/11093 (0%)]\tLoss: 1169830400.000000\n",
      "Train Epoch: 1054 [5120/11093 (45%)]\tLoss: 1258095616.000000\n",
      "Train Epoch: 1054 [8530/11093 (91%)]\tLoss: 1338624660.257913\n",
      "Train Epoch: 1055 [0/11093 (0%)]\tLoss: 1084690816.000000\n",
      "Train Epoch: 1055 [5120/11093 (45%)]\tLoss: 1463872384.000000\n",
      "Train Epoch: 1055 [8530/11093 (91%)]\tLoss: 1104193399.146542\n",
      "Train Epoch: 1056 [0/11093 (0%)]\tLoss: 1396438528.000000\n",
      "Train Epoch: 1056 [5120/11093 (45%)]\tLoss: 1318040064.000000\n",
      "Train Epoch: 1056 [8530/11093 (91%)]\tLoss: 1377451628.642438\n",
      "Train Epoch: 1057 [0/11093 (0%)]\tLoss: 1234349824.000000\n",
      "Train Epoch: 1057 [5120/11093 (45%)]\tLoss: 1491703040.000000\n",
      "Train Epoch: 1057 [8530/11093 (91%)]\tLoss: 1070780488.028136\n",
      "Train Epoch: 1058 [0/11093 (0%)]\tLoss: 1146214912.000000\n",
      "Train Epoch: 1058 [5120/11093 (45%)]\tLoss: 1603583232.000000\n",
      "Train Epoch: 1058 [8530/11093 (91%)]\tLoss: 1087487481.397421\n",
      "Train Epoch: 1059 [0/11093 (0%)]\tLoss: 1467755776.000000\n",
      "Train Epoch: 1059 [5120/11093 (45%)]\tLoss: 1320819584.000000\n",
      "Train Epoch: 1059 [8530/11093 (91%)]\tLoss: 1372150204.173505\n",
      "Train Epoch: 1060 [0/11093 (0%)]\tLoss: 1165790976.000000\n",
      "Train Epoch: 1060 [5120/11093 (45%)]\tLoss: 1384584704.000000\n",
      "Train Epoch: 1060 [8530/11093 (91%)]\tLoss: 1191978602.241501\n",
      "Train Epoch: 1061 [0/11093 (0%)]\tLoss: 1350222592.000000\n",
      "Train Epoch: 1061 [5120/11093 (45%)]\tLoss: 1162204672.000000\n",
      "Train Epoch: 1061 [8530/11093 (91%)]\tLoss: 1227798828.117233\n",
      "Train Epoch: 1062 [0/11093 (0%)]\tLoss: 1570372992.000000\n",
      "Train Epoch: 1062 [5120/11093 (45%)]\tLoss: 1273019648.000000\n",
      "Train Epoch: 1062 [8530/11093 (91%)]\tLoss: 1365182029.430246\n",
      "Train Epoch: 1063 [0/11093 (0%)]\tLoss: 1189917184.000000\n",
      "Train Epoch: 1063 [5120/11093 (45%)]\tLoss: 1230254208.000000\n",
      "Train Epoch: 1063 [8530/11093 (91%)]\tLoss: 1264264349.261430\n",
      "Train Epoch: 1064 [0/11093 (0%)]\tLoss: 1341724800.000000\n",
      "Train Epoch: 1064 [5120/11093 (45%)]\tLoss: 1236129920.000000\n",
      "Train Epoch: 1064 [8530/11093 (91%)]\tLoss: 1310383791.868699\n",
      "Train Epoch: 1065 [0/11093 (0%)]\tLoss: 1453453824.000000\n",
      "Train Epoch: 1065 [5120/11093 (45%)]\tLoss: 1202332160.000000\n",
      "Train Epoch: 1065 [8530/11093 (91%)]\tLoss: 1146385983.024619\n",
      "Train Epoch: 1066 [0/11093 (0%)]\tLoss: 1260098048.000000\n",
      "Train Epoch: 1066 [5120/11093 (45%)]\tLoss: 1257524352.000000\n",
      "Train Epoch: 1066 [8530/11093 (91%)]\tLoss: 1251595464.478312\n",
      "Train Epoch: 1067 [0/11093 (0%)]\tLoss: 1066584640.000000\n",
      "Train Epoch: 1067 [5120/11093 (45%)]\tLoss: 1350726656.000000\n",
      "Train Epoch: 1067 [8530/11093 (91%)]\tLoss: 1273057236.783118\n",
      "Train Epoch: 1068 [0/11093 (0%)]\tLoss: 1336936960.000000\n",
      "Train Epoch: 1068 [5120/11093 (45%)]\tLoss: 1139450624.000000\n",
      "Train Epoch: 1068 [8530/11093 (91%)]\tLoss: 1305393221.627198\n",
      "Train Epoch: 1069 [0/11093 (0%)]\tLoss: 1454149888.000000\n",
      "Train Epoch: 1069 [5120/11093 (45%)]\tLoss: 1188617600.000000\n",
      "Train Epoch: 1069 [8530/11093 (91%)]\tLoss: 1192854618.035170\n",
      "Train Epoch: 1070 [0/11093 (0%)]\tLoss: 1068225664.000000\n",
      "Train Epoch: 1070 [5120/11093 (45%)]\tLoss: 1214867968.000000\n",
      "Train Epoch: 1070 [8530/11093 (91%)]\tLoss: 1265498853.889801\n",
      "Train Epoch: 1071 [0/11093 (0%)]\tLoss: 1254643968.000000\n",
      "Train Epoch: 1071 [5120/11093 (45%)]\tLoss: 1125482240.000000\n",
      "Train Epoch: 1071 [8530/11093 (91%)]\tLoss: 1397998125.017585\n",
      "Train Epoch: 1072 [0/11093 (0%)]\tLoss: 1445228032.000000\n",
      "Train Epoch: 1072 [5120/11093 (45%)]\tLoss: 1473525120.000000\n",
      "Train Epoch: 1072 [8530/11093 (91%)]\tLoss: 1327578655.812427\n",
      "Train Epoch: 1073 [0/11093 (0%)]\tLoss: 1183388672.000000\n",
      "Train Epoch: 1073 [5120/11093 (45%)]\tLoss: 1293221760.000000\n",
      "Train Epoch: 1073 [8530/11093 (91%)]\tLoss: 1375034863.793669\n",
      "Train Epoch: 1074 [0/11093 (0%)]\tLoss: 1621062272.000000\n",
      "Train Epoch: 1074 [5120/11093 (45%)]\tLoss: 1352709376.000000\n",
      "Train Epoch: 1074 [8530/11093 (91%)]\tLoss: 1564668081.669402\n",
      "Train Epoch: 1075 [0/11093 (0%)]\tLoss: 1147519616.000000\n",
      "Train Epoch: 1075 [5120/11093 (45%)]\tLoss: 1261089792.000000\n",
      "Train Epoch: 1075 [8530/11093 (91%)]\tLoss: 1484229978.935522\n",
      "Train Epoch: 1076 [0/11093 (0%)]\tLoss: 1115058176.000000\n",
      "Train Epoch: 1076 [5120/11093 (45%)]\tLoss: 1140217728.000000\n",
      "Train Epoch: 1076 [8530/11093 (91%)]\tLoss: 1685251248.468933\n",
      "Train Epoch: 1077 [0/11093 (0%)]\tLoss: 1328313088.000000\n",
      "Train Epoch: 1077 [5120/11093 (45%)]\tLoss: 1237680384.000000\n",
      "Train Epoch: 1077 [8530/11093 (91%)]\tLoss: 1582121555.432591\n",
      "Train Epoch: 1078 [0/11093 (0%)]\tLoss: 1173991296.000000\n",
      "Train Epoch: 1078 [5120/11093 (45%)]\tLoss: 1258623488.000000\n",
      "Train Epoch: 1078 [8530/11093 (91%)]\tLoss: 1272664404.933177\n",
      "Train Epoch: 1079 [0/11093 (0%)]\tLoss: 1327346432.000000\n",
      "Train Epoch: 1079 [5120/11093 (45%)]\tLoss: 1186866688.000000\n",
      "Train Epoch: 1079 [8530/11093 (91%)]\tLoss: 1128494808.684643\n",
      "Train Epoch: 1080 [0/11093 (0%)]\tLoss: 1277402368.000000\n",
      "Train Epoch: 1080 [5120/11093 (45%)]\tLoss: 1286866944.000000\n",
      "Train Epoch: 1080 [8530/11093 (91%)]\tLoss: 1411336429.692849\n",
      "Train Epoch: 1081 [0/11093 (0%)]\tLoss: 1277961856.000000\n",
      "Train Epoch: 1081 [5120/11093 (45%)]\tLoss: 1264890496.000000\n",
      "Train Epoch: 1081 [8530/11093 (91%)]\tLoss: 1245295557.177022\n",
      "Train Epoch: 1082 [0/11093 (0%)]\tLoss: 1248894976.000000\n",
      "Train Epoch: 1082 [5120/11093 (45%)]\tLoss: 1254537856.000000\n",
      "Train Epoch: 1082 [8530/11093 (91%)]\tLoss: 1234991653.814771\n",
      "Train Epoch: 1083 [0/11093 (0%)]\tLoss: 1145579136.000000\n",
      "Train Epoch: 1083 [5120/11093 (45%)]\tLoss: 1552794112.000000\n",
      "Train Epoch: 1083 [8530/11093 (91%)]\tLoss: 1312414255.418523\n",
      "Train Epoch: 1084 [0/11093 (0%)]\tLoss: 1383936128.000000\n",
      "Train Epoch: 1084 [5120/11093 (45%)]\tLoss: 1187956352.000000\n",
      "Train Epoch: 1084 [8530/11093 (91%)]\tLoss: 1707839271.915592\n",
      "Train Epoch: 1085 [0/11093 (0%)]\tLoss: 1519084672.000000\n",
      "Train Epoch: 1085 [5120/11093 (45%)]\tLoss: 1385426688.000000\n",
      "Train Epoch: 1085 [8530/11093 (91%)]\tLoss: 1383450823.277843\n",
      "Train Epoch: 1086 [0/11093 (0%)]\tLoss: 1258651136.000000\n",
      "Train Epoch: 1086 [5120/11093 (45%)]\tLoss: 1393908224.000000\n",
      "Train Epoch: 1086 [8530/11093 (91%)]\tLoss: 1199973686.921454\n",
      "Train Epoch: 1087 [0/11093 (0%)]\tLoss: 1163721344.000000\n",
      "Train Epoch: 1087 [5120/11093 (45%)]\tLoss: 1127341056.000000\n",
      "Train Epoch: 1087 [8530/11093 (91%)]\tLoss: 1276508364.079719\n",
      "Train Epoch: 1088 [0/11093 (0%)]\tLoss: 1429370752.000000\n",
      "Train Epoch: 1088 [5120/11093 (45%)]\tLoss: 1385326208.000000\n",
      "Train Epoch: 1088 [8530/11093 (91%)]\tLoss: 1134131058.344666\n",
      "Train Epoch: 1089 [0/11093 (0%)]\tLoss: 1503661312.000000\n",
      "Train Epoch: 1089 [5120/11093 (45%)]\tLoss: 1154343936.000000\n",
      "Train Epoch: 1089 [8530/11093 (91%)]\tLoss: 1340230407.502931\n",
      "Train Epoch: 1090 [0/11093 (0%)]\tLoss: 1227048832.000000\n",
      "Train Epoch: 1090 [5120/11093 (45%)]\tLoss: 1201288832.000000\n",
      "Train Epoch: 1090 [8530/11093 (91%)]\tLoss: 1765716241.706917\n",
      "Train Epoch: 1091 [0/11093 (0%)]\tLoss: 1408821120.000000\n",
      "Train Epoch: 1091 [5120/11093 (45%)]\tLoss: 1289897984.000000\n",
      "Train Epoch: 1091 [8530/11093 (91%)]\tLoss: 1335976790.733881\n",
      "Train Epoch: 1092 [0/11093 (0%)]\tLoss: 1309578240.000000\n",
      "Train Epoch: 1092 [5120/11093 (45%)]\tLoss: 1454576000.000000\n",
      "Train Epoch: 1092 [8530/11093 (91%)]\tLoss: 1352153657.022274\n",
      "Train Epoch: 1093 [0/11093 (0%)]\tLoss: 1087802880.000000\n",
      "Train Epoch: 1093 [5120/11093 (45%)]\tLoss: 1242372992.000000\n",
      "Train Epoch: 1093 [8530/11093 (91%)]\tLoss: 1270130243.826495\n",
      "Train Epoch: 1094 [0/11093 (0%)]\tLoss: 1335003136.000000\n",
      "Train Epoch: 1094 [5120/11093 (45%)]\tLoss: 1269886080.000000\n",
      "Train Epoch: 1094 [8530/11093 (91%)]\tLoss: 1159090286.443142\n",
      "Train Epoch: 1095 [0/11093 (0%)]\tLoss: 1372612608.000000\n",
      "Train Epoch: 1095 [5120/11093 (45%)]\tLoss: 1453090048.000000\n",
      "Train Epoch: 1095 [8530/11093 (91%)]\tLoss: 1325912827.498241\n",
      "Train Epoch: 1096 [0/11093 (0%)]\tLoss: 1224890368.000000\n",
      "Train Epoch: 1096 [5120/11093 (45%)]\tLoss: 1463417344.000000\n",
      "Train Epoch: 1096 [8530/11093 (91%)]\tLoss: 1185666325.308324\n",
      "Train Epoch: 1097 [0/11093 (0%)]\tLoss: 1140625664.000000\n",
      "Train Epoch: 1097 [5120/11093 (45%)]\tLoss: 1458526976.000000\n",
      "Train Epoch: 1097 [8530/11093 (91%)]\tLoss: 1170509607.915592\n",
      "Train Epoch: 1098 [0/11093 (0%)]\tLoss: 1430403584.000000\n",
      "Train Epoch: 1098 [5120/11093 (45%)]\tLoss: 1221960960.000000\n",
      "Train Epoch: 1098 [8530/11093 (91%)]\tLoss: 1256495067.985932\n",
      "Train Epoch: 1099 [0/11093 (0%)]\tLoss: 1572346112.000000\n",
      "Train Epoch: 1099 [5120/11093 (45%)]\tLoss: 1342853504.000000\n",
      "Train Epoch: 1099 [8530/11093 (91%)]\tLoss: 1139155664.281360\n",
      "Train Epoch: 1100 [0/11093 (0%)]\tLoss: 1301779584.000000\n",
      "Train Epoch: 1100 [5120/11093 (45%)]\tLoss: 1325399168.000000\n",
      "Train Epoch: 1100 [8530/11093 (91%)]\tLoss: 1205416632.271981\n",
      "Train Epoch: 1101 [0/11093 (0%)]\tLoss: 1223561088.000000\n",
      "Train Epoch: 1101 [5120/11093 (45%)]\tLoss: 1323572608.000000\n",
      "Train Epoch: 1101 [8530/11093 (91%)]\tLoss: 1282052187.235639\n",
      "Train Epoch: 1102 [0/11093 (0%)]\tLoss: 1208258944.000000\n",
      "Train Epoch: 1102 [5120/11093 (45%)]\tLoss: 1297977856.000000\n",
      "Train Epoch: 1102 [8530/11093 (91%)]\tLoss: 1227641326.593200\n",
      "Train Epoch: 1103 [0/11093 (0%)]\tLoss: 1425328640.000000\n",
      "Train Epoch: 1103 [5120/11093 (45%)]\tLoss: 1301050880.000000\n",
      "Train Epoch: 1103 [8530/11093 (91%)]\tLoss: 1316662494.086753\n",
      "Train Epoch: 1104 [0/11093 (0%)]\tLoss: 1468301824.000000\n",
      "Train Epoch: 1104 [5120/11093 (45%)]\tLoss: 1308205568.000000\n",
      "Train Epoch: 1104 [8530/11093 (91%)]\tLoss: 1315417694.236811\n",
      "Train Epoch: 1105 [0/11093 (0%)]\tLoss: 1194102016.000000\n",
      "Train Epoch: 1105 [5120/11093 (45%)]\tLoss: 1568999808.000000\n",
      "Train Epoch: 1105 [8530/11093 (91%)]\tLoss: 1216815132.811255\n",
      "Train Epoch: 1106 [0/11093 (0%)]\tLoss: 1200877824.000000\n",
      "Train Epoch: 1106 [5120/11093 (45%)]\tLoss: 1155839616.000000\n",
      "Train Epoch: 1106 [8530/11093 (91%)]\tLoss: 1220142640.618992\n",
      "Train Epoch: 1107 [0/11093 (0%)]\tLoss: 1291315712.000000\n",
      "Train Epoch: 1107 [5120/11093 (45%)]\tLoss: 1175699328.000000\n",
      "Train Epoch: 1107 [8530/11093 (91%)]\tLoss: 1340848274.457210\n",
      "Train Epoch: 1108 [0/11093 (0%)]\tLoss: 1231666688.000000\n",
      "Train Epoch: 1108 [5120/11093 (45%)]\tLoss: 1139105024.000000\n",
      "Train Epoch: 1108 [8530/11093 (91%)]\tLoss: 1095443075.451348\n",
      "Train Epoch: 1109 [0/11093 (0%)]\tLoss: 1371915136.000000\n",
      "Train Epoch: 1109 [5120/11093 (45%)]\tLoss: 1357651200.000000\n",
      "Train Epoch: 1109 [8530/11093 (91%)]\tLoss: 1342132103.953107\n",
      "Train Epoch: 1110 [0/11093 (0%)]\tLoss: 1225925120.000000\n",
      "Train Epoch: 1110 [5120/11093 (45%)]\tLoss: 1145584512.000000\n",
      "Train Epoch: 1110 [8530/11093 (91%)]\tLoss: 1333831696.806565\n",
      "Train Epoch: 1111 [0/11093 (0%)]\tLoss: 1279636736.000000\n",
      "Train Epoch: 1111 [5120/11093 (45%)]\tLoss: 1272343552.000000\n",
      "Train Epoch: 1111 [8530/11093 (91%)]\tLoss: 1099735260.886284\n",
      "Train Epoch: 1112 [0/11093 (0%)]\tLoss: 1237136000.000000\n",
      "Train Epoch: 1112 [5120/11093 (45%)]\tLoss: 1262907392.000000\n",
      "Train Epoch: 1112 [8530/11093 (91%)]\tLoss: 1202412655.643611\n",
      "Train Epoch: 1113 [0/11093 (0%)]\tLoss: 1237581568.000000\n",
      "Train Epoch: 1113 [5120/11093 (45%)]\tLoss: 1456838144.000000\n",
      "Train Epoch: 1113 [8530/11093 (91%)]\tLoss: 1285404357.477139\n",
      "Train Epoch: 1114 [0/11093 (0%)]\tLoss: 1430748800.000000\n",
      "Train Epoch: 1114 [5120/11093 (45%)]\tLoss: 1225921024.000000\n",
      "Train Epoch: 1114 [8530/11093 (91%)]\tLoss: 1233706057.228605\n",
      "Train Epoch: 1115 [0/11093 (0%)]\tLoss: 1241921792.000000\n",
      "Train Epoch: 1115 [5120/11093 (45%)]\tLoss: 1483204352.000000\n",
      "Train Epoch: 1115 [8530/11093 (91%)]\tLoss: 1106535869.373974\n",
      "Train Epoch: 1116 [0/11093 (0%)]\tLoss: 1358884608.000000\n",
      "Train Epoch: 1116 [5120/11093 (45%)]\tLoss: 1209816192.000000\n",
      "Train Epoch: 1116 [8530/11093 (91%)]\tLoss: 1688383915.366940\n",
      "Train Epoch: 1117 [0/11093 (0%)]\tLoss: 1372443648.000000\n",
      "Train Epoch: 1117 [5120/11093 (45%)]\tLoss: 1203824896.000000\n",
      "Train Epoch: 1117 [8530/11093 (91%)]\tLoss: 1248474706.232122\n",
      "Train Epoch: 1118 [0/11093 (0%)]\tLoss: 1135573120.000000\n",
      "Train Epoch: 1118 [5120/11093 (45%)]\tLoss: 1266081536.000000\n",
      "Train Epoch: 1118 [8530/11093 (91%)]\tLoss: 1504383566.630715\n",
      "Train Epoch: 1119 [0/11093 (0%)]\tLoss: 1184371968.000000\n",
      "Train Epoch: 1119 [5120/11093 (45%)]\tLoss: 1130878592.000000\n",
      "Train Epoch: 1119 [8530/11093 (91%)]\tLoss: 1818977725.373974\n",
      "Train Epoch: 1120 [0/11093 (0%)]\tLoss: 1357071616.000000\n",
      "Train Epoch: 1120 [5120/11093 (45%)]\tLoss: 1141511168.000000\n",
      "Train Epoch: 1120 [8530/11093 (91%)]\tLoss: 1151075686.940211\n",
      "Train Epoch: 1121 [0/11093 (0%)]\tLoss: 1225413120.000000\n",
      "Train Epoch: 1121 [5120/11093 (45%)]\tLoss: 1166531840.000000\n",
      "Train Epoch: 1121 [8530/11093 (91%)]\tLoss: 1281864030.536928\n",
      "Train Epoch: 1122 [0/11093 (0%)]\tLoss: 1349895296.000000\n",
      "Train Epoch: 1122 [5120/11093 (45%)]\tLoss: 1232588160.000000\n",
      "Train Epoch: 1122 [8530/11093 (91%)]\tLoss: 1277316001.162954\n",
      "Train Epoch: 1123 [0/11093 (0%)]\tLoss: 1582172160.000000\n",
      "Train Epoch: 1123 [5120/11093 (45%)]\tLoss: 1399546880.000000\n",
      "Train Epoch: 1123 [8530/11093 (91%)]\tLoss: 1391665641.791325\n",
      "Train Epoch: 1124 [0/11093 (0%)]\tLoss: 1139431424.000000\n",
      "Train Epoch: 1124 [5120/11093 (45%)]\tLoss: 1207110528.000000\n",
      "Train Epoch: 1124 [8530/11093 (91%)]\tLoss: 1191811496.966002\n",
      "Train Epoch: 1125 [0/11093 (0%)]\tLoss: 1367081472.000000\n",
      "Train Epoch: 1125 [5120/11093 (45%)]\tLoss: 1109643520.000000\n",
      "Train Epoch: 1125 [8530/11093 (91%)]\tLoss: 1132037978.335287\n",
      "Train Epoch: 1126 [0/11093 (0%)]\tLoss: 1159656448.000000\n",
      "Train Epoch: 1126 [5120/11093 (45%)]\tLoss: 1115422976.000000\n",
      "Train Epoch: 1126 [8530/11093 (91%)]\tLoss: 1388991957.383353\n",
      "Train Epoch: 1127 [0/11093 (0%)]\tLoss: 1286233344.000000\n",
      "Train Epoch: 1127 [5120/11093 (45%)]\tLoss: 1396570880.000000\n",
      "Train Epoch: 1127 [8530/11093 (91%)]\tLoss: 1201350864.881594\n",
      "Train Epoch: 1128 [0/11093 (0%)]\tLoss: 1469723392.000000\n",
      "Train Epoch: 1128 [5120/11093 (45%)]\tLoss: 1161052928.000000\n",
      "Train Epoch: 1128 [8530/11093 (91%)]\tLoss: 1497386196.483001\n",
      "Train Epoch: 1129 [0/11093 (0%)]\tLoss: 1284176384.000000\n",
      "Train Epoch: 1129 [5120/11093 (45%)]\tLoss: 1427513856.000000\n",
      "Train Epoch: 1129 [8530/11093 (91%)]\tLoss: 1192828572.661196\n",
      "Train Epoch: 1130 [0/11093 (0%)]\tLoss: 1114711296.000000\n",
      "Train Epoch: 1130 [5120/11093 (45%)]\tLoss: 1290897408.000000\n",
      "Train Epoch: 1130 [8530/11093 (91%)]\tLoss: 1503323312.468933\n",
      "Train Epoch: 1131 [0/11093 (0%)]\tLoss: 1329359872.000000\n",
      "Train Epoch: 1131 [5120/11093 (45%)]\tLoss: 1225612544.000000\n",
      "Train Epoch: 1131 [8530/11093 (91%)]\tLoss: 1596539475.432591\n",
      "Train Epoch: 1132 [0/11093 (0%)]\tLoss: 1241885440.000000\n",
      "Train Epoch: 1132 [5120/11093 (45%)]\tLoss: 1242874112.000000\n",
      "Train Epoch: 1132 [8530/11093 (91%)]\tLoss: 1218550722.776084\n",
      "Train Epoch: 1133 [0/11093 (0%)]\tLoss: 1575480320.000000\n",
      "Train Epoch: 1133 [5120/11093 (45%)]\tLoss: 1210307584.000000\n",
      "Train Epoch: 1133 [8530/11093 (91%)]\tLoss: 1274543743.849941\n",
      "Train Epoch: 1134 [0/11093 (0%)]\tLoss: 1398905600.000000\n",
      "Train Epoch: 1134 [5120/11093 (45%)]\tLoss: 1159221888.000000\n",
      "Train Epoch: 1134 [8530/11093 (91%)]\tLoss: 1359508901.364596\n",
      "Train Epoch: 1135 [0/11093 (0%)]\tLoss: 1313450752.000000\n",
      "Train Epoch: 1135 [5120/11093 (45%)]\tLoss: 1308113408.000000\n",
      "Train Epoch: 1135 [8530/11093 (91%)]\tLoss: 1436651764.895662\n",
      "Train Epoch: 1136 [0/11093 (0%)]\tLoss: 1139159680.000000\n",
      "Train Epoch: 1136 [5120/11093 (45%)]\tLoss: 1284524416.000000\n",
      "Train Epoch: 1136 [8530/11093 (91%)]\tLoss: 1460343681.950762\n",
      "Train Epoch: 1137 [0/11093 (0%)]\tLoss: 1296463616.000000\n",
      "Train Epoch: 1137 [5120/11093 (45%)]\tLoss: 1309599744.000000\n",
      "Train Epoch: 1137 [8530/11093 (91%)]\tLoss: 1338434429.148886\n",
      "Train Epoch: 1138 [0/11093 (0%)]\tLoss: 1195877376.000000\n",
      "Train Epoch: 1138 [5120/11093 (45%)]\tLoss: 1272778752.000000\n",
      "Train Epoch: 1138 [8530/11093 (91%)]\tLoss: 1393905390.293083\n",
      "Train Epoch: 1139 [0/11093 (0%)]\tLoss: 1647501056.000000\n",
      "Train Epoch: 1139 [5120/11093 (45%)]\tLoss: 1202987776.000000\n",
      "Train Epoch: 1139 [8530/11093 (91%)]\tLoss: 1460718612.407972\n",
      "Train Epoch: 1140 [0/11093 (0%)]\tLoss: 1177447424.000000\n",
      "Train Epoch: 1140 [5120/11093 (45%)]\tLoss: 1441322112.000000\n",
      "Train Epoch: 1140 [8530/11093 (91%)]\tLoss: 1388300179.957796\n",
      "Train Epoch: 1141 [0/11093 (0%)]\tLoss: 1391971328.000000\n",
      "Train Epoch: 1141 [5120/11093 (45%)]\tLoss: 1128992256.000000\n",
      "Train Epoch: 1141 [8530/11093 (91%)]\tLoss: 1290947181.842907\n",
      "Train Epoch: 1142 [0/11093 (0%)]\tLoss: 1036648576.000000\n",
      "Train Epoch: 1142 [5120/11093 (45%)]\tLoss: 1436487680.000000\n",
      "Train Epoch: 1142 [8530/11093 (91%)]\tLoss: 1485885512.028136\n",
      "Train Epoch: 1143 [0/11093 (0%)]\tLoss: 1513297408.000000\n",
      "Train Epoch: 1143 [5120/11093 (45%)]\tLoss: 1191147008.000000\n",
      "Train Epoch: 1143 [8530/11093 (91%)]\tLoss: 1437429130.954279\n",
      "Train Epoch: 1144 [0/11093 (0%)]\tLoss: 1380557824.000000\n",
      "Train Epoch: 1144 [5120/11093 (45%)]\tLoss: 1283061888.000000\n",
      "Train Epoch: 1144 [8530/11093 (91%)]\tLoss: 1428920053.495897\n",
      "Train Epoch: 1145 [0/11093 (0%)]\tLoss: 1261805696.000000\n",
      "Train Epoch: 1145 [5120/11093 (45%)]\tLoss: 1415823360.000000\n",
      "Train Epoch: 1145 [8530/11093 (91%)]\tLoss: 1313835764.295428\n",
      "Train Epoch: 1146 [0/11093 (0%)]\tLoss: 1455094784.000000\n",
      "Train Epoch: 1146 [5120/11093 (45%)]\tLoss: 1227263360.000000\n",
      "Train Epoch: 1146 [8530/11093 (91%)]\tLoss: 1382069880.647128\n",
      "Train Epoch: 1147 [0/11093 (0%)]\tLoss: 1320737280.000000\n",
      "Train Epoch: 1147 [5120/11093 (45%)]\tLoss: 1102134272.000000\n",
      "Train Epoch: 1147 [8530/11093 (91%)]\tLoss: 1255484599.671747\n",
      "Train Epoch: 1148 [0/11093 (0%)]\tLoss: 1450395648.000000\n",
      "Train Epoch: 1148 [5120/11093 (45%)]\tLoss: 1273858048.000000\n",
      "Train Epoch: 1148 [8530/11093 (91%)]\tLoss: 1127791737.247362\n",
      "Train Epoch: 1149 [0/11093 (0%)]\tLoss: 1218091776.000000\n",
      "Train Epoch: 1149 [5120/11093 (45%)]\tLoss: 1472434944.000000\n",
      "Train Epoch: 1149 [8530/11093 (91%)]\tLoss: 1253018817.275498\n",
      "Train Epoch: 1150 [0/11093 (0%)]\tLoss: 1249243904.000000\n",
      "Train Epoch: 1150 [5120/11093 (45%)]\tLoss: 1144762240.000000\n",
      "Train Epoch: 1150 [8530/11093 (91%)]\tLoss: 1252693672.665885\n",
      "Train Epoch: 1151 [0/11093 (0%)]\tLoss: 1463917440.000000\n",
      "Train Epoch: 1151 [5120/11093 (45%)]\tLoss: 1355753472.000000\n",
      "Train Epoch: 1151 [8530/11093 (91%)]\tLoss: 1122818530.588511\n",
      "Train Epoch: 1152 [0/11093 (0%)]\tLoss: 1437473792.000000\n",
      "Train Epoch: 1152 [5120/11093 (45%)]\tLoss: 1307482240.000000\n",
      "Train Epoch: 1152 [8530/11093 (91%)]\tLoss: 1251242353.744431\n",
      "Train Epoch: 1153 [0/11093 (0%)]\tLoss: 1691191936.000000\n",
      "Train Epoch: 1153 [5120/11093 (45%)]\tLoss: 1224499968.000000\n",
      "Train Epoch: 1153 [8530/11093 (91%)]\tLoss: 1231099368.590856\n",
      "Train Epoch: 1154 [0/11093 (0%)]\tLoss: 1141953536.000000\n",
      "Train Epoch: 1154 [5120/11093 (45%)]\tLoss: 1196116480.000000\n",
      "Train Epoch: 1154 [8530/11093 (91%)]\tLoss: 1575791838.086753\n",
      "Train Epoch: 1155 [0/11093 (0%)]\tLoss: 1142513664.000000\n",
      "Train Epoch: 1155 [5120/11093 (45%)]\tLoss: 1309248384.000000\n",
      "Train Epoch: 1155 [8530/11093 (91%)]\tLoss: 1204261569.875733\n",
      "Train Epoch: 1156 [0/11093 (0%)]\tLoss: 1275257984.000000\n",
      "Train Epoch: 1156 [5120/11093 (45%)]\tLoss: 1293788928.000000\n",
      "Train Epoch: 1156 [8530/11093 (91%)]\tLoss: 1515304645.477139\n",
      "Train Epoch: 1157 [0/11093 (0%)]\tLoss: 1253967104.000000\n",
      "Train Epoch: 1157 [5120/11093 (45%)]\tLoss: 1361805568.000000\n",
      "Train Epoch: 1157 [8530/11093 (91%)]\tLoss: 1172185808.281360\n",
      "Train Epoch: 1158 [0/11093 (0%)]\tLoss: 1365554944.000000\n",
      "Train Epoch: 1158 [5120/11093 (45%)]\tLoss: 1586297600.000000\n",
      "Train Epoch: 1158 [8530/11093 (91%)]\tLoss: 1099895220.970692\n",
      "Train Epoch: 1159 [0/11093 (0%)]\tLoss: 1539949056.000000\n",
      "Train Epoch: 1159 [5120/11093 (45%)]\tLoss: 1153829888.000000\n",
      "Train Epoch: 1159 [8530/11093 (91%)]\tLoss: 1271061654.058617\n",
      "Train Epoch: 1160 [0/11093 (0%)]\tLoss: 1345348352.000000\n",
      "Train Epoch: 1160 [5120/11093 (45%)]\tLoss: 1311942272.000000\n",
      "Train Epoch: 1160 [8530/11093 (91%)]\tLoss: 1358378117.252052\n",
      "Train Epoch: 1161 [0/11093 (0%)]\tLoss: 1506280448.000000\n",
      "Train Epoch: 1161 [5120/11093 (45%)]\tLoss: 1399404288.000000\n",
      "Train Epoch: 1161 [8530/11093 (91%)]\tLoss: 1450600253.524033\n",
      "Train Epoch: 1162 [0/11093 (0%)]\tLoss: 1287581696.000000\n",
      "Train Epoch: 1162 [5120/11093 (45%)]\tLoss: 1185561984.000000\n",
      "Train Epoch: 1162 [8530/11093 (91%)]\tLoss: 1245173551.118406\n",
      "Train Epoch: 1163 [0/11093 (0%)]\tLoss: 1257875712.000000\n",
      "Train Epoch: 1163 [5120/11093 (45%)]\tLoss: 1512418944.000000\n",
      "Train Epoch: 1163 [8530/11093 (91%)]\tLoss: 1161480007.127784\n",
      "Train Epoch: 1164 [0/11093 (0%)]\tLoss: 1314188288.000000\n",
      "Train Epoch: 1164 [5120/11093 (45%)]\tLoss: 1271035776.000000\n",
      "Train Epoch: 1164 [8530/11093 (91%)]\tLoss: 1243851690.766706\n",
      "Train Epoch: 1165 [0/11093 (0%)]\tLoss: 1190332160.000000\n",
      "Train Epoch: 1165 [5120/11093 (45%)]\tLoss: 1249739904.000000\n",
      "Train Epoch: 1165 [8530/11093 (91%)]\tLoss: 1097271706.560375\n",
      "Train Epoch: 1166 [0/11093 (0%)]\tLoss: 1292844544.000000\n",
      "Train Epoch: 1166 [5120/11093 (45%)]\tLoss: 1082976000.000000\n",
      "Train Epoch: 1166 [8530/11093 (91%)]\tLoss: 1351414705.969519\n",
      "Train Epoch: 1167 [0/11093 (0%)]\tLoss: 1376841984.000000\n",
      "Train Epoch: 1167 [5120/11093 (45%)]\tLoss: 1208770176.000000\n",
      "Train Epoch: 1167 [8530/11093 (91%)]\tLoss: 1692616788.032825\n",
      "Train Epoch: 1168 [0/11093 (0%)]\tLoss: 1354013952.000000\n",
      "Train Epoch: 1168 [5120/11093 (45%)]\tLoss: 1349180416.000000\n",
      "Train Epoch: 1168 [8530/11093 (91%)]\tLoss: 1156600225.763189\n",
      "Train Epoch: 1169 [0/11093 (0%)]\tLoss: 1223251584.000000\n",
      "Train Epoch: 1169 [5120/11093 (45%)]\tLoss: 1040964736.000000\n",
      "Train Epoch: 1169 [8530/11093 (91%)]\tLoss: 1247951570.682298\n",
      "Train Epoch: 1170 [0/11093 (0%)]\tLoss: 1452081408.000000\n",
      "Train Epoch: 1170 [5120/11093 (45%)]\tLoss: 1162937088.000000\n",
      "Train Epoch: 1170 [8530/11093 (91%)]\tLoss: 1373475675.535756\n",
      "Train Epoch: 1171 [0/11093 (0%)]\tLoss: 1420894976.000000\n",
      "Train Epoch: 1171 [5120/11093 (45%)]\tLoss: 1332962048.000000\n",
      "Train Epoch: 1171 [8530/11093 (91%)]\tLoss: 1288749689.847597\n",
      "Train Epoch: 1172 [0/11093 (0%)]\tLoss: 1344682240.000000\n",
      "Train Epoch: 1172 [5120/11093 (45%)]\tLoss: 1129041920.000000\n",
      "Train Epoch: 1172 [8530/11093 (91%)]\tLoss: 1257919342.743259\n",
      "Train Epoch: 1173 [0/11093 (0%)]\tLoss: 1344545408.000000\n",
      "Train Epoch: 1173 [5120/11093 (45%)]\tLoss: 1221238272.000000\n",
      "Train Epoch: 1173 [8530/11093 (91%)]\tLoss: 1205734939.010551\n",
      "Train Epoch: 1174 [0/11093 (0%)]\tLoss: 1256271360.000000\n",
      "Train Epoch: 1174 [5120/11093 (45%)]\tLoss: 1318366208.000000\n",
      "Train Epoch: 1174 [8530/11093 (91%)]\tLoss: 1358115358.611958\n",
      "Train Epoch: 1175 [0/11093 (0%)]\tLoss: 1281446656.000000\n",
      "Train Epoch: 1175 [5120/11093 (45%)]\tLoss: 1294306304.000000\n",
      "Train Epoch: 1175 [8530/11093 (91%)]\tLoss: 1111471736.647128\n",
      "Train Epoch: 1176 [0/11093 (0%)]\tLoss: 1211704576.000000\n",
      "Train Epoch: 1176 [5120/11093 (45%)]\tLoss: 1338381184.000000\n",
      "Train Epoch: 1176 [8530/11093 (91%)]\tLoss: 1219093910.958968\n",
      "Train Epoch: 1177 [0/11093 (0%)]\tLoss: 1256358912.000000\n",
      "Train Epoch: 1177 [5120/11093 (45%)]\tLoss: 1372960000.000000\n",
      "Train Epoch: 1177 [8530/11093 (91%)]\tLoss: 1271488752.093787\n",
      "Train Epoch: 1178 [0/11093 (0%)]\tLoss: 1306648576.000000\n",
      "Train Epoch: 1178 [5120/11093 (45%)]\tLoss: 1209690624.000000\n",
      "Train Epoch: 1178 [8530/11093 (91%)]\tLoss: 1260428380.436108\n",
      "Train Epoch: 1179 [0/11093 (0%)]\tLoss: 1439356672.000000\n",
      "Train Epoch: 1179 [5120/11093 (45%)]\tLoss: 1230732288.000000\n",
      "Train Epoch: 1179 [8530/11093 (91%)]\tLoss: 1121292379.235639\n",
      "Train Epoch: 1180 [0/11093 (0%)]\tLoss: 1385991808.000000\n",
      "Train Epoch: 1180 [5120/11093 (45%)]\tLoss: 1168215808.000000\n",
      "Train Epoch: 1180 [8530/11093 (91%)]\tLoss: 1243659231.587339\n",
      "Train Epoch: 1181 [0/11093 (0%)]\tLoss: 1158161408.000000\n",
      "Train Epoch: 1181 [5120/11093 (45%)]\tLoss: 1392052736.000000\n",
      "Train Epoch: 1181 [8530/11093 (91%)]\tLoss: 1249415336.065651\n",
      "Train Epoch: 1182 [0/11093 (0%)]\tLoss: 1273740800.000000\n",
      "Train Epoch: 1182 [5120/11093 (45%)]\tLoss: 1362220800.000000\n",
      "Train Epoch: 1182 [8530/11093 (91%)]\tLoss: 1309700158.424385\n",
      "Train Epoch: 1183 [0/11093 (0%)]\tLoss: 1541775104.000000\n",
      "Train Epoch: 1183 [5120/11093 (45%)]\tLoss: 1209744128.000000\n",
      "Train Epoch: 1183 [8530/11093 (91%)]\tLoss: 1292631756.679953\n",
      "Train Epoch: 1184 [0/11093 (0%)]\tLoss: 1535121024.000000\n",
      "Train Epoch: 1184 [5120/11093 (45%)]\tLoss: 1398050304.000000\n",
      "Train Epoch: 1184 [8530/11093 (91%)]\tLoss: 1251262944.187573\n",
      "Train Epoch: 1185 [0/11093 (0%)]\tLoss: 1117739008.000000\n",
      "Train Epoch: 1185 [5120/11093 (45%)]\tLoss: 1273841920.000000\n",
      "Train Epoch: 1185 [8530/11093 (91%)]\tLoss: 1382671152.318875\n",
      "Train Epoch: 1186 [0/11093 (0%)]\tLoss: 1351485184.000000\n",
      "Train Epoch: 1186 [5120/11093 (45%)]\tLoss: 1251409152.000000\n",
      "Train Epoch: 1186 [8530/11093 (91%)]\tLoss: 1208193268.895662\n",
      "Train Epoch: 1187 [0/11093 (0%)]\tLoss: 1158293248.000000\n",
      "Train Epoch: 1187 [5120/11093 (45%)]\tLoss: 1442140800.000000\n",
      "Train Epoch: 1187 [8530/11093 (91%)]\tLoss: 1193020878.180539\n",
      "Train Epoch: 1188 [0/11093 (0%)]\tLoss: 1332362240.000000\n",
      "Train Epoch: 1188 [5120/11093 (45%)]\tLoss: 1498948096.000000\n",
      "Train Epoch: 1188 [8530/11093 (91%)]\tLoss: 1317337215.249707\n",
      "Train Epoch: 1189 [0/11093 (0%)]\tLoss: 1419864064.000000\n",
      "Train Epoch: 1189 [5120/11093 (45%)]\tLoss: 1621212800.000000\n",
      "Train Epoch: 1189 [8530/11093 (91%)]\tLoss: 1313453611.817116\n",
      "Train Epoch: 1190 [0/11093 (0%)]\tLoss: 1266906368.000000\n",
      "Train Epoch: 1190 [5120/11093 (45%)]\tLoss: 1527028992.000000\n",
      "Train Epoch: 1190 [8530/11093 (91%)]\tLoss: 1111688550.940211\n",
      "Train Epoch: 1191 [0/11093 (0%)]\tLoss: 1224351744.000000\n",
      "Train Epoch: 1191 [5120/11093 (45%)]\tLoss: 1272000256.000000\n",
      "Train Epoch: 1191 [8530/11093 (91%)]\tLoss: 1103643603.582649\n",
      "Train Epoch: 1192 [0/11093 (0%)]\tLoss: 1215061760.000000\n",
      "Train Epoch: 1192 [5120/11093 (45%)]\tLoss: 1269118080.000000\n",
      "Train Epoch: 1192 [8530/11093 (91%)]\tLoss: 1150555240.440797\n",
      "Train Epoch: 1193 [0/11093 (0%)]\tLoss: 1267513600.000000\n",
      "Train Epoch: 1193 [5120/11093 (45%)]\tLoss: 1223753216.000000\n",
      "Train Epoch: 1193 [8530/11093 (91%)]\tLoss: 1148034755.076202\n",
      "Train Epoch: 1194 [0/11093 (0%)]\tLoss: 1510189568.000000\n",
      "Train Epoch: 1194 [5120/11093 (45%)]\tLoss: 1249712128.000000\n",
      "Train Epoch: 1194 [8530/11093 (91%)]\tLoss: 1113313352.028136\n",
      "Train Epoch: 1195 [0/11093 (0%)]\tLoss: 1264132224.000000\n",
      "Train Epoch: 1195 [5120/11093 (45%)]\tLoss: 1314793728.000000\n",
      "Train Epoch: 1195 [8530/11093 (91%)]\tLoss: 1387185530.147714\n",
      "Train Epoch: 1196 [0/11093 (0%)]\tLoss: 1134126208.000000\n",
      "Train Epoch: 1196 [5120/11093 (45%)]\tLoss: 1120231936.000000\n",
      "Train Epoch: 1196 [8530/11093 (91%)]\tLoss: 1620098476.567409\n",
      "Train Epoch: 1197 [0/11093 (0%)]\tLoss: 1080505472.000000\n",
      "Train Epoch: 1197 [5120/11093 (45%)]\tLoss: 1203665920.000000\n",
      "Train Epoch: 1197 [8530/11093 (91%)]\tLoss: 1342197870.443142\n",
      "Train Epoch: 1198 [0/11093 (0%)]\tLoss: 1099054976.000000\n",
      "Train Epoch: 1198 [5120/11093 (45%)]\tLoss: 1255882496.000000\n",
      "Train Epoch: 1198 [8530/11093 (91%)]\tLoss: 1296571292.361079\n",
      "Train Epoch: 1199 [0/11093 (0%)]\tLoss: 1282427136.000000\n",
      "Train Epoch: 1199 [5120/11093 (45%)]\tLoss: 1212638208.000000\n",
      "Train Epoch: 1199 [8530/11093 (91%)]\tLoss: 1346586861.692849\n",
      "Train Epoch: 1200 [0/11093 (0%)]\tLoss: 1296999040.000000\n",
      "Train Epoch: 1200 [5120/11093 (45%)]\tLoss: 1296106240.000000\n",
      "Train Epoch: 1200 [8530/11093 (91%)]\tLoss: 1427675560.966002\n",
      "====> Epoch: 1200 Average loss: 1291449863.8002\n",
      "Train Epoch: 1201 [0/11093 (0%)]\tLoss: 1364345984.000000\n",
      "Train Epoch: 1201 [5120/11093 (45%)]\tLoss: 1350943616.000000\n",
      "Train Epoch: 1201 [8530/11093 (91%)]\tLoss: 1140611132.023447\n",
      "Train Epoch: 1202 [0/11093 (0%)]\tLoss: 1362829824.000000\n",
      "Train Epoch: 1202 [5120/11093 (45%)]\tLoss: 1523250048.000000\n",
      "Train Epoch: 1202 [8530/11093 (91%)]\tLoss: 993952934.865182\n",
      "Train Epoch: 1203 [0/11093 (0%)]\tLoss: 1324761600.000000\n",
      "Train Epoch: 1203 [5120/11093 (45%)]\tLoss: 1160171008.000000\n",
      "Train Epoch: 1203 [8530/11093 (91%)]\tLoss: 1356611026.982415\n",
      "Train Epoch: 1204 [0/11093 (0%)]\tLoss: 1070154496.000000\n",
      "Train Epoch: 1204 [5120/11093 (45%)]\tLoss: 1392121344.000000\n",
      "Train Epoch: 1204 [8530/11093 (91%)]\tLoss: 1655758972.848769\n",
      "Train Epoch: 1205 [0/11093 (0%)]\tLoss: 1385963648.000000\n",
      "Train Epoch: 1205 [5120/11093 (45%)]\tLoss: 1347980544.000000\n",
      "Train Epoch: 1205 [8530/11093 (91%)]\tLoss: 1488043359.737397\n",
      "Train Epoch: 1206 [0/11093 (0%)]\tLoss: 1412026752.000000\n",
      "Train Epoch: 1206 [5120/11093 (45%)]\tLoss: 1249751040.000000\n",
      "Train Epoch: 1206 [8530/11093 (91%)]\tLoss: 1062474318.630715\n",
      "Train Epoch: 1207 [0/11093 (0%)]\tLoss: 1145547392.000000\n",
      "Train Epoch: 1207 [5120/11093 (45%)]\tLoss: 1292468864.000000\n",
      "Train Epoch: 1207 [8530/11093 (91%)]\tLoss: 1372422489.735053\n",
      "Train Epoch: 1208 [0/11093 (0%)]\tLoss: 1214379520.000000\n",
      "Train Epoch: 1208 [5120/11093 (45%)]\tLoss: 1260567168.000000\n",
      "Train Epoch: 1208 [8530/11093 (91%)]\tLoss: 1427670029.205158\n",
      "Train Epoch: 1209 [0/11093 (0%)]\tLoss: 1175857408.000000\n",
      "Train Epoch: 1209 [5120/11093 (45%)]\tLoss: 1357379328.000000\n",
      "Train Epoch: 1209 [8530/11093 (91%)]\tLoss: 1228993150.649472\n",
      "Train Epoch: 1210 [0/11093 (0%)]\tLoss: 1700452992.000000\n",
      "Train Epoch: 1210 [5120/11093 (45%)]\tLoss: 1091242752.000000\n",
      "Train Epoch: 1210 [8530/11093 (91%)]\tLoss: 1329892775.765533\n",
      "Train Epoch: 1211 [0/11093 (0%)]\tLoss: 1147269760.000000\n",
      "Train Epoch: 1211 [5120/11093 (45%)]\tLoss: 1231376000.000000\n",
      "Train Epoch: 1211 [8530/11093 (91%)]\tLoss: 1478052231.352872\n",
      "Train Epoch: 1212 [0/11093 (0%)]\tLoss: 1442872704.000000\n",
      "Train Epoch: 1212 [5120/11093 (45%)]\tLoss: 1599153536.000000\n",
      "Train Epoch: 1212 [8530/11093 (91%)]\tLoss: 1342174975.099648\n",
      "Train Epoch: 1213 [0/11093 (0%)]\tLoss: 1086861952.000000\n",
      "Train Epoch: 1213 [5120/11093 (45%)]\tLoss: 1247544448.000000\n",
      "Train Epoch: 1213 [8530/11093 (91%)]\tLoss: 1485336638.424385\n",
      "Train Epoch: 1214 [0/11093 (0%)]\tLoss: 1182600192.000000\n",
      "Train Epoch: 1214 [5120/11093 (45%)]\tLoss: 1192618880.000000\n",
      "Train Epoch: 1214 [8530/11093 (91%)]\tLoss: 1582947785.378664\n",
      "Train Epoch: 1215 [0/11093 (0%)]\tLoss: 1293305856.000000\n",
      "Train Epoch: 1215 [5120/11093 (45%)]\tLoss: 1282045056.000000\n",
      "Train Epoch: 1215 [8530/11093 (91%)]\tLoss: 1537472408.759672\n",
      "Train Epoch: 1216 [0/11093 (0%)]\tLoss: 1182687744.000000\n",
      "Train Epoch: 1216 [5120/11093 (45%)]\tLoss: 1379176704.000000\n",
      "Train Epoch: 1216 [8530/11093 (91%)]\tLoss: 1241336045.692849\n",
      "Train Epoch: 1217 [0/11093 (0%)]\tLoss: 1180046592.000000\n",
      "Train Epoch: 1217 [5120/11093 (45%)]\tLoss: 1454059520.000000\n",
      "Train Epoch: 1217 [8530/11093 (91%)]\tLoss: 1269969745.932005\n",
      "Train Epoch: 1218 [0/11093 (0%)]\tLoss: 1281397504.000000\n",
      "Train Epoch: 1218 [5120/11093 (45%)]\tLoss: 1242595328.000000\n",
      "Train Epoch: 1218 [8530/11093 (91%)]\tLoss: 1242400218.185229\n",
      "Train Epoch: 1219 [0/11093 (0%)]\tLoss: 1314012416.000000\n",
      "Train Epoch: 1219 [5120/11093 (45%)]\tLoss: 1337525888.000000\n",
      "Train Epoch: 1219 [8530/11093 (91%)]\tLoss: 1124873733.402110\n",
      "Train Epoch: 1220 [0/11093 (0%)]\tLoss: 1350854912.000000\n",
      "Train Epoch: 1220 [5120/11093 (45%)]\tLoss: 1446226432.000000\n",
      "Train Epoch: 1220 [8530/11093 (91%)]\tLoss: 1489606696.815944\n",
      "Train Epoch: 1221 [0/11093 (0%)]\tLoss: 1076070400.000000\n",
      "Train Epoch: 1221 [5120/11093 (45%)]\tLoss: 1297762816.000000\n",
      "Train Epoch: 1221 [8530/11093 (91%)]\tLoss: 1369389855.512310\n",
      "Train Epoch: 1222 [0/11093 (0%)]\tLoss: 1246114560.000000\n",
      "Train Epoch: 1222 [5120/11093 (45%)]\tLoss: 1102109696.000000\n",
      "Train Epoch: 1222 [8530/11093 (91%)]\tLoss: 1122669557.195780\n",
      "Train Epoch: 1223 [0/11093 (0%)]\tLoss: 1160614656.000000\n",
      "Train Epoch: 1223 [5120/11093 (45%)]\tLoss: 1471068160.000000\n",
      "Train Epoch: 1223 [8530/11093 (91%)]\tLoss: 1320807473.219226\n",
      "Train Epoch: 1224 [0/11093 (0%)]\tLoss: 1414347008.000000\n",
      "Train Epoch: 1224 [5120/11093 (45%)]\tLoss: 1171885696.000000\n",
      "Train Epoch: 1224 [8530/11093 (91%)]\tLoss: 1171511932.248535\n",
      "Train Epoch: 1225 [0/11093 (0%)]\tLoss: 1298693120.000000\n",
      "Train Epoch: 1225 [5120/11093 (45%)]\tLoss: 1281841152.000000\n",
      "Train Epoch: 1225 [8530/11093 (91%)]\tLoss: 1395090416.393904\n",
      "Train Epoch: 1226 [0/11093 (0%)]\tLoss: 1189774080.000000\n",
      "Train Epoch: 1226 [5120/11093 (45%)]\tLoss: 1181909632.000000\n",
      "Train Epoch: 1226 [8530/11093 (91%)]\tLoss: 1408964687.230950\n",
      "Train Epoch: 1227 [0/11093 (0%)]\tLoss: 1217434112.000000\n",
      "Train Epoch: 1227 [5120/11093 (45%)]\tLoss: 1451383552.000000\n",
      "Train Epoch: 1227 [8530/11093 (91%)]\tLoss: 1225417942.883939\n",
      "Train Epoch: 1228 [0/11093 (0%)]\tLoss: 1302733568.000000\n",
      "Train Epoch: 1228 [5120/11093 (45%)]\tLoss: 1319073792.000000\n",
      "Train Epoch: 1228 [8530/11093 (91%)]\tLoss: 1242349279.887456\n",
      "Train Epoch: 1229 [0/11093 (0%)]\tLoss: 1301445504.000000\n",
      "Train Epoch: 1229 [5120/11093 (45%)]\tLoss: 1312948736.000000\n",
      "Train Epoch: 1229 [8530/11093 (91%)]\tLoss: 1331023713.538101\n",
      "Train Epoch: 1230 [0/11093 (0%)]\tLoss: 1413483008.000000\n",
      "Train Epoch: 1230 [5120/11093 (45%)]\tLoss: 1220491776.000000\n",
      "Train Epoch: 1230 [8530/11093 (91%)]\tLoss: 1421479066.860492\n",
      "Train Epoch: 1231 [0/11093 (0%)]\tLoss: 1195761024.000000\n",
      "Train Epoch: 1231 [5120/11093 (45%)]\tLoss: 1300212224.000000\n",
      "Train Epoch: 1231 [8530/11093 (91%)]\tLoss: 1173144954.147714\n",
      "Train Epoch: 1232 [0/11093 (0%)]\tLoss: 1213108992.000000\n",
      "Train Epoch: 1232 [5120/11093 (45%)]\tLoss: 1281177088.000000\n",
      "Train Epoch: 1232 [8530/11093 (91%)]\tLoss: 1277103182.030481\n",
      "Train Epoch: 1233 [0/11093 (0%)]\tLoss: 1149391488.000000\n",
      "Train Epoch: 1233 [5120/11093 (45%)]\tLoss: 1247785984.000000\n",
      "Train Epoch: 1233 [8530/11093 (91%)]\tLoss: 1115583141.064478\n",
      "Train Epoch: 1234 [0/11093 (0%)]\tLoss: 1356918144.000000\n",
      "Train Epoch: 1234 [5120/11093 (45%)]\tLoss: 1483611392.000000\n",
      "Train Epoch: 1234 [8530/11093 (91%)]\tLoss: 1240149943.971864\n",
      "Train Epoch: 1235 [0/11093 (0%)]\tLoss: 1498941696.000000\n",
      "Train Epoch: 1235 [5120/11093 (45%)]\tLoss: 1130296832.000000\n",
      "Train Epoch: 1235 [8530/11093 (91%)]\tLoss: 1188085010.907386\n",
      "Train Epoch: 1236 [0/11093 (0%)]\tLoss: 1471479808.000000\n",
      "Train Epoch: 1236 [5120/11093 (45%)]\tLoss: 1184152320.000000\n",
      "Train Epoch: 1236 [8530/11093 (91%)]\tLoss: 1249404887.184056\n",
      "Train Epoch: 1237 [0/11093 (0%)]\tLoss: 1457980032.000000\n",
      "Train Epoch: 1237 [5120/11093 (45%)]\tLoss: 1445766272.000000\n",
      "Train Epoch: 1237 [8530/11093 (91%)]\tLoss: 1243439036.773740\n",
      "Train Epoch: 1238 [0/11093 (0%)]\tLoss: 1284829696.000000\n",
      "Train Epoch: 1238 [5120/11093 (45%)]\tLoss: 1295360512.000000\n",
      "Train Epoch: 1238 [8530/11093 (91%)]\tLoss: 1233292173.955451\n",
      "Train Epoch: 1239 [0/11093 (0%)]\tLoss: 1488305152.000000\n",
      "Train Epoch: 1239 [5120/11093 (45%)]\tLoss: 1110889600.000000\n",
      "Train Epoch: 1239 [8530/11093 (91%)]\tLoss: 1179271917.092614\n",
      "Train Epoch: 1240 [0/11093 (0%)]\tLoss: 1227936000.000000\n",
      "Train Epoch: 1240 [5120/11093 (45%)]\tLoss: 1316747008.000000\n",
      "Train Epoch: 1240 [8530/11093 (91%)]\tLoss: 1272401953.613130\n",
      "Train Epoch: 1241 [0/11093 (0%)]\tLoss: 1182259200.000000\n",
      "Train Epoch: 1241 [5120/11093 (45%)]\tLoss: 1251751296.000000\n",
      "Train Epoch: 1241 [8530/11093 (91%)]\tLoss: 1300202893.355217\n",
      "Train Epoch: 1242 [0/11093 (0%)]\tLoss: 1243257600.000000\n",
      "Train Epoch: 1242 [5120/11093 (45%)]\tLoss: 1219248768.000000\n",
      "Train Epoch: 1242 [8530/11093 (91%)]\tLoss: 1201858480.769050\n",
      "Train Epoch: 1243 [0/11093 (0%)]\tLoss: 1360061184.000000\n",
      "Train Epoch: 1243 [5120/11093 (45%)]\tLoss: 1251153280.000000\n",
      "Train Epoch: 1243 [8530/11093 (91%)]\tLoss: 1138925635.226260\n",
      "Train Epoch: 1244 [0/11093 (0%)]\tLoss: 1380404480.000000\n",
      "Train Epoch: 1244 [5120/11093 (45%)]\tLoss: 1173497728.000000\n",
      "Train Epoch: 1244 [8530/11093 (91%)]\tLoss: 1277987111.315357\n",
      "Train Epoch: 1245 [0/11093 (0%)]\tLoss: 1244477440.000000\n",
      "Train Epoch: 1245 [5120/11093 (45%)]\tLoss: 1371110016.000000\n",
      "Train Epoch: 1245 [8530/11093 (91%)]\tLoss: 1250970529.162954\n",
      "Train Epoch: 1246 [0/11093 (0%)]\tLoss: 1308736000.000000\n",
      "Train Epoch: 1246 [5120/11093 (45%)]\tLoss: 1466737920.000000\n",
      "Train Epoch: 1246 [8530/11093 (91%)]\tLoss: 1340783276.267292\n",
      "Train Epoch: 1247 [0/11093 (0%)]\tLoss: 1181136640.000000\n",
      "Train Epoch: 1247 [5120/11093 (45%)]\tLoss: 1418138880.000000\n",
      "Train Epoch: 1247 [8530/11093 (91%)]\tLoss: 1177752757.270809\n",
      "Train Epoch: 1248 [0/11093 (0%)]\tLoss: 1252742528.000000\n",
      "Train Epoch: 1248 [5120/11093 (45%)]\tLoss: 1272340608.000000\n",
      "Train Epoch: 1248 [8530/11093 (91%)]\tLoss: 1240436980.895662\n",
      "Train Epoch: 1249 [0/11093 (0%)]\tLoss: 1135697152.000000\n",
      "Train Epoch: 1249 [5120/11093 (45%)]\tLoss: 1353734144.000000\n",
      "Train Epoch: 1249 [8530/11093 (91%)]\tLoss: 1199440025.660023\n",
      "Train Epoch: 1250 [0/11093 (0%)]\tLoss: 1358916224.000000\n",
      "Train Epoch: 1250 [5120/11093 (45%)]\tLoss: 1405179392.000000\n",
      "Train Epoch: 1250 [8530/11093 (91%)]\tLoss: 1396698007.559203\n",
      "Train Epoch: 1251 [0/11093 (0%)]\tLoss: 1204289536.000000\n",
      "Train Epoch: 1251 [5120/11093 (45%)]\tLoss: 1209507968.000000\n",
      "Train Epoch: 1251 [8530/11093 (91%)]\tLoss: 1196573036.942556\n",
      "Train Epoch: 1252 [0/11093 (0%)]\tLoss: 1379695232.000000\n",
      "Train Epoch: 1252 [5120/11093 (45%)]\tLoss: 1266720000.000000\n",
      "Train Epoch: 1252 [8530/11093 (91%)]\tLoss: 1538952615.765533\n",
      "Train Epoch: 1253 [0/11093 (0%)]\tLoss: 1201963008.000000\n",
      "Train Epoch: 1253 [5120/11093 (45%)]\tLoss: 1230609920.000000\n",
      "Train Epoch: 1253 [8530/11093 (91%)]\tLoss: 1338015398.264947\n",
      "Train Epoch: 1254 [0/11093 (0%)]\tLoss: 1227990016.000000\n",
      "Train Epoch: 1254 [5120/11093 (45%)]\tLoss: 1170683776.000000\n",
      "Train Epoch: 1254 [8530/11093 (91%)]\tLoss: 1118596414.124267\n",
      "Train Epoch: 1255 [0/11093 (0%)]\tLoss: 1259075072.000000\n",
      "Train Epoch: 1255 [5120/11093 (45%)]\tLoss: 1168148736.000000\n",
      "Train Epoch: 1255 [8530/11093 (91%)]\tLoss: 1406462794.729191\n",
      "Train Epoch: 1256 [0/11093 (0%)]\tLoss: 1306442752.000000\n",
      "Train Epoch: 1256 [5120/11093 (45%)]\tLoss: 1480039040.000000\n",
      "Train Epoch: 1256 [8530/11093 (91%)]\tLoss: 1259736756.670574\n",
      "Train Epoch: 1257 [0/11093 (0%)]\tLoss: 1321996416.000000\n",
      "Train Epoch: 1257 [5120/11093 (45%)]\tLoss: 1173813632.000000\n",
      "Train Epoch: 1257 [8530/11093 (91%)]\tLoss: 1264717108.520516\n",
      "Train Epoch: 1258 [0/11093 (0%)]\tLoss: 1415363712.000000\n",
      "Train Epoch: 1258 [5120/11093 (45%)]\tLoss: 1174479104.000000\n",
      "Train Epoch: 1258 [8530/11093 (91%)]\tLoss: 1136449250.288394\n",
      "Train Epoch: 1259 [0/11093 (0%)]\tLoss: 1163944704.000000\n",
      "Train Epoch: 1259 [5120/11093 (45%)]\tLoss: 1249447680.000000\n",
      "Train Epoch: 1259 [8530/11093 (91%)]\tLoss: 1231614360.159437\n",
      "Train Epoch: 1260 [0/11093 (0%)]\tLoss: 1338115584.000000\n",
      "Train Epoch: 1260 [5120/11093 (45%)]\tLoss: 1240807680.000000\n",
      "Train Epoch: 1260 [8530/11093 (91%)]\tLoss: 1381580319.812427\n",
      "Train Epoch: 1261 [0/11093 (0%)]\tLoss: 1271053312.000000\n",
      "Train Epoch: 1261 [5120/11093 (45%)]\tLoss: 1386041600.000000\n",
      "Train Epoch: 1261 [8530/11093 (91%)]\tLoss: 1395939849.003517\n",
      "Train Epoch: 1262 [0/11093 (0%)]\tLoss: 1165860352.000000\n",
      "Train Epoch: 1262 [5120/11093 (45%)]\tLoss: 1256562176.000000\n",
      "Train Epoch: 1262 [8530/11093 (91%)]\tLoss: 1128009780.820633\n",
      "Train Epoch: 1263 [0/11093 (0%)]\tLoss: 1291930880.000000\n",
      "Train Epoch: 1263 [5120/11093 (45%)]\tLoss: 1225692032.000000\n",
      "Train Epoch: 1263 [8530/11093 (91%)]\tLoss: 1351618459.160610\n",
      "Train Epoch: 1264 [0/11093 (0%)]\tLoss: 1279620608.000000\n",
      "Train Epoch: 1264 [5120/11093 (45%)]\tLoss: 1377212672.000000\n",
      "Train Epoch: 1264 [8530/11093 (91%)]\tLoss: 1209707127.446659\n",
      "Train Epoch: 1265 [0/11093 (0%)]\tLoss: 1530443520.000000\n",
      "Train Epoch: 1265 [5120/11093 (45%)]\tLoss: 1320412672.000000\n",
      "Train Epoch: 1265 [8530/11093 (91%)]\tLoss: 1280349711.005862\n",
      "Train Epoch: 1266 [0/11093 (0%)]\tLoss: 1101502592.000000\n",
      "Train Epoch: 1266 [5120/11093 (45%)]\tLoss: 1209757056.000000\n",
      "Train Epoch: 1266 [8530/11093 (91%)]\tLoss: 1170089962.391559\n",
      "Train Epoch: 1267 [0/11093 (0%)]\tLoss: 1327794432.000000\n",
      "Train Epoch: 1267 [5120/11093 (45%)]\tLoss: 1066388864.000000\n",
      "Train Epoch: 1267 [8530/11093 (91%)]\tLoss: 1272571133.298945\n",
      "Train Epoch: 1268 [0/11093 (0%)]\tLoss: 1302461184.000000\n",
      "Train Epoch: 1268 [5120/11093 (45%)]\tLoss: 1261370624.000000\n",
      "Train Epoch: 1268 [8530/11093 (91%)]\tLoss: 1333401141.420867\n",
      "Train Epoch: 1269 [0/11093 (0%)]\tLoss: 1176201984.000000\n",
      "Train Epoch: 1269 [5120/11093 (45%)]\tLoss: 1354204928.000000\n",
      "Train Epoch: 1269 [8530/11093 (91%)]\tLoss: 1203254789.402110\n",
      "Train Epoch: 1270 [0/11093 (0%)]\tLoss: 1701660672.000000\n",
      "Train Epoch: 1270 [5120/11093 (45%)]\tLoss: 1135325952.000000\n",
      "Train Epoch: 1270 [8530/11093 (91%)]\tLoss: 1203608053.796014\n",
      "Train Epoch: 1271 [0/11093 (0%)]\tLoss: 1103995136.000000\n",
      "Train Epoch: 1271 [5120/11093 (45%)]\tLoss: 1241585408.000000\n",
      "Train Epoch: 1271 [8530/11093 (91%)]\tLoss: 1173088868.239156\n",
      "Train Epoch: 1272 [0/11093 (0%)]\tLoss: 1252167680.000000\n",
      "Train Epoch: 1272 [5120/11093 (45%)]\tLoss: 1323252736.000000\n",
      "Train Epoch: 1272 [8530/11093 (91%)]\tLoss: 1218954694.977726\n",
      "Train Epoch: 1273 [0/11093 (0%)]\tLoss: 1252853504.000000\n",
      "Train Epoch: 1273 [5120/11093 (45%)]\tLoss: 1316471168.000000\n",
      "Train Epoch: 1273 [8530/11093 (91%)]\tLoss: 1229622081.125440\n",
      "Train Epoch: 1274 [0/11093 (0%)]\tLoss: 1155747584.000000\n",
      "Train Epoch: 1274 [5120/11093 (45%)]\tLoss: 1341093632.000000\n",
      "Train Epoch: 1274 [8530/11093 (91%)]\tLoss: 1255015321.960141\n",
      "Train Epoch: 1275 [0/11093 (0%)]\tLoss: 1260300672.000000\n",
      "Train Epoch: 1275 [5120/11093 (45%)]\tLoss: 1483256576.000000\n",
      "Train Epoch: 1275 [8530/11093 (91%)]\tLoss: 1289499858.082063\n",
      "Train Epoch: 1276 [0/11093 (0%)]\tLoss: 1357326848.000000\n",
      "Train Epoch: 1276 [5120/11093 (45%)]\tLoss: 1256055424.000000\n",
      "Train Epoch: 1276 [8530/11093 (91%)]\tLoss: 1363944758.921454\n",
      "Train Epoch: 1277 [0/11093 (0%)]\tLoss: 1125562112.000000\n",
      "Train Epoch: 1277 [5120/11093 (45%)]\tLoss: 1417805568.000000\n",
      "Train Epoch: 1277 [8530/11093 (91%)]\tLoss: 1082267496.740914\n",
      "Train Epoch: 1278 [0/11093 (0%)]\tLoss: 1220417280.000000\n",
      "Train Epoch: 1278 [5120/11093 (45%)]\tLoss: 1348836224.000000\n",
      "Train Epoch: 1278 [8530/11093 (91%)]\tLoss: 1179424885.645956\n",
      "Train Epoch: 1279 [0/11093 (0%)]\tLoss: 1057358016.000000\n",
      "Train Epoch: 1279 [5120/11093 (45%)]\tLoss: 1646503808.000000\n",
      "Train Epoch: 1279 [8530/11093 (91%)]\tLoss: 1272779803.610785\n",
      "Train Epoch: 1280 [0/11093 (0%)]\tLoss: 1221966336.000000\n",
      "Train Epoch: 1280 [5120/11093 (45%)]\tLoss: 1242384896.000000\n",
      "Train Epoch: 1280 [8530/11093 (91%)]\tLoss: 1345442555.498241\n",
      "Train Epoch: 1281 [0/11093 (0%)]\tLoss: 1303346560.000000\n",
      "Train Epoch: 1281 [5120/11093 (45%)]\tLoss: 1286120192.000000\n",
      "Train Epoch: 1281 [8530/11093 (91%)]\tLoss: 1152685736.665885\n",
      "Train Epoch: 1282 [0/11093 (0%)]\tLoss: 1147794944.000000\n",
      "Train Epoch: 1282 [5120/11093 (45%)]\tLoss: 1123876096.000000\n",
      "Train Epoch: 1282 [8530/11093 (91%)]\tLoss: 1235356365.880422\n",
      "Train Epoch: 1283 [0/11093 (0%)]\tLoss: 1310015872.000000\n",
      "Train Epoch: 1283 [5120/11093 (45%)]\tLoss: 1234380800.000000\n",
      "Train Epoch: 1283 [8530/11093 (91%)]\tLoss: 1298311031.146542\n",
      "Train Epoch: 1284 [0/11093 (0%)]\tLoss: 1269353472.000000\n",
      "Train Epoch: 1284 [5120/11093 (45%)]\tLoss: 1542733312.000000\n",
      "Train Epoch: 1284 [8530/11093 (91%)]\tLoss: 1482442298.222743\n",
      "Train Epoch: 1285 [0/11093 (0%)]\tLoss: 1253836032.000000\n",
      "Train Epoch: 1285 [5120/11093 (45%)]\tLoss: 1261502080.000000\n",
      "Train Epoch: 1285 [8530/11093 (91%)]\tLoss: 1287688206.405627\n",
      "Train Epoch: 1286 [0/11093 (0%)]\tLoss: 1342459904.000000\n",
      "Train Epoch: 1286 [5120/11093 (45%)]\tLoss: 1188601088.000000\n",
      "Train Epoch: 1286 [8530/11093 (91%)]\tLoss: 1384998333.373974\n",
      "Train Epoch: 1287 [0/11093 (0%)]\tLoss: 1391731200.000000\n",
      "Train Epoch: 1287 [5120/11093 (45%)]\tLoss: 1362799488.000000\n",
      "Train Epoch: 1287 [8530/11093 (91%)]\tLoss: 1494678092.229777\n",
      "Train Epoch: 1288 [0/11093 (0%)]\tLoss: 1164502272.000000\n",
      "Train Epoch: 1288 [5120/11093 (45%)]\tLoss: 1394239232.000000\n",
      "Train Epoch: 1288 [8530/11093 (91%)]\tLoss: 1328634300.173505\n",
      "Train Epoch: 1289 [0/11093 (0%)]\tLoss: 1197704448.000000\n",
      "Train Epoch: 1289 [5120/11093 (45%)]\tLoss: 1499089408.000000\n",
      "Train Epoch: 1289 [8530/11093 (91%)]\tLoss: 1330666607.643611\n",
      "Train Epoch: 1290 [0/11093 (0%)]\tLoss: 1239200000.000000\n",
      "Train Epoch: 1290 [5120/11093 (45%)]\tLoss: 1403152896.000000\n",
      "Train Epoch: 1290 [8530/11093 (91%)]\tLoss: 1320358324.970692\n",
      "Train Epoch: 1291 [0/11093 (0%)]\tLoss: 1181994496.000000\n",
      "Train Epoch: 1291 [5120/11093 (45%)]\tLoss: 1424583168.000000\n",
      "Train Epoch: 1291 [8530/11093 (91%)]\tLoss: 1220091318.171161\n",
      "Train Epoch: 1292 [0/11093 (0%)]\tLoss: 1291722880.000000\n",
      "Train Epoch: 1292 [5120/11093 (45%)]\tLoss: 1224440576.000000\n",
      "Train Epoch: 1292 [8530/11093 (91%)]\tLoss: 1234373633.200469\n",
      "Train Epoch: 1293 [0/11093 (0%)]\tLoss: 1147490048.000000\n",
      "Train Epoch: 1293 [5120/11093 (45%)]\tLoss: 1252078336.000000\n",
      "Train Epoch: 1293 [8530/11093 (91%)]\tLoss: 1173145415.127784\n",
      "Train Epoch: 1294 [0/11093 (0%)]\tLoss: 1220332544.000000\n",
      "Train Epoch: 1294 [5120/11093 (45%)]\tLoss: 1215418112.000000\n",
      "Train Epoch: 1294 [8530/11093 (91%)]\tLoss: 1274864355.488863\n",
      "Train Epoch: 1295 [0/11093 (0%)]\tLoss: 1178946944.000000\n",
      "Train Epoch: 1295 [5120/11093 (45%)]\tLoss: 1464284416.000000\n",
      "Train Epoch: 1295 [8530/11093 (91%)]\tLoss: 1197455352.797186\n",
      "Train Epoch: 1296 [0/11093 (0%)]\tLoss: 1315090816.000000\n",
      "Train Epoch: 1296 [5120/11093 (45%)]\tLoss: 1291048832.000000\n",
      "Train Epoch: 1296 [8530/11093 (91%)]\tLoss: 1411491472.656507\n",
      "Train Epoch: 1297 [0/11093 (0%)]\tLoss: 1332855808.000000\n",
      "Train Epoch: 1297 [5120/11093 (45%)]\tLoss: 1353074944.000000\n",
      "Train Epoch: 1297 [8530/11093 (91%)]\tLoss: 1240373903.456038\n",
      "Train Epoch: 1298 [0/11093 (0%)]\tLoss: 1797497472.000000\n",
      "Train Epoch: 1298 [5120/11093 (45%)]\tLoss: 1242922240.000000\n",
      "Train Epoch: 1298 [8530/11093 (91%)]\tLoss: 1027161170.832356\n",
      "Train Epoch: 1299 [0/11093 (0%)]\tLoss: 1394810112.000000\n",
      "Train Epoch: 1299 [5120/11093 (45%)]\tLoss: 1306553344.000000\n",
      "Train Epoch: 1299 [8530/11093 (91%)]\tLoss: 1377427504.018757\n",
      "Train Epoch: 1300 [0/11093 (0%)]\tLoss: 1559197696.000000\n",
      "Train Epoch: 1300 [5120/11093 (45%)]\tLoss: 1403267840.000000\n",
      "Train Epoch: 1300 [8530/11093 (91%)]\tLoss: 1181475171.338804\n",
      "Train Epoch: 1301 [0/11093 (0%)]\tLoss: 1149197312.000000\n",
      "Train Epoch: 1301 [5120/11093 (45%)]\tLoss: 1256367616.000000\n",
      "Train Epoch: 1301 [8530/11093 (91%)]\tLoss: 1080271837.186401\n",
      "Train Epoch: 1302 [0/11093 (0%)]\tLoss: 1306033152.000000\n",
      "Train Epoch: 1302 [5120/11093 (45%)]\tLoss: 1171088640.000000\n",
      "Train Epoch: 1302 [8530/11093 (91%)]\tLoss: 1247983070.987104\n",
      "Train Epoch: 1303 [0/11093 (0%)]\tLoss: 1274411904.000000\n",
      "Train Epoch: 1303 [5120/11093 (45%)]\tLoss: 1283957760.000000\n",
      "Train Epoch: 1303 [8530/11093 (91%)]\tLoss: 1279508422.377491\n",
      "Train Epoch: 1304 [0/11093 (0%)]\tLoss: 1174292480.000000\n",
      "Train Epoch: 1304 [5120/11093 (45%)]\tLoss: 1346484864.000000\n",
      "Train Epoch: 1304 [8530/11093 (91%)]\tLoss: 1247973467.235639\n",
      "Train Epoch: 1305 [0/11093 (0%)]\tLoss: 1184632320.000000\n",
      "Train Epoch: 1305 [5120/11093 (45%)]\tLoss: 1259981568.000000\n",
      "Train Epoch: 1305 [8530/11093 (91%)]\tLoss: 1416312094.912075\n",
      "Train Epoch: 1306 [0/11093 (0%)]\tLoss: 1431541760.000000\n",
      "Train Epoch: 1306 [5120/11093 (45%)]\tLoss: 1464845568.000000\n",
      "Train Epoch: 1306 [8530/11093 (91%)]\tLoss: 1213435380.595545\n",
      "Train Epoch: 1307 [0/11093 (0%)]\tLoss: 1480741248.000000\n",
      "Train Epoch: 1307 [5120/11093 (45%)]\tLoss: 1354339584.000000\n",
      "Train Epoch: 1307 [8530/11093 (91%)]\tLoss: 1337854362.560375\n",
      "Train Epoch: 1308 [0/11093 (0%)]\tLoss: 1387813376.000000\n",
      "Train Epoch: 1308 [5120/11093 (45%)]\tLoss: 1177944064.000000\n",
      "Train Epoch: 1308 [8530/11093 (91%)]\tLoss: 1236692439.784291\n",
      "Train Epoch: 1309 [0/11093 (0%)]\tLoss: 1418681728.000000\n",
      "Train Epoch: 1309 [5120/11093 (45%)]\tLoss: 1363342080.000000\n",
      "Train Epoch: 1309 [8530/11093 (91%)]\tLoss: 1134400808.515826\n",
      "Train Epoch: 1310 [0/11093 (0%)]\tLoss: 1269687040.000000\n",
      "Train Epoch: 1310 [5120/11093 (45%)]\tLoss: 1359622528.000000\n",
      "Train Epoch: 1310 [8530/11093 (91%)]\tLoss: 1554754858.916764\n",
      "Train Epoch: 1311 [0/11093 (0%)]\tLoss: 1076705664.000000\n",
      "Train Epoch: 1311 [5120/11093 (45%)]\tLoss: 1108582016.000000\n",
      "Train Epoch: 1311 [8530/11093 (91%)]\tLoss: 1148798445.392731\n",
      "Train Epoch: 1312 [0/11093 (0%)]\tLoss: 1159679872.000000\n",
      "Train Epoch: 1312 [5120/11093 (45%)]\tLoss: 1197768960.000000\n",
      "Train Epoch: 1312 [8530/11093 (91%)]\tLoss: 1166538341.439625\n",
      "Train Epoch: 1313 [0/11093 (0%)]\tLoss: 1220794624.000000\n",
      "Train Epoch: 1313 [5120/11093 (45%)]\tLoss: 1190913024.000000\n",
      "Train Epoch: 1313 [8530/11093 (91%)]\tLoss: 1149455188.332942\n",
      "Train Epoch: 1314 [0/11093 (0%)]\tLoss: 1486797056.000000\n",
      "Train Epoch: 1314 [5120/11093 (45%)]\tLoss: 1508026368.000000\n",
      "Train Epoch: 1314 [8530/11093 (91%)]\tLoss: 1257388985.172333\n",
      "Train Epoch: 1315 [0/11093 (0%)]\tLoss: 1363404544.000000\n",
      "Train Epoch: 1315 [5120/11093 (45%)]\tLoss: 1313864960.000000\n",
      "Train Epoch: 1315 [8530/11093 (91%)]\tLoss: 1218822854.677608\n",
      "Train Epoch: 1316 [0/11093 (0%)]\tLoss: 1327414144.000000\n",
      "Train Epoch: 1316 [5120/11093 (45%)]\tLoss: 1046263296.000000\n",
      "Train Epoch: 1316 [8530/11093 (91%)]\tLoss: 1177628138.991794\n",
      "Train Epoch: 1317 [0/11093 (0%)]\tLoss: 1407526144.000000\n",
      "Train Epoch: 1317 [5120/11093 (45%)]\tLoss: 1342023936.000000\n",
      "Train Epoch: 1317 [8530/11093 (91%)]\tLoss: 1287258112.000000\n",
      "Train Epoch: 1318 [0/11093 (0%)]\tLoss: 1481103872.000000\n",
      "Train Epoch: 1318 [5120/11093 (45%)]\tLoss: 1276082816.000000\n",
      "Train Epoch: 1318 [8530/11093 (91%)]\tLoss: 1122743160.347011\n",
      "Train Epoch: 1319 [0/11093 (0%)]\tLoss: 1119249920.000000\n",
      "Train Epoch: 1319 [5120/11093 (45%)]\tLoss: 1277271552.000000\n",
      "Train Epoch: 1319 [8530/11093 (91%)]\tLoss: 1445242896.806565\n",
      "Train Epoch: 1320 [0/11093 (0%)]\tLoss: 1260440576.000000\n",
      "Train Epoch: 1320 [5120/11093 (45%)]\tLoss: 1264004096.000000\n",
      "Train Epoch: 1320 [8530/11093 (91%)]\tLoss: 1348365169.144197\n",
      "Train Epoch: 1321 [0/11093 (0%)]\tLoss: 1151717888.000000\n",
      "Train Epoch: 1321 [5120/11093 (45%)]\tLoss: 1111701504.000000\n",
      "Train Epoch: 1321 [8530/11093 (91%)]\tLoss: 1375534412.529895\n",
      "Train Epoch: 1322 [0/11093 (0%)]\tLoss: 1294190080.000000\n",
      "Train Epoch: 1322 [5120/11093 (45%)]\tLoss: 1417877760.000000\n",
      "Train Epoch: 1322 [8530/11093 (91%)]\tLoss: 1277461209.885111\n",
      "Train Epoch: 1323 [0/11093 (0%)]\tLoss: 1397848320.000000\n",
      "Train Epoch: 1323 [5120/11093 (45%)]\tLoss: 1289319680.000000\n",
      "Train Epoch: 1323 [8530/11093 (91%)]\tLoss: 1309881784.572098\n",
      "Train Epoch: 1324 [0/11093 (0%)]\tLoss: 1249722880.000000\n",
      "Train Epoch: 1324 [5120/11093 (45%)]\tLoss: 1244780288.000000\n",
      "Train Epoch: 1324 [8530/11093 (91%)]\tLoss: 1176263637.983587\n",
      "Train Epoch: 1325 [0/11093 (0%)]\tLoss: 1429335552.000000\n",
      "Train Epoch: 1325 [5120/11093 (45%)]\tLoss: 1460563456.000000\n",
      "Train Epoch: 1325 [8530/11093 (91%)]\tLoss: 1169587955.094959\n",
      "Train Epoch: 1326 [0/11093 (0%)]\tLoss: 1372972672.000000\n",
      "Train Epoch: 1326 [5120/11093 (45%)]\tLoss: 1339176960.000000\n",
      "Train Epoch: 1326 [8530/11093 (91%)]\tLoss: 1228974250.466588\n",
      "Train Epoch: 1327 [0/11093 (0%)]\tLoss: 1291210624.000000\n",
      "Train Epoch: 1327 [5120/11093 (45%)]\tLoss: 1127452544.000000\n",
      "Train Epoch: 1327 [8530/11093 (91%)]\tLoss: 1268881756.135991\n",
      "Train Epoch: 1328 [0/11093 (0%)]\tLoss: 1502979840.000000\n",
      "Train Epoch: 1328 [5120/11093 (45%)]\tLoss: 1245688832.000000\n",
      "Train Epoch: 1328 [8530/11093 (91%)]\tLoss: 1113534161.481829\n",
      "Train Epoch: 1329 [0/11093 (0%)]\tLoss: 1363492864.000000\n",
      "Train Epoch: 1329 [5120/11093 (45%)]\tLoss: 1293802624.000000\n",
      "Train Epoch: 1329 [8530/11093 (91%)]\tLoss: 1172536998.264947\n",
      "Train Epoch: 1330 [0/11093 (0%)]\tLoss: 1111384192.000000\n",
      "Train Epoch: 1330 [5120/11093 (45%)]\tLoss: 1378950144.000000\n",
      "Train Epoch: 1330 [8530/11093 (91%)]\tLoss: 1167920206.030481\n",
      "Train Epoch: 1331 [0/11093 (0%)]\tLoss: 1216492416.000000\n",
      "Train Epoch: 1331 [5120/11093 (45%)]\tLoss: 1714552832.000000\n",
      "Train Epoch: 1331 [8530/11093 (91%)]\tLoss: 1328478949.889801\n",
      "Train Epoch: 1332 [0/11093 (0%)]\tLoss: 1424917248.000000\n",
      "Train Epoch: 1332 [5120/11093 (45%)]\tLoss: 1133481216.000000\n",
      "Train Epoch: 1332 [8530/11093 (91%)]\tLoss: 1321771536.206331\n",
      "Train Epoch: 1333 [0/11093 (0%)]\tLoss: 1313143552.000000\n",
      "Train Epoch: 1333 [5120/11093 (45%)]\tLoss: 1247942016.000000\n",
      "Train Epoch: 1333 [8530/11093 (91%)]\tLoss: 1085237284.014068\n",
      "Train Epoch: 1334 [0/11093 (0%)]\tLoss: 1251077376.000000\n",
      "Train Epoch: 1334 [5120/11093 (45%)]\tLoss: 1196525568.000000\n",
      "Train Epoch: 1334 [8530/11093 (91%)]\tLoss: 1209034864.844080\n",
      "Train Epoch: 1335 [0/11093 (0%)]\tLoss: 1405133824.000000\n",
      "Train Epoch: 1335 [5120/11093 (45%)]\tLoss: 1266475520.000000\n",
      "Train Epoch: 1335 [8530/11093 (91%)]\tLoss: 1264085488.994138\n",
      "Train Epoch: 1336 [0/11093 (0%)]\tLoss: 1230361344.000000\n",
      "Train Epoch: 1336 [5120/11093 (45%)]\tLoss: 1209050880.000000\n",
      "Train Epoch: 1336 [8530/11093 (91%)]\tLoss: 1273161802.429074\n",
      "Train Epoch: 1337 [0/11093 (0%)]\tLoss: 1163188736.000000\n",
      "Train Epoch: 1337 [5120/11093 (45%)]\tLoss: 1634563584.000000\n",
      "Train Epoch: 1337 [8530/11093 (91%)]\tLoss: 1227139319.296600\n",
      "Train Epoch: 1338 [0/11093 (0%)]\tLoss: 1298321536.000000\n",
      "Train Epoch: 1338 [5120/11093 (45%)]\tLoss: 1190897664.000000\n",
      "Train Epoch: 1338 [8530/11093 (91%)]\tLoss: 1316346261.758499\n",
      "Train Epoch: 1339 [0/11093 (0%)]\tLoss: 1331267584.000000\n",
      "Train Epoch: 1339 [5120/11093 (45%)]\tLoss: 1537119488.000000\n",
      "Train Epoch: 1339 [8530/11093 (91%)]\tLoss: 1084217442.438452\n",
      "Train Epoch: 1340 [0/11093 (0%)]\tLoss: 1402891776.000000\n",
      "Train Epoch: 1340 [5120/11093 (45%)]\tLoss: 1122321664.000000\n",
      "Train Epoch: 1340 [8530/11093 (91%)]\tLoss: 1328409649.219226\n",
      "Train Epoch: 1341 [0/11093 (0%)]\tLoss: 1549711616.000000\n",
      "Train Epoch: 1341 [5120/11093 (45%)]\tLoss: 1081278208.000000\n",
      "Train Epoch: 1341 [8530/11093 (91%)]\tLoss: 1305571159.934349\n",
      "Train Epoch: 1342 [0/11093 (0%)]\tLoss: 1375308544.000000\n",
      "Train Epoch: 1342 [5120/11093 (45%)]\tLoss: 1335837696.000000\n",
      "Train Epoch: 1342 [8530/11093 (91%)]\tLoss: 1386150168.909730\n",
      "Train Epoch: 1343 [0/11093 (0%)]\tLoss: 1188629760.000000\n",
      "Train Epoch: 1343 [5120/11093 (45%)]\tLoss: 1340818944.000000\n",
      "Train Epoch: 1343 [8530/11093 (91%)]\tLoss: 1171404216.572098\n",
      "Train Epoch: 1344 [0/11093 (0%)]\tLoss: 1440333184.000000\n",
      "Train Epoch: 1344 [5120/11093 (45%)]\tLoss: 1326349056.000000\n",
      "Train Epoch: 1344 [8530/11093 (91%)]\tLoss: 1181688144.131301\n",
      "Train Epoch: 1345 [0/11093 (0%)]\tLoss: 1318976768.000000\n",
      "Train Epoch: 1345 [5120/11093 (45%)]\tLoss: 1198521600.000000\n",
      "Train Epoch: 1345 [8530/11093 (91%)]\tLoss: 1113121353.828839\n",
      "Train Epoch: 1346 [0/11093 (0%)]\tLoss: 1413289728.000000\n",
      "Train Epoch: 1346 [5120/11093 (45%)]\tLoss: 1497251584.000000\n",
      "Train Epoch: 1346 [8530/11093 (91%)]\tLoss: 1190373392.806565\n",
      "Train Epoch: 1347 [0/11093 (0%)]\tLoss: 1169908992.000000\n",
      "Train Epoch: 1347 [5120/11093 (45%)]\tLoss: 1226648064.000000\n",
      "Train Epoch: 1347 [8530/11093 (91%)]\tLoss: 1324362090.541618\n",
      "Train Epoch: 1348 [0/11093 (0%)]\tLoss: 1147379712.000000\n",
      "Train Epoch: 1348 [5120/11093 (45%)]\tLoss: 1457734016.000000\n",
      "Train Epoch: 1348 [8530/11093 (91%)]\tLoss: 1093247120.056272\n",
      "Train Epoch: 1349 [0/11093 (0%)]\tLoss: 1074563072.000000\n",
      "Train Epoch: 1349 [5120/11093 (45%)]\tLoss: 1210881536.000000\n",
      "Train Epoch: 1349 [8530/11093 (91%)]\tLoss: 1239279075.788980\n",
      "Train Epoch: 1350 [0/11093 (0%)]\tLoss: 1225106176.000000\n",
      "Train Epoch: 1350 [5120/11093 (45%)]\tLoss: 1481316864.000000\n",
      "Train Epoch: 1350 [8530/11093 (91%)]\tLoss: 1301574155.404455\n",
      "Train Epoch: 1351 [0/11093 (0%)]\tLoss: 1176196352.000000\n",
      "Train Epoch: 1351 [5120/11093 (45%)]\tLoss: 1394076544.000000\n",
      "Train Epoch: 1351 [8530/11093 (91%)]\tLoss: 1356329675.479484\n",
      "Train Epoch: 1352 [0/11093 (0%)]\tLoss: 1476036480.000000\n",
      "Train Epoch: 1352 [5120/11093 (45%)]\tLoss: 1281485568.000000\n",
      "Train Epoch: 1352 [8530/11093 (91%)]\tLoss: 1323352390.527550\n",
      "Train Epoch: 1353 [0/11093 (0%)]\tLoss: 1346747392.000000\n",
      "Train Epoch: 1353 [5120/11093 (45%)]\tLoss: 1351473664.000000\n",
      "Train Epoch: 1353 [8530/11093 (91%)]\tLoss: 1244452424.628371\n",
      "Train Epoch: 1354 [0/11093 (0%)]\tLoss: 1090969216.000000\n",
      "Train Epoch: 1354 [5120/11093 (45%)]\tLoss: 1125660672.000000\n",
      "Train Epoch: 1354 [8530/11093 (91%)]\tLoss: 1530481185.012896\n",
      "Train Epoch: 1355 [0/11093 (0%)]\tLoss: 1215449344.000000\n",
      "Train Epoch: 1355 [5120/11093 (45%)]\tLoss: 1494159232.000000\n",
      "Train Epoch: 1355 [8530/11093 (91%)]\tLoss: 1313439167.774912\n",
      "Train Epoch: 1356 [0/11093 (0%)]\tLoss: 1137706496.000000\n",
      "Train Epoch: 1356 [5120/11093 (45%)]\tLoss: 1100599168.000000\n",
      "Train Epoch: 1356 [8530/11093 (91%)]\tLoss: 1105649327.868699\n",
      "Train Epoch: 1357 [0/11093 (0%)]\tLoss: 1250889728.000000\n",
      "Train Epoch: 1357 [5120/11093 (45%)]\tLoss: 1495949056.000000\n",
      "Train Epoch: 1357 [8530/11093 (91%)]\tLoss: 1219570257.031653\n",
      "Train Epoch: 1358 [0/11093 (0%)]\tLoss: 1541743104.000000\n",
      "Train Epoch: 1358 [5120/11093 (45%)]\tLoss: 1264518272.000000\n",
      "Train Epoch: 1358 [8530/11093 (91%)]\tLoss: 1474019731.357562\n",
      "Train Epoch: 1359 [0/11093 (0%)]\tLoss: 1131823104.000000\n",
      "Train Epoch: 1359 [5120/11093 (45%)]\tLoss: 1280139008.000000\n",
      "Train Epoch: 1359 [8530/11093 (91%)]\tLoss: 1343819444.670574\n",
      "Train Epoch: 1360 [0/11093 (0%)]\tLoss: 1279984896.000000\n",
      "Train Epoch: 1360 [5120/11093 (45%)]\tLoss: 1423469824.000000\n",
      "Train Epoch: 1360 [8530/11093 (91%)]\tLoss: 1411069214.912075\n",
      "Train Epoch: 1361 [0/11093 (0%)]\tLoss: 1346995968.000000\n",
      "Train Epoch: 1361 [5120/11093 (45%)]\tLoss: 1241803392.000000\n",
      "Train Epoch: 1361 [8530/11093 (91%)]\tLoss: 1403379452.698710\n",
      "Train Epoch: 1362 [0/11093 (0%)]\tLoss: 1283016960.000000\n",
      "Train Epoch: 1362 [5120/11093 (45%)]\tLoss: 1251170304.000000\n",
      "Train Epoch: 1362 [8530/11093 (91%)]\tLoss: 1536145400.797186\n",
      "Train Epoch: 1363 [0/11093 (0%)]\tLoss: 1348564480.000000\n",
      "Train Epoch: 1363 [5120/11093 (45%)]\tLoss: 1319348480.000000\n",
      "Train Epoch: 1363 [8530/11093 (91%)]\tLoss: 1200977086.874560\n",
      "Train Epoch: 1364 [0/11093 (0%)]\tLoss: 1308404224.000000\n",
      "Train Epoch: 1364 [5120/11093 (45%)]\tLoss: 1501429248.000000\n",
      "Train Epoch: 1364 [8530/11093 (91%)]\tLoss: 1160643328.300117\n",
      "Train Epoch: 1365 [0/11093 (0%)]\tLoss: 1389788160.000000\n",
      "Train Epoch: 1365 [5120/11093 (45%)]\tLoss: 1146564224.000000\n",
      "Train Epoch: 1365 [8530/11093 (91%)]\tLoss: 1123247703.033998\n",
      "Train Epoch: 1366 [0/11093 (0%)]\tLoss: 1187052544.000000\n",
      "Train Epoch: 1366 [5120/11093 (45%)]\tLoss: 1208493824.000000\n",
      "Train Epoch: 1366 [8530/11093 (91%)]\tLoss: 1498429087.062134\n",
      "Train Epoch: 1367 [0/11093 (0%)]\tLoss: 1257226240.000000\n",
      "Train Epoch: 1367 [5120/11093 (45%)]\tLoss: 1267782912.000000\n",
      "Train Epoch: 1367 [8530/11093 (91%)]\tLoss: 1187781609.191090\n",
      "Train Epoch: 1368 [0/11093 (0%)]\tLoss: 1309306368.000000\n",
      "Train Epoch: 1368 [5120/11093 (45%)]\tLoss: 1237925248.000000\n",
      "Train Epoch: 1368 [8530/11093 (91%)]\tLoss: 1271334016.450176\n",
      "Train Epoch: 1369 [0/11093 (0%)]\tLoss: 1245545216.000000\n",
      "Train Epoch: 1369 [5120/11093 (45%)]\tLoss: 1560680704.000000\n",
      "Train Epoch: 1369 [8530/11093 (91%)]\tLoss: 1229465962.541618\n",
      "Train Epoch: 1370 [0/11093 (0%)]\tLoss: 1119649280.000000\n",
      "Train Epoch: 1370 [5120/11093 (45%)]\tLoss: 1254348416.000000\n",
      "Train Epoch: 1370 [8530/11093 (91%)]\tLoss: 1172075326.724502\n",
      "Train Epoch: 1371 [0/11093 (0%)]\tLoss: 1653714176.000000\n",
      "Train Epoch: 1371 [5120/11093 (45%)]\tLoss: 1223644800.000000\n",
      "Train Epoch: 1371 [8530/11093 (91%)]\tLoss: 1373882413.617820\n",
      "Train Epoch: 1372 [0/11093 (0%)]\tLoss: 1222249984.000000\n",
      "Train Epoch: 1372 [5120/11093 (45%)]\tLoss: 1253361920.000000\n",
      "Train Epoch: 1372 [8530/11093 (91%)]\tLoss: 1183586229.570926\n",
      "Train Epoch: 1373 [0/11093 (0%)]\tLoss: 1190965248.000000\n",
      "Train Epoch: 1373 [5120/11093 (45%)]\tLoss: 1274954496.000000\n",
      "Train Epoch: 1373 [8530/11093 (91%)]\tLoss: 1188160457.978898\n",
      "Train Epoch: 1374 [0/11093 (0%)]\tLoss: 1228282112.000000\n",
      "Train Epoch: 1374 [5120/11093 (45%)]\tLoss: 1216054784.000000\n",
      "Train Epoch: 1374 [8530/11093 (91%)]\tLoss: 1274315251.395076\n",
      "Train Epoch: 1375 [0/11093 (0%)]\tLoss: 1274960128.000000\n",
      "Train Epoch: 1375 [5120/11093 (45%)]\tLoss: 1450872448.000000\n",
      "Train Epoch: 1375 [8530/11093 (91%)]\tLoss: 1350757963.029308\n",
      "Train Epoch: 1376 [0/11093 (0%)]\tLoss: 1248340864.000000\n",
      "Train Epoch: 1376 [5120/11093 (45%)]\tLoss: 1254855808.000000\n",
      "Train Epoch: 1376 [8530/11093 (91%)]\tLoss: 1313283510.171161\n",
      "Train Epoch: 1377 [0/11093 (0%)]\tLoss: 1214686464.000000\n",
      "Train Epoch: 1377 [5120/11093 (45%)]\tLoss: 1416286464.000000\n",
      "Train Epoch: 1377 [8530/11093 (91%)]\tLoss: 1348547563.592028\n",
      "Train Epoch: 1378 [0/11093 (0%)]\tLoss: 1653405952.000000\n",
      "Train Epoch: 1378 [5120/11093 (45%)]\tLoss: 1183751168.000000\n",
      "Train Epoch: 1378 [8530/11093 (91%)]\tLoss: 1251118657.425557\n",
      "Train Epoch: 1379 [0/11093 (0%)]\tLoss: 1562617600.000000\n",
      "Train Epoch: 1379 [5120/11093 (45%)]\tLoss: 1195412736.000000\n",
      "Train Epoch: 1379 [8530/11093 (91%)]\tLoss: 1375166089.453693\n",
      "Train Epoch: 1380 [0/11093 (0%)]\tLoss: 1243392384.000000\n",
      "Train Epoch: 1380 [5120/11093 (45%)]\tLoss: 1137742080.000000\n",
      "Train Epoch: 1380 [8530/11093 (91%)]\tLoss: 1528190421.383353\n",
      "Train Epoch: 1381 [0/11093 (0%)]\tLoss: 1162062720.000000\n",
      "Train Epoch: 1381 [5120/11093 (45%)]\tLoss: 1365931520.000000\n",
      "Train Epoch: 1381 [8530/11093 (91%)]\tLoss: 1398019483.760844\n",
      "Train Epoch: 1382 [0/11093 (0%)]\tLoss: 1391799552.000000\n",
      "Train Epoch: 1382 [5120/11093 (45%)]\tLoss: 1388424448.000000\n",
      "Train Epoch: 1382 [8530/11093 (91%)]\tLoss: 1097644869.927315\n",
      "Train Epoch: 1383 [0/11093 (0%)]\tLoss: 1438609152.000000\n",
      "Train Epoch: 1383 [5120/11093 (45%)]\tLoss: 1208858880.000000\n",
      "Train Epoch: 1383 [8530/11093 (91%)]\tLoss: 1039479787.592028\n",
      "Train Epoch: 1384 [0/11093 (0%)]\tLoss: 1309158144.000000\n",
      "Train Epoch: 1384 [5120/11093 (45%)]\tLoss: 1384093696.000000\n",
      "Train Epoch: 1384 [8530/11093 (91%)]\tLoss: 1243383181.355217\n",
      "Train Epoch: 1385 [0/11093 (0%)]\tLoss: 1228447232.000000\n",
      "Train Epoch: 1385 [5120/11093 (45%)]\tLoss: 1098613248.000000\n",
      "Train Epoch: 1385 [8530/11093 (91%)]\tLoss: 1223362202.260258\n",
      "Train Epoch: 1386 [0/11093 (0%)]\tLoss: 1432519680.000000\n",
      "Train Epoch: 1386 [5120/11093 (45%)]\tLoss: 1507978752.000000\n",
      "Train Epoch: 1386 [8530/11093 (91%)]\tLoss: 1211947183.268464\n",
      "Train Epoch: 1387 [0/11093 (0%)]\tLoss: 1214865408.000000\n",
      "Train Epoch: 1387 [5120/11093 (45%)]\tLoss: 1311876096.000000\n",
      "Train Epoch: 1387 [8530/11093 (91%)]\tLoss: 1363001286.377491\n",
      "Train Epoch: 1388 [0/11093 (0%)]\tLoss: 1362071296.000000\n",
      "Train Epoch: 1388 [5120/11093 (45%)]\tLoss: 1226781312.000000\n",
      "Train Epoch: 1388 [8530/11093 (91%)]\tLoss: 1309078296.309496\n",
      "Train Epoch: 1389 [0/11093 (0%)]\tLoss: 1351634432.000000\n",
      "Train Epoch: 1389 [5120/11093 (45%)]\tLoss: 1308904448.000000\n",
      "Train Epoch: 1389 [8530/11093 (91%)]\tLoss: 1505722713.735053\n",
      "Train Epoch: 1390 [0/11093 (0%)]\tLoss: 1469254272.000000\n",
      "Train Epoch: 1390 [5120/11093 (45%)]\tLoss: 1239051776.000000\n",
      "Train Epoch: 1390 [8530/11093 (91%)]\tLoss: 1275755737.284877\n",
      "Train Epoch: 1391 [0/11093 (0%)]\tLoss: 1390467072.000000\n",
      "Train Epoch: 1391 [5120/11093 (45%)]\tLoss: 1170864512.000000\n",
      "Train Epoch: 1391 [8530/11093 (91%)]\tLoss: 1245688773.177022\n",
      "Train Epoch: 1392 [0/11093 (0%)]\tLoss: 1120008192.000000\n",
      "Train Epoch: 1392 [5120/11093 (45%)]\tLoss: 1214173696.000000\n",
      "Train Epoch: 1392 [8530/11093 (91%)]\tLoss: 1415449447.540446\n",
      "Train Epoch: 1393 [0/11093 (0%)]\tLoss: 1120022528.000000\n",
      "Train Epoch: 1393 [5120/11093 (45%)]\tLoss: 1262665856.000000\n",
      "Train Epoch: 1393 [8530/11093 (91%)]\tLoss: 1225525043.920281\n",
      "Train Epoch: 1394 [0/11093 (0%)]\tLoss: 1290723072.000000\n",
      "Train Epoch: 1394 [5120/11093 (45%)]\tLoss: 1249324032.000000\n",
      "Train Epoch: 1394 [8530/11093 (91%)]\tLoss: 1107874939.648300\n",
      "Train Epoch: 1395 [0/11093 (0%)]\tLoss: 1166028160.000000\n",
      "Train Epoch: 1395 [5120/11093 (45%)]\tLoss: 1499858176.000000\n",
      "Train Epoch: 1395 [8530/11093 (91%)]\tLoss: 1158331897.397421\n",
      "Train Epoch: 1396 [0/11093 (0%)]\tLoss: 1064009856.000000\n",
      "Train Epoch: 1396 [5120/11093 (45%)]\tLoss: 1464458752.000000\n",
      "Train Epoch: 1396 [8530/11093 (91%)]\tLoss: 1165492992.300117\n",
      "Train Epoch: 1397 [0/11093 (0%)]\tLoss: 1291641856.000000\n",
      "Train Epoch: 1397 [5120/11093 (45%)]\tLoss: 1325717504.000000\n",
      "Train Epoch: 1397 [8530/11093 (91%)]\tLoss: 1079218036.745604\n",
      "Train Epoch: 1398 [0/11093 (0%)]\tLoss: 1332693248.000000\n",
      "Train Epoch: 1398 [5120/11093 (45%)]\tLoss: 1146683776.000000\n",
      "Train Epoch: 1398 [8530/11093 (91%)]\tLoss: 1419345804.754982\n",
      "Train Epoch: 1399 [0/11093 (0%)]\tLoss: 1283247616.000000\n",
      "Train Epoch: 1399 [5120/11093 (45%)]\tLoss: 1333211776.000000\n",
      "Train Epoch: 1399 [8530/11093 (91%)]\tLoss: 1236994228.070340\n",
      "Train Epoch: 1400 [0/11093 (0%)]\tLoss: 1039383808.000000\n",
      "Train Epoch: 1400 [5120/11093 (45%)]\tLoss: 1254817024.000000\n",
      "Train Epoch: 1400 [8530/11093 (91%)]\tLoss: 1359775040.525205\n",
      "====> Epoch: 1400 Average loss: 1291175490.5097\n",
      "Train Epoch: 1401 [0/11093 (0%)]\tLoss: 1604297728.000000\n",
      "Train Epoch: 1401 [5120/11093 (45%)]\tLoss: 1041226880.000000\n",
      "Train Epoch: 1401 [8530/11093 (91%)]\tLoss: 1160396089.322392\n",
      "Train Epoch: 1402 [0/11093 (0%)]\tLoss: 1136375552.000000\n",
      "Train Epoch: 1402 [5120/11093 (45%)]\tLoss: 1439868800.000000\n",
      "Train Epoch: 1402 [8530/11093 (91%)]\tLoss: 1388103034.147714\n",
      "Train Epoch: 1403 [0/11093 (0%)]\tLoss: 1191061504.000000\n",
      "Train Epoch: 1403 [5120/11093 (45%)]\tLoss: 1189642752.000000\n",
      "Train Epoch: 1403 [8530/11093 (91%)]\tLoss: 1342820193.538101\n",
      "Train Epoch: 1404 [0/11093 (0%)]\tLoss: 1389175424.000000\n",
      "Train Epoch: 1404 [5120/11093 (45%)]\tLoss: 1626766976.000000\n",
      "Train Epoch: 1404 [8530/11093 (91%)]\tLoss: 1192328793.434936\n",
      "Train Epoch: 1405 [0/11093 (0%)]\tLoss: 1312169216.000000\n",
      "Train Epoch: 1405 [5120/11093 (45%)]\tLoss: 1285352064.000000\n",
      "Train Epoch: 1405 [8530/11093 (91%)]\tLoss: 1145001659.873388\n",
      "Train Epoch: 1406 [0/11093 (0%)]\tLoss: 1275478912.000000\n",
      "Train Epoch: 1406 [5120/11093 (45%)]\tLoss: 1285944832.000000\n",
      "Train Epoch: 1406 [8530/11093 (91%)]\tLoss: 1142374073.472450\n",
      "Train Epoch: 1407 [0/11093 (0%)]\tLoss: 1421915008.000000\n",
      "Train Epoch: 1407 [5120/11093 (45%)]\tLoss: 1242499200.000000\n",
      "Train Epoch: 1407 [8530/11093 (91%)]\tLoss: 1200095539.320047\n",
      "Train Epoch: 1408 [0/11093 (0%)]\tLoss: 1452277760.000000\n",
      "Train Epoch: 1408 [5120/11093 (45%)]\tLoss: 1169949952.000000\n",
      "Train Epoch: 1408 [8530/11093 (91%)]\tLoss: 1301240866.813599\n",
      "Train Epoch: 1409 [0/11093 (0%)]\tLoss: 1300588032.000000\n",
      "Train Epoch: 1409 [5120/11093 (45%)]\tLoss: 1460692096.000000\n",
      "Train Epoch: 1409 [8530/11093 (91%)]\tLoss: 1139444237.805393\n",
      "Train Epoch: 1410 [0/11093 (0%)]\tLoss: 1286192640.000000\n",
      "Train Epoch: 1410 [5120/11093 (45%)]\tLoss: 1642822912.000000\n",
      "Train Epoch: 1410 [8530/11093 (91%)]\tLoss: 1420378553.772568\n",
      "Train Epoch: 1411 [0/11093 (0%)]\tLoss: 1296832768.000000\n",
      "Train Epoch: 1411 [5120/11093 (45%)]\tLoss: 1520368896.000000\n",
      "Train Epoch: 1411 [8530/11093 (91%)]\tLoss: 1087581674.991794\n",
      "Train Epoch: 1412 [0/11093 (0%)]\tLoss: 1388911104.000000\n",
      "Train Epoch: 1412 [5120/11093 (45%)]\tLoss: 1550571520.000000\n",
      "Train Epoch: 1412 [8530/11093 (91%)]\tLoss: 1114045081.059789\n",
      "Train Epoch: 1413 [0/11093 (0%)]\tLoss: 1330007808.000000\n",
      "Train Epoch: 1413 [5120/11093 (45%)]\tLoss: 1244386560.000000\n",
      "Train Epoch: 1413 [8530/11093 (91%)]\tLoss: 1159268762.560375\n",
      "Train Epoch: 1414 [0/11093 (0%)]\tLoss: 1226655616.000000\n",
      "Train Epoch: 1414 [5120/11093 (45%)]\tLoss: 1173630976.000000\n",
      "Train Epoch: 1414 [8530/11093 (91%)]\tLoss: 1229893367.896835\n",
      "Train Epoch: 1415 [0/11093 (0%)]\tLoss: 1191820288.000000\n",
      "Train Epoch: 1415 [5120/11093 (45%)]\tLoss: 1303257856.000000\n",
      "Train Epoch: 1415 [8530/11093 (91%)]\tLoss: 1169653106.944900\n",
      "Train Epoch: 1416 [0/11093 (0%)]\tLoss: 1209088512.000000\n",
      "Train Epoch: 1416 [5120/11093 (45%)]\tLoss: 1310454400.000000\n",
      "Train Epoch: 1416 [8530/11093 (91%)]\tLoss: 1607089618.982415\n",
      "Train Epoch: 1417 [0/11093 (0%)]\tLoss: 1293674112.000000\n",
      "Train Epoch: 1417 [5120/11093 (45%)]\tLoss: 1509338624.000000\n",
      "Train Epoch: 1417 [8530/11093 (91%)]\tLoss: 1144355826.794842\n",
      "Train Epoch: 1418 [0/11093 (0%)]\tLoss: 1491528832.000000\n",
      "Train Epoch: 1418 [5120/11093 (45%)]\tLoss: 1233671552.000000\n",
      "Train Epoch: 1418 [8530/11093 (91%)]\tLoss: 1194896068.276670\n",
      "Train Epoch: 1419 [0/11093 (0%)]\tLoss: 1221090816.000000\n",
      "Train Epoch: 1419 [5120/11093 (45%)]\tLoss: 1358364032.000000\n",
      "Train Epoch: 1419 [8530/11093 (91%)]\tLoss: 1713166357.608441\n",
      "Train Epoch: 1420 [0/11093 (0%)]\tLoss: 1470309120.000000\n",
      "Train Epoch: 1420 [5120/11093 (45%)]\tLoss: 1437291136.000000\n",
      "Train Epoch: 1420 [8530/11093 (91%)]\tLoss: 1246285281.388042\n",
      "Train Epoch: 1421 [0/11093 (0%)]\tLoss: 1287238784.000000\n",
      "Train Epoch: 1421 [5120/11093 (45%)]\tLoss: 1329149952.000000\n",
      "Train Epoch: 1421 [8530/11093 (91%)]\tLoss: 1287389644.980070\n",
      "Train Epoch: 1422 [0/11093 (0%)]\tLoss: 1283066368.000000\n",
      "Train Epoch: 1422 [5120/11093 (45%)]\tLoss: 1299625856.000000\n",
      "Train Epoch: 1422 [8530/11093 (91%)]\tLoss: 1262114107.723330\n",
      "Train Epoch: 1423 [0/11093 (0%)]\tLoss: 1436944256.000000\n",
      "Train Epoch: 1423 [5120/11093 (45%)]\tLoss: 1341074048.000000\n",
      "Train Epoch: 1423 [8530/11093 (91%)]\tLoss: 1265345270.696366\n",
      "Train Epoch: 1424 [0/11093 (0%)]\tLoss: 1534112768.000000\n",
      "Train Epoch: 1424 [5120/11093 (45%)]\tLoss: 1487577216.000000\n",
      "Train Epoch: 1424 [8530/11093 (91%)]\tLoss: 1250028900.539273\n",
      "Train Epoch: 1425 [0/11093 (0%)]\tLoss: 1215447552.000000\n",
      "Train Epoch: 1425 [5120/11093 (45%)]\tLoss: 1185030912.000000\n",
      "Train Epoch: 1425 [8530/11093 (91%)]\tLoss: 1167325695.399765\n",
      "Train Epoch: 1426 [0/11093 (0%)]\tLoss: 1143028736.000000\n",
      "Train Epoch: 1426 [5120/11093 (45%)]\tLoss: 1293252608.000000\n",
      "Train Epoch: 1426 [8530/11093 (91%)]\tLoss: 1373592764.473623\n",
      "Train Epoch: 1427 [0/11093 (0%)]\tLoss: 1242789888.000000\n",
      "Train Epoch: 1427 [5120/11093 (45%)]\tLoss: 1184837248.000000\n",
      "Train Epoch: 1427 [8530/11093 (91%)]\tLoss: 1211295818.429074\n",
      "Train Epoch: 1428 [0/11093 (0%)]\tLoss: 1396239360.000000\n",
      "Train Epoch: 1428 [5120/11093 (45%)]\tLoss: 1234727936.000000\n",
      "Train Epoch: 1428 [8530/11093 (91%)]\tLoss: 1165734930.007034\n",
      "Train Epoch: 1429 [0/11093 (0%)]\tLoss: 1278119936.000000\n",
      "Train Epoch: 1429 [5120/11093 (45%)]\tLoss: 1388911104.000000\n",
      "Train Epoch: 1429 [8530/11093 (91%)]\tLoss: 1515616114.344666\n",
      "Train Epoch: 1430 [0/11093 (0%)]\tLoss: 1149818880.000000\n",
      "Train Epoch: 1430 [5120/11093 (45%)]\tLoss: 1492113280.000000\n",
      "Train Epoch: 1430 [8530/11093 (91%)]\tLoss: 1422224932.614302\n",
      "Train Epoch: 1431 [0/11093 (0%)]\tLoss: 1625149184.000000\n",
      "Train Epoch: 1431 [5120/11093 (45%)]\tLoss: 1243100160.000000\n",
      "Train Epoch: 1431 [8530/11093 (91%)]\tLoss: 1074243677.636577\n",
      "Train Epoch: 1432 [0/11093 (0%)]\tLoss: 1314603520.000000\n",
      "Train Epoch: 1432 [5120/11093 (45%)]\tLoss: 1341662720.000000\n",
      "Train Epoch: 1432 [8530/11093 (91%)]\tLoss: 1235375880.703400\n",
      "Train Epoch: 1433 [0/11093 (0%)]\tLoss: 1536178688.000000\n",
      "Train Epoch: 1433 [5120/11093 (45%)]\tLoss: 1350585088.000000\n",
      "Train Epoch: 1433 [8530/11093 (91%)]\tLoss: 1197861399.409144\n",
      "Train Epoch: 1434 [0/11093 (0%)]\tLoss: 1260287488.000000\n",
      "Train Epoch: 1434 [5120/11093 (45%)]\tLoss: 1503325440.000000\n",
      "Train Epoch: 1434 [8530/11093 (91%)]\tLoss: 1082989929.341149\n",
      "Train Epoch: 1435 [0/11093 (0%)]\tLoss: 1273355008.000000\n",
      "Train Epoch: 1435 [5120/11093 (45%)]\tLoss: 1285692672.000000\n",
      "Train Epoch: 1435 [8530/11093 (91%)]\tLoss: 1430015803.123095\n",
      "Train Epoch: 1436 [0/11093 (0%)]\tLoss: 1326993664.000000\n",
      "Train Epoch: 1436 [5120/11093 (45%)]\tLoss: 1355966848.000000\n",
      "Train Epoch: 1436 [8530/11093 (91%)]\tLoss: 1351844646.715123\n",
      "Train Epoch: 1437 [0/11093 (0%)]\tLoss: 1389814528.000000\n",
      "Train Epoch: 1437 [5120/11093 (45%)]\tLoss: 1218226944.000000\n",
      "Train Epoch: 1437 [8530/11093 (91%)]\tLoss: 1165885593.660023\n",
      "Train Epoch: 1438 [0/11093 (0%)]\tLoss: 1070761792.000000\n",
      "Train Epoch: 1438 [5120/11093 (45%)]\tLoss: 1091918336.000000\n",
      "Train Epoch: 1438 [8530/11093 (91%)]\tLoss: 1324328746.316530\n",
      "Train Epoch: 1439 [0/11093 (0%)]\tLoss: 1252340608.000000\n",
      "Train Epoch: 1439 [5120/11093 (45%)]\tLoss: 1117316608.000000\n",
      "Train Epoch: 1439 [8530/11093 (91%)]\tLoss: 1263936438.771395\n",
      "Train Epoch: 1440 [0/11093 (0%)]\tLoss: 1209314048.000000\n",
      "Train Epoch: 1440 [5120/11093 (45%)]\tLoss: 1556286720.000000\n",
      "Train Epoch: 1440 [8530/11093 (91%)]\tLoss: 1194639532.867526\n",
      "Train Epoch: 1441 [0/11093 (0%)]\tLoss: 1188981632.000000\n",
      "Train Epoch: 1441 [5120/11093 (45%)]\tLoss: 1282027008.000000\n",
      "Train Epoch: 1441 [8530/11093 (91%)]\tLoss: 1147264687.868699\n",
      "Train Epoch: 1442 [0/11093 (0%)]\tLoss: 1165535488.000000\n",
      "Train Epoch: 1442 [5120/11093 (45%)]\tLoss: 1603508736.000000\n",
      "Train Epoch: 1442 [8530/11093 (91%)]\tLoss: 1219140469.946073\n",
      "Train Epoch: 1443 [0/11093 (0%)]\tLoss: 1314146304.000000\n",
      "Train Epoch: 1443 [5120/11093 (45%)]\tLoss: 1435112192.000000\n",
      "Train Epoch: 1443 [8530/11093 (91%)]\tLoss: 1417262943.137163\n",
      "Train Epoch: 1444 [0/11093 (0%)]\tLoss: 1322861184.000000\n",
      "Train Epoch: 1444 [5120/11093 (45%)]\tLoss: 1288910720.000000\n",
      "Train Epoch: 1444 [8530/11093 (91%)]\tLoss: 1566819629.317702\n",
      "Train Epoch: 1445 [0/11093 (0%)]\tLoss: 1207269120.000000\n",
      "Train Epoch: 1445 [5120/11093 (45%)]\tLoss: 1298547584.000000\n",
      "Train Epoch: 1445 [8530/11093 (91%)]\tLoss: 1313624174.443142\n",
      "Train Epoch: 1446 [0/11093 (0%)]\tLoss: 1333627264.000000\n",
      "Train Epoch: 1446 [5120/11093 (45%)]\tLoss: 1133417472.000000\n",
      "Train Epoch: 1446 [8530/11093 (91%)]\tLoss: 1621382152.403283\n",
      "Train Epoch: 1447 [0/11093 (0%)]\tLoss: 1288791040.000000\n",
      "Train Epoch: 1447 [5120/11093 (45%)]\tLoss: 1489387008.000000\n",
      "Train Epoch: 1447 [8530/11093 (91%)]\tLoss: 1298320865.388042\n",
      "Train Epoch: 1448 [0/11093 (0%)]\tLoss: 1158072448.000000\n",
      "Train Epoch: 1448 [5120/11093 (45%)]\tLoss: 1119027328.000000\n",
      "Train Epoch: 1448 [8530/11093 (91%)]\tLoss: 1304920870.715123\n",
      "Train Epoch: 1449 [0/11093 (0%)]\tLoss: 1448589312.000000\n",
      "Train Epoch: 1449 [5120/11093 (45%)]\tLoss: 1350720640.000000\n",
      "Train Epoch: 1449 [8530/11093 (91%)]\tLoss: 1389915454.124267\n",
      "Train Epoch: 1450 [0/11093 (0%)]\tLoss: 1217758464.000000\n",
      "Train Epoch: 1450 [5120/11093 (45%)]\tLoss: 1329898368.000000\n",
      "Train Epoch: 1450 [8530/11093 (91%)]\tLoss: 1222346125.355217\n",
      "Train Epoch: 1451 [0/11093 (0%)]\tLoss: 1063597568.000000\n",
      "Train Epoch: 1451 [5120/11093 (45%)]\tLoss: 1176351360.000000\n",
      "Train Epoch: 1451 [8530/11093 (91%)]\tLoss: 1348507765.645956\n",
      "Train Epoch: 1452 [0/11093 (0%)]\tLoss: 1240000256.000000\n",
      "Train Epoch: 1452 [5120/11093 (45%)]\tLoss: 1305885568.000000\n",
      "Train Epoch: 1452 [8530/11093 (91%)]\tLoss: 1270057255.315357\n",
      "Train Epoch: 1453 [0/11093 (0%)]\tLoss: 1586539776.000000\n",
      "Train Epoch: 1453 [5120/11093 (45%)]\tLoss: 1217855744.000000\n",
      "Train Epoch: 1453 [8530/11093 (91%)]\tLoss: 1190743406.143025\n",
      "Train Epoch: 1454 [0/11093 (0%)]\tLoss: 1343123712.000000\n",
      "Train Epoch: 1454 [5120/11093 (45%)]\tLoss: 1170866048.000000\n",
      "Train Epoch: 1454 [8530/11093 (91%)]\tLoss: 1197736704.300117\n",
      "Train Epoch: 1455 [0/11093 (0%)]\tLoss: 1313067904.000000\n",
      "Train Epoch: 1455 [5120/11093 (45%)]\tLoss: 1167440640.000000\n",
      "Train Epoch: 1455 [8530/11093 (91%)]\tLoss: 1222614338.926143\n",
      "Train Epoch: 1456 [0/11093 (0%)]\tLoss: 1292639488.000000\n",
      "Train Epoch: 1456 [5120/11093 (45%)]\tLoss: 1422493824.000000\n",
      "Train Epoch: 1456 [8530/11093 (91%)]\tLoss: 1283496514.626026\n",
      "Train Epoch: 1457 [0/11093 (0%)]\tLoss: 1431741440.000000\n",
      "Train Epoch: 1457 [5120/11093 (45%)]\tLoss: 1248019712.000000\n",
      "Train Epoch: 1457 [8530/11093 (91%)]\tLoss: 1284652345.322392\n",
      "Train Epoch: 1458 [0/11093 (0%)]\tLoss: 1151400448.000000\n",
      "Train Epoch: 1458 [5120/11093 (45%)]\tLoss: 1137708032.000000\n",
      "Train Epoch: 1458 [8530/11093 (91%)]\tLoss: 1329881404.923798\n",
      "Train Epoch: 1459 [0/11093 (0%)]\tLoss: 1497874944.000000\n",
      "Train Epoch: 1459 [5120/11093 (45%)]\tLoss: 1371357568.000000\n",
      "Train Epoch: 1459 [8530/11093 (91%)]\tLoss: 1256120060.698710\n",
      "Train Epoch: 1460 [0/11093 (0%)]\tLoss: 1260291200.000000\n",
      "Train Epoch: 1460 [5120/11093 (45%)]\tLoss: 1527796224.000000\n",
      "Train Epoch: 1460 [8530/11093 (91%)]\tLoss: 1151796045.130129\n",
      "Train Epoch: 1461 [0/11093 (0%)]\tLoss: 1393350400.000000\n",
      "Train Epoch: 1461 [5120/11093 (45%)]\tLoss: 1192853760.000000\n",
      "Train Epoch: 1461 [8530/11093 (91%)]\tLoss: 1170781893.477139\n",
      "Train Epoch: 1462 [0/11093 (0%)]\tLoss: 1479323520.000000\n",
      "Train Epoch: 1462 [5120/11093 (45%)]\tLoss: 1218489600.000000\n",
      "Train Epoch: 1462 [8530/11093 (91%)]\tLoss: 1306669829.101993\n",
      "Train Epoch: 1463 [0/11093 (0%)]\tLoss: 1232531072.000000\n",
      "Train Epoch: 1463 [5120/11093 (45%)]\tLoss: 1357616384.000000\n",
      "Train Epoch: 1463 [8530/11093 (91%)]\tLoss: 1407352486.264947\n",
      "Train Epoch: 1464 [0/11093 (0%)]\tLoss: 1378335616.000000\n",
      "Train Epoch: 1464 [5120/11093 (45%)]\tLoss: 1390570752.000000\n",
      "Train Epoch: 1464 [8530/11093 (91%)]\tLoss: 1485352772.726846\n",
      "Train Epoch: 1465 [0/11093 (0%)]\tLoss: 1269214464.000000\n",
      "Train Epoch: 1465 [5120/11093 (45%)]\tLoss: 1307212544.000000\n",
      "Train Epoch: 1465 [8530/11093 (91%)]\tLoss: 1236179829.946073\n",
      "Train Epoch: 1466 [0/11093 (0%)]\tLoss: 1454318336.000000\n",
      "Train Epoch: 1466 [5120/11093 (45%)]\tLoss: 1377141248.000000\n",
      "Train Epoch: 1466 [8530/11093 (91%)]\tLoss: 1085230830.293083\n",
      "Train Epoch: 1467 [0/11093 (0%)]\tLoss: 1208728192.000000\n",
      "Train Epoch: 1467 [5120/11093 (45%)]\tLoss: 1232192000.000000\n",
      "Train Epoch: 1467 [8530/11093 (91%)]\tLoss: 1156065796.201641\n",
      "Train Epoch: 1468 [0/11093 (0%)]\tLoss: 1314388992.000000\n",
      "Train Epoch: 1468 [5120/11093 (45%)]\tLoss: 1492171520.000000\n",
      "Train Epoch: 1468 [8530/11093 (91%)]\tLoss: 1294857061.139508\n",
      "Train Epoch: 1469 [0/11093 (0%)]\tLoss: 1379906432.000000\n",
      "Train Epoch: 1469 [5120/11093 (45%)]\tLoss: 1183768576.000000\n",
      "Train Epoch: 1469 [8530/11093 (91%)]\tLoss: 1258818638.030481\n",
      "Train Epoch: 1470 [0/11093 (0%)]\tLoss: 1150950400.000000\n",
      "Train Epoch: 1470 [5120/11093 (45%)]\tLoss: 1465581824.000000\n",
      "Train Epoch: 1470 [8530/11093 (91%)]\tLoss: 1108346368.600235\n",
      "Train Epoch: 1471 [0/11093 (0%)]\tLoss: 1231181440.000000\n",
      "Train Epoch: 1471 [5120/11093 (45%)]\tLoss: 1400026112.000000\n",
      "Train Epoch: 1471 [8530/11093 (91%)]\tLoss: 1164179045.439625\n",
      "Train Epoch: 1472 [0/11093 (0%)]\tLoss: 1352007424.000000\n",
      "Train Epoch: 1472 [5120/11093 (45%)]\tLoss: 1447126656.000000\n",
      "Train Epoch: 1472 [8530/11093 (91%)]\tLoss: 1277452067.113716\n",
      "Train Epoch: 1473 [0/11093 (0%)]\tLoss: 1138126720.000000\n",
      "Train Epoch: 1473 [5120/11093 (45%)]\tLoss: 1329968384.000000\n",
      "Train Epoch: 1473 [8530/11093 (91%)]\tLoss: 1314691496.966002\n",
      "Train Epoch: 1474 [0/11093 (0%)]\tLoss: 1309135872.000000\n",
      "Train Epoch: 1474 [5120/11093 (45%)]\tLoss: 1180654336.000000\n",
      "Train Epoch: 1474 [8530/11093 (91%)]\tLoss: 1306687653.664713\n",
      "Train Epoch: 1475 [0/11093 (0%)]\tLoss: 1556299008.000000\n",
      "Train Epoch: 1475 [5120/11093 (45%)]\tLoss: 1384742528.000000\n",
      "Train Epoch: 1475 [8530/11093 (91%)]\tLoss: 1304222332.248535\n",
      "Train Epoch: 1476 [0/11093 (0%)]\tLoss: 1231288192.000000\n",
      "Train Epoch: 1476 [5120/11093 (45%)]\tLoss: 1255809280.000000\n",
      "Train Epoch: 1476 [8530/11093 (91%)]\tLoss: 1513770964.783118\n",
      "Train Epoch: 1477 [0/11093 (0%)]\tLoss: 1384037120.000000\n",
      "Train Epoch: 1477 [5120/11093 (45%)]\tLoss: 1132887552.000000\n",
      "Train Epoch: 1477 [8530/11093 (91%)]\tLoss: 1294893632.225088\n",
      "Train Epoch: 1478 [0/11093 (0%)]\tLoss: 1270526208.000000\n",
      "Train Epoch: 1478 [5120/11093 (45%)]\tLoss: 1235809408.000000\n",
      "Train Epoch: 1478 [8530/11093 (91%)]\tLoss: 1368727888.131301\n",
      "Train Epoch: 1479 [0/11093 (0%)]\tLoss: 1243684864.000000\n",
      "Train Epoch: 1479 [5120/11093 (45%)]\tLoss: 1385211520.000000\n",
      "Train Epoch: 1479 [8530/11093 (91%)]\tLoss: 1501228311.709261\n",
      "Train Epoch: 1480 [0/11093 (0%)]\tLoss: 1371254656.000000\n",
      "Train Epoch: 1480 [5120/11093 (45%)]\tLoss: 1473767936.000000\n",
      "Train Epoch: 1480 [8530/11093 (91%)]\tLoss: 1329914902.808910\n",
      "Train Epoch: 1481 [0/11093 (0%)]\tLoss: 1156477952.000000\n",
      "Train Epoch: 1481 [5120/11093 (45%)]\tLoss: 1180169728.000000\n",
      "Train Epoch: 1481 [8530/11093 (91%)]\tLoss: 1362341623.896835\n",
      "Train Epoch: 1482 [0/11093 (0%)]\tLoss: 1193465216.000000\n",
      "Train Epoch: 1482 [5120/11093 (45%)]\tLoss: 1297756928.000000\n",
      "Train Epoch: 1482 [8530/11093 (91%)]\tLoss: 1352102488.234467\n",
      "Train Epoch: 1483 [0/11093 (0%)]\tLoss: 1190083712.000000\n",
      "Train Epoch: 1483 [5120/11093 (45%)]\tLoss: 1237076480.000000\n",
      "Train Epoch: 1483 [8530/11093 (91%)]\tLoss: 1095656355.563892\n",
      "Train Epoch: 1484 [0/11093 (0%)]\tLoss: 1172381696.000000\n",
      "Train Epoch: 1484 [5120/11093 (45%)]\tLoss: 1503010560.000000\n",
      "Train Epoch: 1484 [8530/11093 (91%)]\tLoss: 1263552058.222743\n",
      "Train Epoch: 1485 [0/11093 (0%)]\tLoss: 1288770432.000000\n",
      "Train Epoch: 1485 [5120/11093 (45%)]\tLoss: 1191435520.000000\n",
      "Train Epoch: 1485 [8530/11093 (91%)]\tLoss: 1554749941.796014\n",
      "Train Epoch: 1486 [0/11093 (0%)]\tLoss: 1443731328.000000\n",
      "Train Epoch: 1486 [5120/11093 (45%)]\tLoss: 1431523072.000000\n",
      "Train Epoch: 1486 [8530/11093 (91%)]\tLoss: 1401330549.946073\n",
      "Train Epoch: 1487 [0/11093 (0%)]\tLoss: 1722960256.000000\n",
      "Train Epoch: 1487 [5120/11093 (45%)]\tLoss: 1356457472.000000\n",
      "Train Epoch: 1487 [8530/11093 (91%)]\tLoss: 1336991254.208675\n",
      "Train Epoch: 1488 [0/11093 (0%)]\tLoss: 1490927360.000000\n",
      "Train Epoch: 1488 [5120/11093 (45%)]\tLoss: 1177219328.000000\n",
      "Train Epoch: 1488 [8530/11093 (91%)]\tLoss: 1161929001.716295\n",
      "Train Epoch: 1489 [0/11093 (0%)]\tLoss: 1365249792.000000\n",
      "Train Epoch: 1489 [5120/11093 (45%)]\tLoss: 1259004928.000000\n",
      "Train Epoch: 1489 [8530/11093 (91%)]\tLoss: 1140185647.418523\n",
      "Train Epoch: 1490 [0/11093 (0%)]\tLoss: 1544114176.000000\n",
      "Train Epoch: 1490 [5120/11093 (45%)]\tLoss: 1423740032.000000\n",
      "Train Epoch: 1490 [8530/11093 (91%)]\tLoss: 1143150517.570926\n",
      "Train Epoch: 1491 [0/11093 (0%)]\tLoss: 1409174016.000000\n",
      "Train Epoch: 1491 [5120/11093 (45%)]\tLoss: 1274508160.000000\n",
      "Train Epoch: 1491 [8530/11093 (91%)]\tLoss: 1586178641.031653\n",
      "Train Epoch: 1492 [0/11093 (0%)]\tLoss: 1309942528.000000\n",
      "Train Epoch: 1492 [5120/11093 (45%)]\tLoss: 1268888320.000000\n",
      "Train Epoch: 1492 [8530/11093 (91%)]\tLoss: 1337171804.736225\n",
      "Train Epoch: 1493 [0/11093 (0%)]\tLoss: 1313008128.000000\n",
      "Train Epoch: 1493 [5120/11093 (45%)]\tLoss: 1204845952.000000\n",
      "Train Epoch: 1493 [8530/11093 (91%)]\tLoss: 1328268281.997655\n",
      "Train Epoch: 1494 [0/11093 (0%)]\tLoss: 1297403648.000000\n",
      "Train Epoch: 1494 [5120/11093 (45%)]\tLoss: 1258516352.000000\n",
      "Train Epoch: 1494 [8530/11093 (91%)]\tLoss: 1414973562.447831\n",
      "Train Epoch: 1495 [0/11093 (0%)]\tLoss: 1124113664.000000\n",
      "Train Epoch: 1495 [5120/11093 (45%)]\tLoss: 1395025792.000000\n",
      "Train Epoch: 1495 [8530/11093 (91%)]\tLoss: 1312713892.464244\n",
      "Train Epoch: 1496 [0/11093 (0%)]\tLoss: 1254830336.000000\n",
      "Train Epoch: 1496 [5120/11093 (45%)]\tLoss: 1245490304.000000\n",
      "Train Epoch: 1496 [8530/11093 (91%)]\tLoss: 1241142741.383353\n",
      "Train Epoch: 1497 [0/11093 (0%)]\tLoss: 1241322240.000000\n",
      "Train Epoch: 1497 [5120/11093 (45%)]\tLoss: 1310501888.000000\n",
      "Train Epoch: 1497 [8530/11093 (91%)]\tLoss: 1363769586.494725\n",
      "Train Epoch: 1498 [0/11093 (0%)]\tLoss: 1303643904.000000\n",
      "Train Epoch: 1498 [5120/11093 (45%)]\tLoss: 1233270912.000000\n",
      "Train Epoch: 1498 [8530/11093 (91%)]\tLoss: 1623451645.599062\n",
      "Train Epoch: 1499 [0/11093 (0%)]\tLoss: 1194312960.000000\n",
      "Train Epoch: 1499 [5120/11093 (45%)]\tLoss: 1297060864.000000\n",
      "Train Epoch: 1499 [8530/11093 (91%)]\tLoss: 1190133760.000000\n",
      "Train Epoch: 1500 [0/11093 (0%)]\tLoss: 1386480640.000000\n",
      "Train Epoch: 1500 [5120/11093 (45%)]\tLoss: 1389670144.000000\n",
      "Train Epoch: 1500 [8530/11093 (91%)]\tLoss: 1315785095.352872\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66a02b-7c87-466b-b5cc-62df1f81fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1115c-3718-4f3e-9766-92c28b509833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
